This is octave.info, produced by makeinfo version 6.5 from octave.texi.

INFO-DIR-SECTION Math
START-INFO-DIR-ENTRY
* Octave: (octave).             Interactive language for numerical computations.
END-INFO-DIR-ENTRY

Copyright © 1996-2018 John W. Eaton.

   Permission is granted to make and distribute verbatim copies of this
manual provided the copyright notice and this permission notice are
preserved on all copies.

   Permission is granted to copy and distribute modified versions of
this manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

   Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions.


File: octave.info,  Node: Iterative Techniques,  Next: Real Life Example,  Prev: Sparse Linear Algebra,  Up: Sparse Matrices

22.3 Iterative Techniques Applied to Sparse Matrices
====================================================

The left division ‘\’ and right division ‘/’ operators, discussed in the
previous section, use direct solvers to resolve a linear equation of the
form ‘X = A \ B’ or ‘X = B / A’.  Octave also includes a number of
functions to solve sparse linear equations using iterative techniques.

 -- : X = pcg (A, B, TOL, MAXIT, M1, M2, X0, ...)
 -- : X = pcg (A, B, TOL, MAXIT, M, [], X0, ...)
 -- : [X, FLAG, RELRES, ITER, RESVEC, EIGEST] = pcg (A, B, ...)

     Solve the linear system of equations ‘A * X = B’ by means of the
     Preconditioned Conjugate Gradient iterative method.

     The input arguments are:

        • A is the matrix of the linear system and it must be square.  A
          can be passed as a matrix, function handle, or inline function
          ‘Afun’ such that ‘Afun(x) = A * x’.  Additional parameters to
          ‘Afun’ may be passed after X0.

          A has to be Hermitian and Positive Definite (HPD).  If ‘pcg’
          detects A not to be positive definite, a warning is printed
          and the FLAG output is set.

        • B is the right-hand side vector.

        • TOL is the required relative tolerance for the residual error,
          ‘B - A * X’.  The iteration stops if
          ‘norm (B - A * X)’ ≤ ‘TOL * norm (B)’.  If TOL is omitted or
          empty, then a tolerance of 1e-6 is used.

        • MAXIT is the maximum allowed number of iterations; if MAXIT is
          omitted or empty then a value of 20 is used.

        • M is a HPD preconditioning matrix.  For any decomposition ‘M =
          P1 * P2’ such that ‘inv (P1) * A * inv (P2)’ is HPD, the
          conjugate gradient method is formally applied to the linear
          system ‘inv (P1) * A * inv (P2) * Y = inv (P1) * B’, with ‘X =
          inv (P2) * Y’ (split preconditioning).  In practice, at each
          iteration of the conjugate gradient method a linear system
          with matrix M is solved with ‘mldivide’.  If a particular
          factorization ‘M = M1 * M2’ is available (for instance, an
          incomplete Cholesky factorization of A), the two matrices M1
          and M2 can be passed and the relative linear systems are
          solved with the ‘mldivide’ operator.  Note that a proper
          choice of the preconditioner may dramatically improve the
          overall performance of the method.  Instead of matrices M1 and
          M2, the user may pass two functions which return the results
          of applying the inverse of M1 and M2 to a vector.  If M1 is
          omitted or empty ‘[]’, then no preconditioning is applied.  If
          no factorization of M is available, M2 can be omitted or left
          [], and the input variable M1 can be used to pass the
          preconditioner M.

        • X0 is the initial guess.  If X0 is omitted or empty then the
          function sets X0 to a zero vector by default.

     The arguments which follow X0 are treated as parameters, and passed
     in an appropriate manner to any of the functions (A or M1 or M2)
     that have been given to ‘pcg’.  See the examples below for further
     details.

     The output arguments are:

        • X is the computed approximation to the solution of
          ‘A * X = B’.  If the algorithm did not converge, then X is the
          iteration which has the minimum residual.

        • FLAG reports on the convergence:

             • 0: The algorithm converged to within the prescribed
               tolerance.

             • 1: The algorithm did not converge and it reached the
               maximum number of iterations.

             • 2: The preconditioner matrix is singular.

             • 3: The algorithm stagnated, i.e., the absolute value of
               the difference between the current iteration X and the
               previous is less than ‘EPS * norm (X,2)’.

             • 4: The algorithm detects that the input (preconditioned)
               matrix is not HPD.

        • RELRES is the ratio of the final residual to its initial
          value, measured in the Euclidean norm.

        • ITER indicates the iteration of X which it was computed.
          Since the output X corresponds to the minimal residual
          solution, the total number of iterations that the method
          performed is given by ‘length(resvec) - 1’.

        • RESVEC describes the convergence history of the method.
          ‘RESVEC (I, 1)’ is the Euclidean norm of the residual, and
          ‘RESVEC (I, 2)’ is the preconditioned residual norm, after the
          (I-1)-th iteration, ‘I = 1, 2, ..., ITER+1’.  The
          preconditioned residual norm is defined as ‘R' * (M \ R)’
          where ‘R = B - A * X’, see also the description of M.  If
          EIGEST is not required, only ‘RESVEC (:, 1)’ is returned.

        • EIGEST returns the estimate for the smallest ‘EIGEST(1)’ and
          largest ‘EIGEST(2)’ eigenvalues of the preconditioned matrix
          ‘P = M \ A’.  In particular, if no preconditioning is used,
          the estimates for the extreme eigenvalues of A are returned.
          ‘EIGEST(1)’ is an overestimate and ‘EIGEST(2)’ is an
          underestimate, so that ‘EIGEST(2) / EIGEST(1)’ is a lower
          bound for ‘cond (P, 2)’, which nevertheless in the limit
          should theoretically be equal to the actual value of the
          condition number.

     Let us consider a trivial problem with a tridiagonal matrix

          n = 10;
          A = toeplitz (sparse ([1, 1], [1, 2], [2, 1], 1, n));
          b = A * ones (n, 1);
          M1 = ichol (A); # in this tridiagonal case it corresponds to chol (A)'
          M2 = M1';
          M = M1 * M2;
          Afun = @(x) A * x;
          Mfun = @(x) M \ x;
          M1fun = @(x) M1 \ x;
          M2fun = @(x) M2 \ x;

     EXAMPLE 1: Simplest use of ‘pcg’

          x = pcg (A, b)

     EXAMPLE 2: ‘pcg’ with a function which computes ‘A * X’

          x = pcg (Afun, b)

     EXAMPLE 3: ‘pcg’ with a preconditioner matrix M

          x = pcg (A, b, 1e-06, 100, M)

     EXAMPLE 4: ‘pcg’ with a function as preconditioner

          x = pcg (Afun, b, 1e-6, 100, Mfun)

     EXAMPLE 5: ‘pcg’ with preconditioner matrices M1 and M2

          x = pcg (A, b, 1e-6, 100, M1, M2)

     EXAMPLE 6: ‘pcg’ with functions as preconditioners

          x = pcg (Afun, b, 1e-6, 100, M1fun, M2fun)

     EXAMPLE 7: ‘pcg’ with as input a function requiring an argument

            function y = Ap (A, x, p) # compute A^p * x
               y = x;
               for i = 1:p
                 y = A * y;
               endfor
            endfunction
          Apfun = @(x, p) Ap (A, x, p);
          x = pcg (Apfun, b, [], [], [], [], [], 2);

     EXAMPLE 8: explicit example to show that ‘pcg’ uses a split
     preconditioner

          M1 = ichol (A + 0.1 * eye (n)); # factorization of A perturbed
          M2 = M1';
          M = M1 * M2;

          ## reference solution computed by pcg after two iterations
          [x_ref, fl] = pcg (A, b, [], 2, M)

          ## split preconditioning
          [y, fl] = pcg ((M1 \ A) / M2, M1 \ b, [], 2)
          x = M2 \ y # compare x and x_ref


     References:

       1. C.T. Kelley, ‘Iterative Methods for Linear and Nonlinear
          Equations’, SIAM, 1995.  (the base PCG algorithm)

       2. Y. Saad, ‘Iterative Methods for Sparse Linear Systems’, PWS
          1996.  (condition number estimate from PCG) Revised version of
          this book is available online at
          <https://www-users.cs.umn.edu/~saad/books.html>

     See also: *note sparse: XREFsparse, *note pcr: XREFpcr, *note
     gmres: XREFgmres, *note bicg: XREFbicg, *note bicgstab:
     XREFbicgstab, *note cgs: XREFcgs.

 -- : X = pcr (A, B, TOL, MAXIT, M, X0, ...)
 -- : [X, FLAG, RELRES, ITER, RESVEC] = pcr (...)

     Solve the linear system of equations ‘A * X = B’ by means of the
     Preconditioned Conjugate Residuals iterative method.

     The input arguments are

        • A can be either a square (preferably sparse) matrix or a
          function handle, inline function or string containing the name
          of a function which computes ‘A * X’.  In principle A should
          be symmetric and non-singular; if ‘pcr’ finds A to be
          numerically singular, you will get a warning message and the
          FLAG output parameter will be set.

        • B is the right hand side vector.

        • TOL is the required relative tolerance for the residual error,
          ‘B - A * X’.  The iteration stops if ‘norm (B - A * X) <= TOL
          * norm (B - A * X0)’.  If TOL is empty or is omitted, the
          function sets ‘TOL = 1e-6’ by default.

        • MAXIT is the maximum allowable number of iterations; if ‘[]’
          is supplied for MAXIT, or ‘pcr’ has less arguments, a default
          value equal to 20 is used.

        • M is the (left) preconditioning matrix, so that the iteration
          is (theoretically) equivalent to solving by ‘pcr’ ‘P * X = M \
          B’, with ‘P = M \ A’.  Note that a proper choice of the
          preconditioner may dramatically improve the overall
          performance of the method.  Instead of matrix M, the user may
          pass a function which returns the results of applying the
          inverse of M to a vector (usually this is the preferred way of
          using the preconditioner).  If ‘[]’ is supplied for M, or M is
          omitted, no preconditioning is applied.

        • X0 is the initial guess.  If X0 is empty or omitted, the
          function sets X0 to a zero vector by default.

     The arguments which follow X0 are treated as parameters, and passed
     in a proper way to any of the functions (A or M) which are passed
     to ‘pcr’.  See the examples below for further details.

     The output arguments are

        • X is the computed approximation to the solution of ‘A * X =
          B’.

        • FLAG reports on the convergence.  ‘FLAG = 0’ means the
          solution converged and the tolerance criterion given by TOL is
          satisfied.  ‘FLAG = 1’ means that the MAXIT limit for the
          iteration count was reached.  ‘FLAG = 3’ reports a ‘pcr’
          breakdown, see [1] for details.

        • RELRES is the ratio of the final residual to its initial
          value, measured in the Euclidean norm.

        • ITER is the actual number of iterations performed.

        • RESVEC describes the convergence history of the method, so
          that ‘RESVEC (i)’ contains the Euclidean norms of the residual
          after the (I-1)-th iteration, ‘I = 1,2, ..., ITER+1’.

     Let us consider a trivial problem with a diagonal matrix (we
     exploit the sparsity of A)

          n = 10;
          A = sparse (diag (1:n));
          b = rand (N, 1);

     EXAMPLE 1: Simplest use of ‘pcr’

          x = pcr (A, b)

     EXAMPLE 2: ‘pcr’ with a function which computes ‘A * X’.

          function y = apply_a (x)
            y = [1:10]' .* x;
          endfunction

          x = pcr ("apply_a", b)

     EXAMPLE 3: Preconditioned iteration, with full diagnostics.  The
     preconditioner (quite strange, because even the original matrix A
     is trivial) is defined as a function

          function y = apply_m (x)
            k = floor (length (x) - 2);
            y = x;
            y(1:k) = x(1:k) ./ [1:k]';
          endfunction

          [x, flag, relres, iter, resvec] = ...
                             pcr (A, b, [], [], "apply_m")
          semilogy ([1:iter+1], resvec);

     EXAMPLE 4: Finally, a preconditioner which depends on a parameter
     K.

          function y = apply_m (x, varargin)
            k = varargin{1};
            y = x;
            y(1:k) = x(1:k) ./ [1:k]';
          endfunction

          [x, flag, relres, iter, resvec] = ...
                             pcr (A, b, [], [], "apply_m"', [], 3)

     References:

     [1] W. Hackbusch, ‘Iterative Solution of Large Sparse Systems of
     Equations’, section 9.5.4; Springer, 1994

     See also: *note sparse: XREFsparse, *note pcg: XREFpcg.

   The speed with which an iterative solver converges to a solution can
be accelerated with the use of a pre-conditioning matrix M.  In this
case the linear equation ‘M^-1 * X = M^-1 * A \ B’ is solved instead.
Typical pre-conditioning matrices are partial factorizations of the
original matrix.

 -- : L = ichol (A)
 -- : L = ichol (A, OPTS)

     Compute the incomplete Cholesky factorization of the sparse square
     matrix A.

     By default, ‘ichol’ uses only the lower triangle of A and produces
     a lower triangular factor L such that L*L’ approximates A.

     The factor given by this routine may be useful as a preconditioner
     for a system of linear equations being solved by iterative methods
     such as PCG (Preconditioned Conjugate Gradient).

     The factorization may be modified by passing options in a structure
     OPTS.  The option name is a field of the structure and the setting
     is the value of field.  Names and specifiers are case sensitive.

     type
          Type of factorization.

          "nofill" (default)
               Incomplete Cholesky factorization with no fill-in
               (IC(0)).

          "ict"
               Incomplete Cholesky factorization with threshold dropping
               (ICT).

     diagcomp
          A non-negative scalar ALPHA for incomplete Cholesky
          factorization of ‘A + ALPHA * diag (diag (A))’ instead of A.
          This can be useful when A is not positive definite.  The
          default value is 0.

     droptol
          A non-negative scalar specifying the drop tolerance for
          factorization if performing ICT.  The default value is 0 which
          produces the complete Cholesky factorization.

          Non-diagonal entries of L are set to 0 unless

          ‘abs (L(i,j)) >= droptol * norm (A(j:end, j), 1)’.

     michol
          Modified incomplete Cholesky factorization:

          "off" (default)
               Row and column sums are not necessarily preserved.

          "on"
               The diagonal of L is modified so that row (and column)
               sums are preserved even when elements have been dropped
               during the factorization.  The relationship preserved is:
               ‘A * e = L * L' * e’, where e is a vector of ones.

     shape

          "lower" (default)
               Use only the lower triangle of A and return a lower
               triangular factor L such that L*L’ approximates A.

          "upper"
               Use only the upper triangle of A and return an upper
               triangular factor U such that ‘U'*U’ approximates A.

     EXAMPLES

     The following problem demonstrates how to factorize a sample
     symmetric positive definite matrix with the full Cholesky
     decomposition and with the incomplete one.

          A = [ 0.37, -0.05,  -0.05,  -0.07;
               -0.05,  0.116,  0.0,   -0.05;
               -0.05,  0.0,    0.116, -0.05;
               -0.07, -0.05,  -0.05,   0.202];
          A = sparse (A);
          nnz (tril (A))
          ans =  9
          L = chol (A, "lower");
          nnz (L)
          ans =  10
          norm (A - L * L', "fro") / norm (A, "fro")
          ans =  1.1993e-16
          opts.type = "nofill";
          L = ichol (A, opts);
          nnz (L)
          ans =  9
          norm (A - L * L', "fro") / norm (A, "fro")
          ans =  0.019736

     Another example for decomposition is a finite difference matrix
     used to solve a boundary value problem on the unit square.

          nx = 400; ny = 200;
          hx = 1 / (nx + 1); hy = 1 / (ny + 1);
          Dxx = spdiags ([ones(nx, 1), -2*ones(nx, 1), ones(nx, 1)],
                         [-1 0 1 ], nx, nx) / (hx ^ 2);
          Dyy = spdiags ([ones(ny, 1), -2*ones(ny, 1), ones(ny, 1)],
                         [-1 0 1 ], ny, ny) / (hy ^ 2);
          A = -kron (Dxx, speye (ny)) - kron (speye (nx), Dyy);
          nnz (tril (A))
          ans =  239400
          opts.type = "nofill";
          L = ichol (A, opts);
          nnz (tril (A))
          ans =  239400
          norm (A - L * L', "fro") / norm (A, "fro")
          ans =  0.062327

     References for implemented algorithms:

     [1] Y. Saad.  "Preconditioning Techniques."  ‘Iterative Methods for
     Sparse Linear Systems’, PWS Publishing Company, 1996.

     [2] M. Jones, P. Plassmann: ‘An Improved Incomplete Cholesky
     Factorization’, 1992.

     See also: *note chol: XREFchol, *note ilu: XREFilu, *note pcg:
     XREFpcg.

 -- : ilu (A)
 -- : ilu (A, OPTS)
 -- : [L, U] = ilu (...)
 -- : [L, U, P] = ilu (...)

     Compute the incomplete LU factorization of the sparse square matrix
     A.

     ‘ilu’ returns a unit lower triangular matrix L, an upper triangular
     matrix U, and optionally a permutation matrix P, such that ‘L*U’
     approximates ‘P*A’.

     The factors given by this routine may be useful as preconditioners
     for a system of linear equations being solved by iterative methods
     such as BICG (BiConjugate Gradients) or GMRES (Generalized Minimum
     Residual Method).

     The factorization may be modified by passing options in a structure
     OPTS.  The option name is a field of the structure and the setting
     is the value of field.  Names and specifiers are case sensitive.

     ‘type’
          Type of factorization.

          "nofill" (default)
               ILU factorization with no fill-in (ILU(0)).

               Additional supported options: ‘milu’.

          "crout"
               Crout version of ILU factorization (ILUC).

               Additional supported options: ‘milu’, ‘droptol’.

          "ilutp"
               ILU factorization with threshold and pivoting.

               Additional supported options: ‘milu’, ‘droptol’, ‘udiag’,
               ‘thresh’.

     ‘droptol’
          A non-negative scalar specifying the drop tolerance for
          factorization.  The default value is 0 which produces the
          complete LU factorization.

          Non-diagonal entries of U are set to 0 unless

          ‘abs (U(i,j)) >= droptol * norm (A(:,j))’.

          Non-diagonal entries of L are set to 0 unless

          ‘abs (L(i,j)) >= droptol * norm (A(:,j))/U(j,j)’.

     ‘milu’
          Modified incomplete LU factorization:

          "row"
               Row-sum modified incomplete LU factorization.  The
               factorization preserves row sums: ‘A * e = L * U * e’,
               where e is a vector of ones.

          "col"
               Column-sum modified incomplete LU factorization.  The
               factorization preserves column sums: ‘e' * A = e' * L *
               U’.

          "off" (default)
               Row and column sums are not necessarily preserved.

     ‘udiag’
          If true, any zeros on the diagonal of the upper triangular
          factor are replaced by the local drop tolerance ‘droptol *
          norm (A(:,j))/U(j,j)’.  The default is false.

     ‘thresh’
          Pivot threshold for factorization.  It can range between 0
          (diagonal pivoting) and 1 (default), where the maximum
          magnitude entry in the column is chosen to be the pivot.

     If ‘ilu’ is called with just one output, the returned matrix is ‘L
     + U - speye (size (A))’, where L is unit lower triangular and U is
     upper triangular.

     With two outputs, ‘ilu’ returns a unit lower triangular matrix L
     and an upper triangular matrix U.  For OPTS.type == "ilutp", one of
     the factors is permuted based on the value of OPTS.milu.  When
     OPTS.milu == "row", U is a column permuted upper triangular factor.
     Otherwise, L is a row-permuted unit lower triangular factor.

     If there are three named outputs and OPTS.milu != "row", P is
     returned such that L and U are incomplete factors of ‘P*A’.  When
     OPTS.milu == "row", P is returned such that L and U are incomplete
     factors of ‘A*P’.

     EXAMPLES

          A = gallery ("neumann", 1600) + speye (1600);
          opts.type = "nofill";
          nnz (A)
          ans = 7840

          nnz (lu (A))
          ans = 126478

          nnz (ilu (A, opts))
          ans = 7840

     This shows that A has 7,840 nonzeros, the complete LU factorization
     has 126,478 nonzeros, and the incomplete LU factorization, with 0
     level of fill-in, has 7,840 nonzeros, the same amount as A.  Taken
     from: <http://www.mathworks.com/help/matlab/ref/ilu.html>

          A = gallery ("wathen", 10, 10);
          b = sum (A, 2);
          tol = 1e-8;
          maxit = 50;
          opts.type = "crout";
          opts.droptol = 1e-4;
          [L, U] = ilu (A, opts);
          x = bicg (A, b, tol, maxit, L, U);
          norm (A * x - b, inf)

     This example uses ILU as preconditioner for a random FEM-Matrix,
     which has a large condition number.  Without L and U BICG would not
     converge.

     See also: *note lu: XREFlu, *note ichol: XREFichol, *note bicg:
     XREFbicg, *note gmres: XREFgmres.


File: octave.info,  Node: Real Life Example,  Prev: Iterative Techniques,  Up: Sparse Matrices

22.4 Real Life Example using Sparse Matrices
============================================

A common application for sparse matrices is in the solution of Finite
Element Models.  Finite element models allow numerical solution of
partial differential equations that do not have closed form solutions,
typically because of the complex shape of the domain.

   In order to motivate this application, we consider the boundary value
Laplace equation.  This system can model scalar potential fields, such
as heat or electrical potential.  Given a medium Omega with boundary
dOmega.  At all points on the dOmega the boundary conditions are known,
and we wish to calculate the potential in Omega.  Boundary conditions
may specify the potential (Dirichlet boundary condition), its normal
derivative across the boundary (Neumann boundary condition), or a
weighted sum of the potential and its derivative (Cauchy boundary
condition).

   In a thermal model, we want to calculate the temperature in Omega and
know the boundary temperature (Dirichlet condition) or heat flux (from
which we can calculate the Neumann condition by dividing by the thermal
conductivity at the boundary).  Similarly, in an electrical model, we
want to calculate the voltage in Omega and know the boundary voltage
(Dirichlet) or current (Neumann condition after diving by the electrical
conductivity).  In an electrical model, it is common for much of the
boundary to be electrically isolated; this is a Neumann boundary
condition with the current equal to zero.

   The simplest finite element models will divide Omega into simplexes
(triangles in 2D, pyramids in 3D).

   The following example creates a simple rectangular 2-D electrically
conductive medium with 10 V and 20 V imposed on opposite sides
(Dirichlet boundary conditions).  All other edges are electrically
isolated.

        node_y = [1;1.2;1.5;1.8;2]*ones(1,11);
        node_x = ones(5,1)*[1,1.05,1.1,1.2, ...
                  1.3,1.5,1.7,1.8,1.9,1.95,2];
        nodes = [node_x(:), node_y(:)];

        [h,w] = size (node_x);
        elems = [];
        for idx = 1:w-1
          widx = (idx-1)*h;
          elems = [elems; ...
            widx+[(1:h-1);(2:h);h+(1:h-1)]'; ...
            widx+[(2:h);h+(2:h);h+(1:h-1)]' ];
        endfor

        E = size (elems,1); # No. of simplices
        N = size (nodes,1); # No. of vertices
        D = size (elems,2); # dimensions+1

   This creates a N-by-2 matrix ‘nodes’ and a E-by-3 matrix ‘elems’ with
values, which define finite element triangles:

       nodes(1:7,:)'
         1.00 1.00 1.00 1.00 1.00 1.05 1.05 ...
         1.00 1.20 1.50 1.80 2.00 1.00 1.20 ...

       elems(1:7,:)'
         1    2    3    4    2    3    4 ...
         2    3    4    5    7    8    9 ...
         6    7    8    9    6    7    8 ...

   Using a first order FEM, we approximate the electrical conductivity
distribution in Omega as constant on each simplex (represented by the
vector ‘conductivity’).  Based on the finite element geometry, we first
calculate a system (or stiffness) matrix for each simplex (represented
as 3-by-3 elements on the diagonal of the element-wise system matrix
‘SE’).  Based on ‘SE’ and a N-by-DE connectivity matrix ‘C’,
representing the connections between simplices and vertices, the global
connectivity matrix ‘S’ is calculated.

       ## Element conductivity
       conductivity = [1*ones(1,16), ...
              2*ones(1,48), 1*ones(1,16)];

       ## Connectivity matrix
       C = sparse ((1:D*E), reshape (elems', ...
              D*E, 1), 1, D*E, N);

       ## Calculate system matrix
       Siidx = floor ([0:D*E-1]'/D) * D * ...
              ones(1,D) + ones(D*E,1)*(1:D) ;
       Sjidx = [1:D*E]'*ones (1,D);
       Sdata = zeros (D*E,D);
       dfact = factorial (D-1);
       for j = 1:E
          a = inv ([ones(D,1), ...
              nodes(elems(j,:), :)]);
          const = conductivity(j) * 2 / ...
              dfact / abs (det (a));
          Sdata(D*(j-1)+(1:D),:) = const * ...
              a(2:D,:)' * a(2:D,:);
       endfor
       ## Element-wise system matrix
       SE = sparse(Siidx,Sjidx,Sdata);
       ## Global system matrix
       S = C'* SE *C;

   The system matrix acts like the conductivity ‘S’ in Ohm’s law ‘S * V
= I’.  Based on the Dirichlet and Neumann boundary conditions, we are
able to solve for the voltages at each vertex ‘V’.

       ## Dirichlet boundary conditions
       D_nodes = [1:5, 51:55];
       D_value = [10*ones(1,5), 20*ones(1,5)];

       V = zeros (N,1);
       V(D_nodes) = D_value;
       idx = 1:N; # vertices without Dirichlet
                  # boundary condns
       idx(D_nodes) = [];

       ## Neumann boundary conditions.  Note that
       ## N_value must be normalized by the
       ## boundary length and element conductivity
       N_nodes = [];
       N_value = [];

       Q = zeros (N,1);
       Q(N_nodes) = N_value;

       V(idx) = S(idx,idx) \ ( Q(idx) - ...
                 S(idx,D_nodes) * V(D_nodes));

   Finally, in order to display the solution, we show each solved
voltage value in the z-axis for each simplex vertex.

       elemx = elems(:,[1,2,3,1])';
       xelems = reshape (nodes(elemx, 1), 4, E);
       yelems = reshape (nodes(elemx, 2), 4, E);
       velems = reshape (V(elemx), 4, E);
       plot3 (xelems,yelems,velems,"k");
       print "grid.eps";


File: octave.info,  Node: Numerical Integration,  Next: Differential Equations,  Prev: Sparse Matrices,  Up: Top

23 Numerical Integration
************************

Octave comes with several built-in functions for computing the integral
of a function numerically (termed quadrature).  These functions all
solve 1-dimensional integration problems.

* Menu:

* Functions of One Variable::
* Orthogonal Collocation::
* Functions of Multiple Variables::


File: octave.info,  Node: Functions of One Variable,  Next: Orthogonal Collocation,  Up: Numerical Integration

23.1 Functions of One Variable
==============================

Octave supports five different adaptive quadrature algorithms for
computing the integral of a function f over the interval from a to b.
These are

‘quad’
     Numerical integration based on Gaussian quadrature.

‘quadv’
     Numerical integration using an adaptive vectorized Simpson’s rule.

‘quadl’
     Numerical integration using an adaptive Lobatto rule.

‘quadgk’
     Numerical integration using an adaptive Gauss-Konrod rule.

‘quadcc’
     Numerical integration using adaptive Clenshaw-Curtis rules.

     In addition, the following functions are also provided:

‘integral’
     A compatibility wrapper function that will choose between ‘quadv’
     and ‘quadgk’ depending on the integrand and options chosen.

‘trapz, cumtrapz’
     Numerical integration of data using the trapezoidal method.

The best quadrature algorithm to use depends on the integrand.  If you
have empirical data, rather than a function, the choice is ‘trapz’ or
‘cumtrapz’.  If you are uncertain about the characteristics of the
integrand, ‘quadcc’ will be the most robust as it can handle
discontinuities, singularities, oscillatory functions, and infinite
intervals.  When the integrand is smooth ‘quadgk’ may be the fastest of
the algorithms.

     Function    Characteristics
----------------------------------------------------------------------------
     quad        Low accuracy with nonsmooth integrands
     quadv       Medium accuracy with smooth integrands
     quadl       Medium accuracy with smooth integrands.  Slower than
                 quadgk.
     quadgk      Medium accuracy (1e-6 – 1e-9) with smooth integrands.
                 Handles oscillatory functions and infinite bounds
     quadcc      Low to High accuracy with nonsmooth/smooth integrands
                 Handles oscillatory functions, singularities, and
                 infinite bounds

   Here is an example of using ‘quad’ to integrate the function

       F(X) = X * sin (1/X) * sqrt (abs (1 - X))

from X = 0 to X = 3.

   This is a fairly difficult integration (plot the function over the
range of integration to see why).

   The first step is to define the function:

     function y = f (x)
       y = x .* sin (1./x) .* sqrt (abs (1 - x));
     endfunction

   Note the use of the ‘dot’ forms of the operators.  This is not
necessary for the ‘quad’ integrator, but is required by the other
integrators.  In any case, it makes it much easier to generate a set of
points for plotting because it is possible to call the function with a
vector argument to produce a vector result.

   The second step is to call quad with the limits of integration:

     [q, ier, nfun, err] = quad ("f", 0, 3)
          ⇒ 1.9819
          ⇒ 1
          ⇒ 5061
          ⇒ 1.1522e-07

   Although ‘quad’ returns a nonzero value for IER, the result is
reasonably accurate (to see why, examine what happens to the result if
you move the lower bound to 0.1, then 0.01, then 0.001, etc.).

   The function "f" can be the string name of a function, a function
handle, or an inline function.  These options make it quite easy to do
integration without having to fully define a function in an m-file.  For
example:

     # Verify integral (x^3) = x^4/4
     f = inline ("x.^3");
     quadgk (f, 0, 1)
          ⇒ 0.25000

     # Verify gamma function = (n-1)! for n = 4
     f = @(x) x.^3 .* exp (-x);
     quadcc (f, 0, Inf)
          ⇒ 6.0000

 -- : Q = quad (F, A, B)
 -- : Q = quad (F, A, B, TOL)
 -- : Q = quad (F, A, B, TOL, SING)
 -- : [Q, IER, NFUN, ERR] = quad (...)
     Numerically evaluate the integral of F from A to B using Fortran
     routines from QUADPACK.

     F is a function handle, inline function, or a string containing the
     name of the function to evaluate.  The function must have the form
     ‘y = f (x)’ where Y and X are scalars.

     A and B are the lower and upper limits of integration.  Either or
     both may be infinite.

     The optional argument TOL is a vector that specifies the desired
     accuracy of the result.  The first element of the vector is the
     desired absolute tolerance, and the second element is the desired
     relative tolerance.  To choose a relative test only, set the
     absolute tolerance to zero.  To choose an absolute test only, set
     the relative tolerance to zero.  Both tolerances default to ‘sqrt
     (eps)’ or approximately 1.5e-8.

     The optional argument SING is a vector of values at which the
     integrand is known to be singular.

     The result of the integration is returned in Q.

     IER contains an integer error code (0 indicates a successful
     integration).

     NFUN indicates the number of function evaluations that were made.

     ERR contains an estimate of the error in the solution.

     The function ‘quad_options’ can set other optional parameters for
     ‘quad’.

     Note: because ‘quad’ is written in Fortran it cannot be called
     recursively.  This prevents its use in integrating over more than
     one variable by routines ‘dblquad’ and ‘triplequad’.

     See also: *note quad_options: XREFquad_options, *note quadv:
     XREFquadv, *note quadl: XREFquadl, *note quadgk: XREFquadgk, *note
     quadcc: XREFquadcc, *note trapz: XREFtrapz, *note dblquad:
     XREFdblquad, *note triplequad: XREFtriplequad.

 -- : quad_options ()
 -- : val = quad_options (OPT)
 -- : quad_options (OPT, VAL)
     Query or set options for the function ‘quad’.

     When called with no arguments, the names of all available options
     and their current values are displayed.

     Given one argument, return the value of the option OPT.

     When called with two arguments, ‘quad_options’ sets the option OPT
     to value VAL.

     Options include

     "absolute tolerance"
          Absolute tolerance; may be zero for pure relative error test.

     "relative tolerance"
          Non-negative relative tolerance.  If the absolute tolerance is
          zero, the relative tolerance must be greater than or equal to
          ‘max (50*eps, 0.5e-28)’.

     "single precision absolute tolerance"
          Absolute tolerance for single precision; may be zero for pure
          relative error test.

     "single precision relative tolerance"
          Non-negative relative tolerance for single precision.  If the
          absolute tolerance is zero, the relative tolerance must be
          greater than or equal to ‘max (50*eps, 0.5e-28)’.

 -- : Q = quadv (F, A, B)
 -- : Q = quadv (F, A, B, TOL)
 -- : Q = quadv (F, A, B, TOL, TRACE)
 -- : Q = quadv (F, A, B, TOL, TRACE, P1, P2, ...)
 -- : [Q, NFUN] = quadv (...)

     Numerically evaluate the integral of F from A to B using an
     adaptive Simpson’s rule.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  ‘quadv’ is a vectorized version
     of ‘quad’ and the function defined by F must accept a scalar or
     vector as input and return a scalar, vector, or array as output.

     A and B are the lower and upper limits of integration.  Both limits
     must be finite.

     The optional argument TOL defines the absolute tolerance used to
     stop the adaptation procedure.  The default value is 1e-6.

     The algorithm used by ‘quadv’ involves recursively subdividing the
     integration interval and applying Simpson’s rule on each
     subinterval.  If TRACE is true then after computing each of these
     partial integrals display: (1) the total number of function
     evaluations, (2) the left end of the subinterval, (3) the length of
     the subinterval, (4) the approximation of the integral over the
     subinterval.

     Additional arguments P1, etc., are passed directly to the function
     F.  To use default values for TOL and TRACE, one may pass empty
     matrices ([]).

     The result of the integration is returned in Q.

     The optional output NFUN indicates the total number of function
     evaluations performed.

     Note: ‘quadv’ is written in Octave’s scripting language and can be
     used recursively in ‘dblquad’ and ‘triplequad’, unlike the ‘quad’
     function.

     See also: *note quad: XREFquad, *note quadl: XREFquadl, *note
     quadgk: XREFquadgk, *note quadcc: XREFquadcc, *note trapz:
     XREFtrapz, *note dblquad: XREFdblquad, *note triplequad:
     XREFtriplequad, *note integral: XREFintegral, *note integral2:
     XREFintegral2, *note integral3: XREFintegral3.

 -- : Q = quadl (F, A, B)
 -- : Q = quadl (F, A, B, TOL)
 -- : Q = quadl (F, A, B, TOL, TRACE)
 -- : Q = quadl (F, A, B, TOL, TRACE, P1, P2, ...)
 -- : [Q, NFUN] = quadl (...)

     Numerically evaluate the integral of F from A to B using an
     adaptive Lobatto rule.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be
     vectorized and return a vector of output values when given a vector
     of input values.

     A and B are the lower and upper limits of integration.  Both limits
     must be finite.

     The optional argument TOL defines the absolute tolerance with which
     to perform the integration.  The default value is 1e-6.

     The algorithm used by ‘quadl’ involves recursively subdividing the
     integration interval.  If TRACE is defined then for each
     subinterval display: (1) the total number of function evaluations,
     (2) the left end of the subinterval, (3) the length of the
     subinterval, (4) the approximation of the integral over the
     subinterval.

     Additional arguments P1, etc., are passed directly to the function
     F.  To use default values for TOL and TRACE, one may pass empty
     matrices ([]).

     The result of the integration is returned in Q.

     The optional output NFUN indicates the total number of function
     evaluations performed.

     Reference: W. Gander and W. Gautschi, ‘Adaptive Quadrature -
     Revisited’, BIT Vol.  40, No.  1, March 2000, pp.  84–101.
     <https://www.inf.ethz.ch/personal/gander/>

     See also: *note quad: XREFquad, *note quadv: XREFquadv, *note
     quadgk: XREFquadgk, *note quadcc: XREFquadcc, *note trapz:
     XREFtrapz, *note dblquad: XREFdblquad, *note triplequad:
     XREFtriplequad, *note integral: XREFintegral, *note integral2:
     XREFintegral2, *note integral3: XREFintegral3.

 -- : Q = quadgk (F, A, B)
 -- : Q = quadgk (F, A, B, ABSTOL)
 -- : Q = quadgk (F, A, B, ABSTOL, TRACE)
 -- : Q = quadgk (F, A, B, PROP, VAL, ...)
 -- : [Q, ERR] = quadgk (...)

     Numerically evaluate the integral of F from A to B using adaptive
     Gauss-Konrod quadrature.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be
     vectorized and return a vector of output values when given a vector
     of input values.

     A and B are the lower and upper limits of integration.  Either or
     both limits may be infinite or contain weak end singularities.
     Variable transformation will be used to treat any infinite
     intervals and weaken the singularities.  For example:

          quadgk (@(x) 1 ./ (sqrt (x) .* (x + 1)), 0, Inf)

     Note that the formulation of the integrand uses the
     element-by-element operator ‘./’ and all user functions to ‘quadgk’
     should do the same.

     The optional argument TOL defines the absolute tolerance used to
     stop the integration procedure.  The default value is 1e-10 (1e-5
     for single).

     The algorithm used by ‘quadgk’ involves subdividing the integration
     interval and evaluating each subinterval.  If TRACE is true then
     after computing each of these partial integrals display: (1) the
     number of subintervals at this step, (2) the current estimate of
     the error ERR, (3) the current estimate for the integral Q.

     Alternatively, properties of ‘quadgk’ can be passed to the function
     as pairs "PROP", VAL.  Valid properties are

     ‘AbsTol’
          Define the absolute error tolerance for the quadrature.  The
          default absolute tolerance is 1e-10 (1e-5 for single).

     ‘RelTol’
          Define the relative error tolerance for the quadrature.  The
          default relative tolerance is 1e-6 (1e-4 for single).

     ‘MaxIntervalCount’
          ‘quadgk’ initially subdivides the interval on which to perform
          the quadrature into 10 intervals.  Subintervals that have an
          unacceptable error are subdivided and re-evaluated.  If the
          number of subintervals exceeds 650 subintervals at any point
          then a poor convergence is signaled and the current estimate
          of the integral is returned.  The property "MaxIntervalCount"
          can be used to alter the number of subintervals that can exist
          before exiting.

     ‘WayPoints’
          Discontinuities in the first derivative of the function to
          integrate can be flagged with the "WayPoints" property.  This
          forces the ends of a subinterval to fall on the breakpoints of
          the function and can result in significantly improved
          estimation of the error in the integral, faster computation,
          or both.  For example,

               quadgk (@(x) abs (1 - x.^2), 0, 2, "Waypoints", 1)

          signals the breakpoint in the integrand at ‘X = 1’.

     ‘Trace’
          If logically true ‘quadgk’ prints information on the
          convergence of the quadrature at each iteration.

     If any of A, B, or WAYPOINTS is complex then the quadrature is
     treated as a contour integral along a piecewise continuous path
     defined by the above.  In this case the integral is assumed to have
     no edge singularities.  For example,

          quadgk (@(z) log (z), 1+1i, 1+1i, "WayPoints",
                  [1-1i, -1,-1i, -1+1i])

     integrates ‘log (z)’ along the square defined by ‘[1+1i, 1-1i,
     -1-1i, -1+1i]’.

     The result of the integration is returned in Q.

     ERR is an approximate bound on the error in the integral ‘abs (Q -
     I)’, where I is the exact value of the integral.

     Reference: L.F. Shampine, ‘"Vectorized adaptive quadrature in
     MATLAB"’, Journal of Computational and Applied Mathematics, pp.
     131–140, Vol 211, Issue 2, Feb 2008.

     See also: *note quad: XREFquad, *note quadv: XREFquadv, *note
     quadl: XREFquadl, *note quadcc: XREFquadcc, *note trapz: XREFtrapz,
     *note dblquad: XREFdblquad, *note triplequad: XREFtriplequad, *note
     integral: XREFintegral, *note integral2: XREFintegral2, *note
     integral3: XREFintegral3.

 -- : Q = quadcc (F, A, B)
 -- : Q = quadcc (F, A, B, TOL)
 -- : Q = quadcc (F, A, B, TOL, SING)
 -- : [Q, ERR, NR_POINTS] = quadcc (...)
     Numerically evaluate the integral of F from A to B using
     doubly-adaptive Clenshaw-Curtis quadrature.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be
     vectorized and must return a vector of output values if given a
     vector of input values.  For example,

          f = @(x) x .* sin (1./x) .* sqrt (abs (1 - x));

     which uses the element-by-element “dot” form for all operators.

     A and B are the lower and upper limits of integration.  Either or
     both limits may be infinite.  ‘quadcc’ handles an infinite limit by
     substituting the variable of integration with ‘x = tan (pi/2*u)’.

     The optional argument TOL is a 1- or 2-element vector that
     specifies the desired accuracy of the result.  The first element of
     the vector is the desired absolute tolerance, and the second
     element is the desired relative tolerance.  To choose a relative
     test only, set the absolute tolerance to zero.  To choose an
     absolute test only, set the relative tolerance to zero.  The
     default absolute tolerance is 1e-10 (1e-5 for single), and the
     default relative tolerance is 1e-6 (1e-4 for single).

     The optional argument SING contains a list of points where the
     integrand has known singularities, or discontinuities in any of its
     derivatives, inside the integration interval.  For the example
     above, which has a discontinuity at x=1, the call to ‘quadcc’ would
     be as follows

          int = quadcc (f, a, b, [], [ 1 ]);

     The result of the integration is returned in Q.

     ERR is an estimate of the absolute integration error.

     NR_POINTS is the number of points at which the integrand was
     evaluated.

     If the adaptive integration did not converge, the value of ERR will
     be larger than the requested tolerance.  Therefore, it is
     recommended to verify this value for difficult integrands.

     ‘quadcc’ is capable of dealing with non-numeric values of the
     integrand such as ‘NaN’ or ‘Inf’.  If the integral diverges, and
     ‘quadcc’ detects this, then a warning is issued and ‘Inf’ or ‘-Inf’
     is returned.

     Note: ‘quadcc’ is a general purpose quadrature algorithm and, as
     such, may be less efficient for a smooth or otherwise well-behaved
     integrand than other methods such as ‘quadgk’.

     The algorithm uses Clenshaw-Curtis quadrature rules of increasing
     degree in each interval and bisects the interval if either the
     function does not appear to be smooth or a rule of maximum degree
     has been reached.  The error estimate is computed from the L2-norm
     of the difference between two successive interpolations of the
     integrand over the nodes of the respective quadrature rules.

     Implementation Note: For Octave versions ≤ 4.2, ‘quadcc’ accepted a
     single tolerance argument which specified the relative tolerance.
     For versions 4.4 and 5, ‘quadcc’ will issue a warning when called
     with a single tolerance argument indicating that the meaning of
     this input has changed from relative tolerance to absolute
     tolerance.  The warning ID for this message is
     "Octave:quadcc:RelTol-conversion".  The warning may be disabled
     with ‘warning ("off", "Octave:quadcc:RelTol-conversion")’.

     Reference: P. Gonnet, ‘Increasing the Reliability of Adaptive
     Quadrature Using Explicit Interpolants’, ACM Transactions on
     Mathematical Software, Vol.  37, Issue 3, Article No.  3, 2010.

     See also: *note quad: XREFquad, *note quadv: XREFquadv, *note
     quadl: XREFquadl, *note quadgk: XREFquadgk, *note trapz: XREFtrapz,
     *note dblquad: XREFdblquad, *note triplequad: XREFtriplequad.

 -- : Q = integral (F, A, B)
 -- : Q = integral (F, A, B, PROP, VAL, ...)

     Numerically evaluate the integral of F from A to B using adaptive
     quadrature.

     ‘integral’ is a wrapper for ‘quadcc’ (general scalar integrands),
     ‘quadgk’ (integrals with specified integration paths), and ‘quadv’
     (array-valued integrands) that is intended to provide MATLAB
     compatibility.  More control of the numerical integration may be
     achievable by calling the various quadrature functions directly.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be
     vectorized and return a vector of output values when given a vector
     of input values.

     A and B are the lower and upper limits of integration.  Either or
     both limits may be infinite or contain weak end singularities.  If
     either or both limits are complex, ‘integral’ will perform a
     straight line path integral.  Alternatively, a complex domain path
     can be specified using the "Waypoints" option (see below).

     Additional optional parameters can be specified using "PROPERTY",
     VALUE pairs.  Valid properties are:

     ‘Waypoints’
          Specifies points to be used in defining subintervals of the
          quadrature algorithm, or if A, B, or WAYPOINTS are complex
          then the quadrature is calculated as a contour integral along
          a piecewise continuous path.  For more detail see ‘quadgk’.

     ‘ArrayValued’
          ‘integral’ expects F to return a scalar value unless
          ARRAYVALUED is specified as true.  This option will cause
          ‘integral’ to perform the integration over the entire array
          and return Q with the same dimensions as returned by F.  For
          more detail see ‘quadv’.

     ‘AbsTol’
          Define the absolute error tolerance for the quadrature.  The
          default absolute tolerance is 1e-10 (1e-5 for single).

     ‘RelTol’
          Define the relative error tolerance for the quadrature.  The
          default relative tolerance is 1e-6 (1e-4 for single).

     Adaptive quadrature is used to minimize the estimate of error until
     the following is satisfied:

            ERROR <= max (ABSTOL, RELTOL*|Q|).

     Known MATLAB incompatibilities:

       1. If tolerances are left unspecified, and any integration limits
          or waypoints are of type ‘single’, then Octave’s integral
          functions automatically reduce the default absolute and
          relative error tolerances as specified above.  If tighter
          tolerances are desired they must be specified.  MATLAB leaves
          the tighter tolerances appropriate for ‘double’ inputs in
          place regardless of the class of the integration limits.

       2. As a consequence of using ‘quadcc’, ‘quadgk’, and ‘quadv’,
          certain option combinations are not supported.  Currently,
          "ArrayValued" cannot be combined with "RelTol" or "Waypoints".

     See also: *note integral2: XREFintegral2, *note integral3:
     XREFintegral3, *note quad: XREFquad, *note quadgk: XREFquadgk,
     *note quadv: XREFquadv, *note quadl: XREFquadl, *note quadcc:
     XREFquadcc, *note trapz: XREFtrapz, *note dblquad: XREFdblquad,
     *note triplequad: XREFtriplequad.

   Sometimes one does not have the function, but only the raw (x, y)
points from which to perform an integration.  This can occur when
collecting data in an experiment.  The ‘trapz’ function can integrate
these values as shown in the following example where "data" has been
collected on the cosine function over the range [0, pi/2).

     x = 0:0.1:pi/2;  # Uniformly spaced points
     y = cos (x);
     trapz (x, y)
          ⇒ 0.99666

   The answer is reasonably close to the exact value of 1.  Ordinary
quadrature is sensitive to the characteristics of the integrand.
Empirical integration depends not just on the integrand, but also on the
particular points chosen to represent the function.  Repeating the
example above with the sine function over the range [0, pi/2) produces
far inferior results.

     x = 0:0.1:pi/2;  # Uniformly spaced points
     y = sin (x);
     trapz (x, y)
          ⇒ 0.92849

   However, a slightly different choice of data points can change the
result significantly.  The same integration, with the same number of
points, but spaced differently produces a more accurate answer.

     x = linspace (0, pi/2, 16);  # Uniformly spaced, but including endpoint
     y = sin (x);
     trapz (x, y)
          ⇒ 0.99909

   In general there may be no way of knowing the best distribution of
points ahead of time.  Or the points may come from an experiment where
there is no freedom to select the best distribution.  In any case, one
must remain aware of this issue when using ‘trapz’.

 -- : Q = trapz (Y)
 -- : Q = trapz (X, Y)
 -- : Q = trapz (..., DIM)

     Numerically evaluate the integral of points Y using the trapezoidal
     method.

     ‘trapz (Y)’ computes the integral of Y along the first
     non-singleton dimension.  When the argument X is omitted an equally
     spaced X vector with unit spacing (1) is assumed.  ‘trapz (X, Y)’
     evaluates the integral with respect to the spacing in X and the
     values in Y.  This is useful if the points in Y have been sampled
     unevenly.

     If the optional DIM argument is given, operate along this
     dimension.

     Application Note: If X is not specified then unit spacing will be
     used.  To scale the integral to the correct value you must multiply
     by the actual spacing value (deltaX). As an example, the integral
     of x^3 over the range [0, 1] is x^4/4 or 0.25.  The following code
     uses ‘trapz’ to calculate the integral in three different ways.

          x = 0:0.1:1;
          y = x.^3;
          q = trapz (y)
            ⇒ q = 2.525   # No scaling
          q * 0.1
            ⇒ q = 0.2525  # Approximation to integral by scaling
          trapz (x, y)
            ⇒ q = 0.2525  # Same result by specifying X

     See also: *note cumtrapz: XREFcumtrapz.

 -- : Q = cumtrapz (Y)
 -- : Q = cumtrapz (X, Y)
 -- : Q = cumtrapz (..., DIM)
     Cumulative numerical integration of points Y using the trapezoidal
     method.

     ‘cumtrapz (Y)’ computes the cumulative integral of Y along the
     first non-singleton dimension.  Where ‘trapz’ reports only the
     overall integral sum, ‘cumtrapz’ reports the current partial sum
     value at each point of Y.

     When the argument X is omitted an equally spaced X vector with unit
     spacing (1) is assumed.  ‘cumtrapz (X, Y)’ evaluates the integral
     with respect to the spacing in X and the values in Y.  This is
     useful if the points in Y have been sampled unevenly.

     If the optional DIM argument is given, operate along this
     dimension.

     Application Note: If X is not specified then unit spacing will be
     used.  To scale the integral to the correct value you must multiply
     by the actual spacing value (deltaX).

     See also: *note trapz: XREFtrapz, *note cumsum: XREFcumsum.


File: octave.info,  Node: Orthogonal Collocation,  Next: Functions of Multiple Variables,  Prev: Functions of One Variable,  Up: Numerical Integration

23.2 Orthogonal Collocation
===========================

 -- : [R, AMAT, BMAT, Q] = colloc (N, "left", "right")
     Compute derivative and integral weight matrices for orthogonal
     collocation.

     Reference: J. Villadsen, M. L. Michelsen, ‘Solution of Differential
     Equation Models by Polynomial Approximation’.

   Here is an example of using ‘colloc’ to generate weight matrices for
solving the second order differential equation U’ - ALPHA * U” = 0 with
the boundary conditions U(0) = 0 and U(1) = 1.

   First, we can generate the weight matrices for N points (including
the endpoints of the interval), and incorporate the boundary conditions
in the right hand side (for a specific value of ALPHA).

     n = 7;
     alpha = 0.1;
     [r, a, b] = colloc (n-2, "left", "right");
     at = a(2:n-1,2:n-1);
     bt = b(2:n-1,2:n-1);
     rhs = alpha * b(2:n-1,n) - a(2:n-1,n);

   Then the solution at the roots R is

     u = [ 0; (at - alpha * bt) \ rhs; 1]
          ⇒ [ 0.00; 0.004; 0.01 0.00; 0.12; 0.62; 1.00 ]


File: octave.info,  Node: Functions of Multiple Variables,  Prev: Orthogonal Collocation,  Up: Numerical Integration

23.3 Functions of Multiple Variables
====================================

Octave includes several functions for computing the integral of
functions of multiple variables.  This procedure can generally be
performed by creating a function that integrates f with respect to x,
and then integrates that function with respect to y.  This procedure can
be performed manually using the following example which integrates the
function:

     f(x, y) = sin(pi*x*y) * sqrt(x*y)

   for x and y between 0 and 1.

   Using ‘quadgk’ in the example below, a double integration can be
performed.  (Note that any of the 1-D quadrature functions can be used
in this fashion except for ‘quad’ since it is written in Fortran and
cannot be called recursively.)

     function q = g(y)
       q = ones (size (y));
       for i = 1:length (y)
         f = @(x) sin (pi*x.*y(i)) .* sqrt (x.*y(i));
         q(i) = quadgk (f, 0, 1);
       endfor
     endfunction

     I = quadgk ("g", 0, 1)
           ⇒ 0.30022

   The algorithm above is implemented in the function ‘dblquad’ for
integrals over two variables.  The 3-D equivalent of this process is
implemented in ‘triplequad’ for integrals over three variables.  As an
example, the result above can be replicated with a call to ‘dblquad’ as
shown below.

     I = dblquad (@(x, y) sin (pi*x.*y) .* sqrt (x.*y), 0, 1, 0, 1)
           ⇒ 0.30022

 -- : dblquad (F, XA, XB, YA, YB)
 -- : dblquad (F, XA, XB, YA, YB, TOL)
 -- : dblquad (F, XA, XB, YA, YB, TOL, QUADF)
 -- : dblquad (F, XA, XB, YA, YB, TOL, QUADF, ...)
     Numerically evaluate the double integral of F.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must have the
     form z = f(x,y) where X is a vector and Y is a scalar.  It should
     return a vector of the same length and orientation as X.

     XA, YA and XB, YB are the lower and upper limits of integration for
     x and y respectively.  The underlying integrator determines whether
     infinite bounds are accepted.

     The optional argument TOL defines the absolute tolerance used to
     integrate each sub-integral.  The default value is 1e-6.

     The optional argument QUADF specifies which underlying integrator
     function to use.  Any choice but ‘quad’ is available and the
     default is ‘quadcc’.

     Additional arguments, are passed directly to F.  To use the default
     value for TOL or QUADF one may pass ’:’ or an empty matrix ([]).

     See also: *note integral2: XREFintegral2, *note integral3:
     XREFintegral3, *note triplequad: XREFtriplequad, *note quad:
     XREFquad, *note quadv: XREFquadv, *note quadl: XREFquadl, *note
     quadgk: XREFquadgk, *note quadcc: XREFquadcc, *note trapz:
     XREFtrapz.

 -- : triplequad (F, XA, XB, YA, YB, ZA, ZB)
 -- : triplequad (F, XA, XB, YA, YB, ZA, ZB, TOL)
 -- : triplequad (F, XA, XB, YA, YB, ZA, ZB, TOL, QUADF)
 -- : triplequad (F, XA, XB, YA, YB, ZA, ZB, TOL, QUADF, ...)
     Numerically evaluate the triple integral of F.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must have the
     form w = f(x,y,z) where either X or Y is a vector and the remaining
     inputs are scalars.  It should return a vector of the same length
     and orientation as X or Y.

     XA, YA, ZA and XB, YB, ZB are the lower and upper limits of
     integration for x, y, and z respectively.  The underlying
     integrator determines whether infinite bounds are accepted.

     The optional argument TOL defines the absolute tolerance used to
     integrate each sub-integral.  The default value is 1e-6.

     The optional argument QUADF specifies which underlying integrator
     function to use.  Any choice but ‘quad’ is available and the
     default is ‘quadcc’.

     Additional arguments, are passed directly to F.  To use the default
     value for TOL or QUADF one may pass ’:’ or an empty matrix ([]).

     See also: *note integral3: XREFintegral3, *note integral2:
     XREFintegral2, *note dblquad: XREFdblquad, *note quad: XREFquad,
     *note quadv: XREFquadv, *note quadl: XREFquadl, *note quadgk:
     XREFquadgk, *note quadcc: XREFquadcc, *note trapz: XREFtrapz.

   The recursive algorithm for quadrature presented above is referred to
as "iterated".  A separate 2-D integration method is implemented in the
function ‘quad2d’.  This function performs a "tiled" integration by
subdividing the integration domain into rectangular regions and
performing separate integrations over those domains.  The domains are
further subdivided in areas requiring refinement to reach the desired
numerical accuracy.  For certain functions this method can be faster
than the 2-D iteration used in the other functions above.

 -- : Q = quad2d (F, XA, XB, YA, YB)
 -- : Q = quad2d (F, XA, XB, YA, YB, PROP, VAL, ...)
 -- : [Q, ERR, ITER] = quad2d (...)

     Numerically evaluate the two-dimensional integral of F using
     adaptive quadrature over the two-dimensional domain defined by XA,
     XB, YA, YB using tiled integration.  Additionally, YA and YB may be
     scalar functions of X, allowing for the integration over
     non-rectangular domains.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be of the
     form z = f(x,y) where X is a vector and Y is a scalar.  It should
     return a vector of the same length and orientation as X.

     Additional optional parameters can be specified using "PROPERTY",
     VALUE pairs.  Valid properties are:

     ‘AbsTol’
          Define the absolute error tolerance for the quadrature.  The
          default value is 1e-10 (1e-5 for single).

     ‘RelTol’
          Define the relative error tolerance for the quadrature.  The
          default value is 1e-6 (1e-4 for single).

     ‘MaxFunEvals’
          The maximum number of function calls to the vectorized
          function F.  The default value is 5000.

     ‘Singular’
          Enable/disable transforms to weaken singularities on the edge
          of the integration domain.  The default value is TRUE.

     ‘Vectorized’
          Option to disable vectorized integration, forcing Octave to
          use only scalar inputs when calling the integrand.  The
          default value is FALSE.

     ‘FailurePlot’
          If ‘quad2d’ fails to converge to the desired error tolerance
          before MaxFunEvals is reached, a plot of the areas that still
          need refinement is created.  The default value is FALSE.

     Adaptive quadrature is used to minimize the estimate of error until
     the following is satisfied:

                  ERROR <= max (ABSTOL, RELTOL*|Q|)

     The optional output ERR is an approximate bound on the error in the
     integral ‘abs (Q - I)’, where I is the exact value of the integral.
     The optional output ITER is the number of vectorized function calls
     to the function F that were used.

     Example 1 : integrate a rectangular region in x-y plane

          F = @(X,Y) 2*ones (size (X));
          Q = quad2d (F, 0, 1, 0, 1)
            ⇒ Q =  2

     The result is a volume, which for this constant-value integrand, is
     just ‘LENGTH * WIDTH * HEIGHT’.

     Example 2 : integrate a triangular region in x-y plane

          F = @(X,Y) 2*ones (size (X));
          YMAX = @(X) 1 - X;
          Q = quad2d (F, 0, 1, 0, YMAX)
            ⇒ Q =  1

     The result is a volume, which for this constant-value integrand, is
     the Triangle Area x Height or ‘1/2 * BASE * WIDTH * HEIGHT’.

     Programming Notes: If there are singularities within the
     integration region it is best to split the integral and place the
     singularities on the boundary.

     Known MATLAB incompatibility: If tolerances are left unspecified,
     and any integration limits are of type ‘single’, then Octave’s
     integral functions automatically reduce the default absolute and
     relative error tolerances as specified above.  If tighter
     tolerances are desired they must be specified.  MATLAB leaves the
     tighter tolerances appropriate for ‘double’ inputs in place
     regardless of the class of the integration limits.

     Reference: L.F. Shampine, ‘MATLAB program for quadrature in 2D’,
     Applied Mathematics and Computation, pp.  266–274, Vol 1, 2008.

     See also: *note integral2: XREFintegral2, *note dblquad:
     XREFdblquad, *note integral: XREFintegral, *note quad: XREFquad,
     *note quadgk: XREFquadgk, *note quadv: XREFquadv, *note quadl:
     XREFquadl, *note quadcc: XREFquadcc, *note trapz: XREFtrapz, *note
     integral3: XREFintegral3, *note triplequad: XREFtriplequad.

   Finally, the functions ‘integral2’ and ‘integral3’ are provided as
general 2-D and 3-D integration functions.  They will auto-select
between iterated and tiled integration methods and, unlike ‘dblquad’ and
‘triplequad’, will work with non-rectangular integration domains.

 -- : Q = integral2 (F, XA, XB, YA, YB)
 -- : Q = integral2 (F, XA, XB, YA, YB, PROP, VAL, ...)
 -- : [Q, ERR] = integral2 (...)

     Numerically evaluate the two-dimensional integral of F using
     adaptive quadrature over the two-dimensional domain defined by XA,
     XB, YA, YB (scalars may be finite or infinite).  Additionally, YA
     and YB may be scalar functions of X, allowing for integration over
     non-rectangular domains.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be of the
     form z = f(x,y) where X is a vector and Y is a scalar.  It should
     return a vector of the same length and orientation as X.

     Additional optional parameters can be specified using "PROPERTY",
     VALUE pairs.  Valid properties are:

     ‘AbsTol’
          Define the absolute error tolerance for the quadrature.  The
          default value is 1e-10 (1e-5 for single).

     ‘RelTol’
          Define the relative error tolerance for the quadrature.  The
          default value is 1e-6 (1e-4 for single).

     ‘Method’
          Specify the two-dimensional integration method to be used,
          with valid options being "auto" (default), "tiled", or
          "iterated".  When using "auto", Octave will choose the "tiled"
          method unless any of the integration limits are infinite.

     ‘Vectorized’
          Enable or disable vectorized integration.  A value of ‘false’
          forces Octave to use only scalar inputs when calling the
          integrand, which enables integrands f(x,y) that have not been
          vectorized and only accept X and Y as scalars to be used.  The
          default value is ‘true’.

     Adaptive quadrature is used to minimize the estimate of error until
     the following is satisfied:

                  ERROR <= max (ABSTOL, RELTOL*|Q|)

     ERR is an approximate bound on the error in the integral ‘abs (Q -
     I)’, where I is the exact value of the integral.

     Example 1 : integrate a rectangular region in x-y plane

          F = @(X,Y) 2*ones (size (X));
          Q = integral2 (F, 0, 1, 0, 1)
            ⇒ Q =  2

     The result is a volume, which for this constant-value integrand, is
     just ‘LENGTH * WIDTH * HEIGHT’.

     Example 2 : integrate a triangular region in x-y plane

          F = @(X,Y) 2*ones (size (X));
          YMAX = @(X) 1 - X;
          Q = integral2 (F, 0, 1, 0, YMAX)
            ⇒ Q =  1

     The result is a volume, which for this constant-value integrand, is
     the Triangle Area x Height or ‘1/2 * BASE * WIDTH * HEIGHT’.

     Programming Notes: If there are singularities within the
     integration region it is best to split the integral and place the
     singularities on the boundary.

     Known MATLAB incompatibility: If tolerances are left unspecified,
     and any integration limits are of type ‘single’, then Octave’s
     integral functions automatically reduce the default absolute and
     relative error tolerances as specified above.  If tighter
     tolerances are desired they must be specified.  MATLAB leaves the
     tighter tolerances appropriate for ‘double’ inputs in place
     regardless of the class of the integration limits.

     Reference: L.F. Shampine, ‘MATLAB program for quadrature in 2D’,
     Applied Mathematics and Computation, pp.  266–274, Vol 1, 2008.

     See also: *note quad2d: XREFquad2d, *note dblquad: XREFdblquad,
     *note integral: XREFintegral, *note quad: XREFquad, *note quadgk:
     XREFquadgk, *note quadv: XREFquadv, *note quadl: XREFquadl, *note
     quadcc: XREFquadcc, *note trapz: XREFtrapz, *note integral3:
     XREFintegral3, *note triplequad: XREFtriplequad.

 -- : Q = integral3 (F, XA, XB, YA, YB, ZA, ZB)
 -- : Q = integral3 (F, XA, XB, YA, YB, ZA, ZB, PROP, VAL, ...)

     Numerically evaluate the three-dimensional integral of F using
     adaptive quadrature over the three-dimensional domain defined by
     XA, XB, YA, YB, ZA, ZB (scalars may be finite or infinite).
     Additionally, YA and YB may be scalar functions of X and ZA, and ZB
     maybe be scalar functions of X and Y, allowing for integration over
     non-rectangular domains.

     F is a function handle, inline function, or string containing the
     name of the function to evaluate.  The function F must be of the
     form z = f(x,y) where X is a vector and Y is a scalar.  It should
     return a vector of the same length and orientation as X.

     Additional optional parameters can be specified using "PROPERTY",
     VALUE pairs.  Valid properties are:

     ‘AbsTol’
          Define the absolute error tolerance for the quadrature.  The
          default value is 1e-10 (1e-5 for single).

     ‘RelTol’
          Define the relative error tolerance for the quadrature.  The
          default value is 1e-6 (1e-4 for single).

     ‘Method’
          Specify the two-dimensional integration method to be used,
          with valid options being "auto" (default), "tiled", or
          "iterated".  When using "auto", Octave will choose the "tiled"
          method unless any of the integration limits are infinite.

     ‘Vectorized’
          Enable or disable vectorized integration.  A value of ‘false’
          forces Octave to use only scalar inputs when calling the
          integrand, which enables integrands f(x,y) that have not been
          vectorized and only accept X and Y as scalars to be used.  The
          default value is ‘true’.

     Adaptive quadrature is used to minimize the estimate of error until
     the following is satisfied:

                  ERROR <= max (ABSTOL, RELTOL*|Q|)

     ERR is an approximate bound on the error in the integral ‘abs (Q -
     I)’, where I is the exact value of the integral.

     Example 1 : integrate over a rectangular volume

          F = @(X,Y,Z) ones (size (X));
          Q = integral3 (F, 0, 1, 0, 1, 0, 1)
            ⇒ Q =  1

     For this constant-value integrand, the result is a volume which is
     just ‘LENGTH * WIDTH * HEIGHT’.

     Example 2 : integrate over a spherical volume

          F = @(X,Y) ones (size (X));
          YMAX = @(X) sqrt (1 - X.^2);
          ZMAX = @(X) sqrt (1 - X.^2 - Y.^2);
          Q = integral3 (F, 0, 1, 0, YMAX)
            ⇒ Q =  0.52360

     For this constant-value integrand, the result is a volume which is
     1/8th of a unit sphere or ‘1/8 * 4/3 * pi’.

     Programming Notes: If there are singularities within the
     integration region it is best to split the integral and place the
     singularities on the boundary.

     Known MATLAB incompatibility: If tolerances are left unspecified,
     and any integration limits are of type ‘single’, then Octave’s
     integral functions automatically reduce the default absolute and
     relative error tolerances as specified above.  If tighter
     tolerances are desired they must be specified.  MATLAB leaves the
     tighter tolerances appropriate for ‘double’ inputs in place
     regardless of the class of the integration limits.

     Reference: L.F. Shampine, ‘MATLAB program for quadrature in 2D’,
     Applied Mathematics and Computation, pp.  266–274, Vol 1, 2008.

     See also: *note triplequad: XREFtriplequad, *note integral:
     XREFintegral, *note quad: XREFquad, *note quadgk: XREFquadgk, *note
     quadv: XREFquadv, *note quadl: XREFquadl, *note quadcc: XREFquadcc,
     *note trapz: XREFtrapz, *note integral2: XREFintegral2, *note
     quad2d: XREFquad2d, *note dblquad: XREFdblquad.

   The above integrations can be fairly slow, and that problem increases
exponentially with the dimensionality of the integral.  Another possible
solution for 2-D integration is to use Orthogonal Collocation as
described in the previous section (*note Orthogonal Collocation::).  The
integral of a function f(x,y) for x and y between 0 and 1 can be
approximated using n points by the sum over ‘i=1:n’ and ‘j=1:n’ of
‘q(i)*q(j)*f(r(i),r(j))’, where q and r is as returned by ‘colloc (n)’.
The generalization to more than two variables is straight forward.  The
following code computes the studied integral using n=8 points.

     f = @(x,y) sin (pi*x*y') .* sqrt (x*y');
     n = 8;
     [t, ~, ~, q] = colloc (n);
     I = q'*f(t,t)*q;
           ⇒ 0.30022

It should be noted that the number of points determines the quality of
the approximation.  If the integration needs to be performed between a
and b, instead of 0 and 1, then a change of variables is needed.


File: octave.info,  Node: Differential Equations,  Next: Optimization,  Prev: Numerical Integration,  Up: Top

24 Differential Equations
*************************

Octave has built-in functions for solving ordinary differential
equations, and differential-algebraic equations.  All solvers are based
on reliable ODE routines written in Fortran.

* Menu:

* Ordinary Differential Equations::
* Differential-Algebraic Equations::


File: octave.info,  Node: Ordinary Differential Equations,  Next: Differential-Algebraic Equations,  Up: Differential Equations

24.1 Ordinary Differential Equations
====================================

The function ‘lsode’ can be used to solve ODEs of the form

     dx
     -- = f (x, t)
     dt

using Hindmarsh’s ODE solver LSODE.

 -- : [X, ISTATE, MSG] = lsode (FCN, X_0, T)
 -- : [X, ISTATE, MSG] = lsode (FCN, X_0, T, T_CRIT)
     Ordinary Differential Equation (ODE) solver.

     The set of differential equations to solve is

          dx
          -- = f (x, t)
          dt

     with

          x(t_0) = x_0

     The solution is returned in the matrix X, with each row
     corresponding to an element of the vector T.  The first element of
     T should be t_0 and should correspond to the initial state of the
     system X_0, so that the first row of the output is X_0.

     The first argument, FCN, is a string, inline, or function handle
     that names the function f to call to compute the vector of right
     hand sides for the set of equations.  The function must have the
     form

          XDOT = f (X, T)

     in which XDOT and X are vectors and T is a scalar.

     If FCN is a two-element string array or a two-element cell array of
     strings, inline functions, or function handles, the first element
     names the function f described above, and the second element names
     a function to compute the Jacobian of f.  The Jacobian function
     must have the form

          JAC = j (X, T)

     in which JAC is the matrix of partial derivatives

                       | df_1  df_1       df_1 |
                       | ----  ----  ...  ---- |
                       | dx_1  dx_2       dx_N |
                       |                       |
                       | df_2  df_2       df_2 |
                       | ----  ----  ...  ---- |
                df_i   | dx_1  dx_2       dx_N |
          jac = ---- = |                       |
                dx_j   |  .    .     .    .    |
                       |  .    .      .   .    |
                       |  .    .       .  .    |
                       |                       |
                       | df_N  df_N       df_N |
                       | ----  ----  ...  ---- |
                       | dx_1  dx_2       dx_N |

     The second argument specifies the initial state of the system x_0.
     The third argument is a vector, T, specifying the time values for
     which a solution is sought.

     The fourth argument is optional, and may be used to specify a set
     of times that the ODE solver should not integrate past.  It is
     useful for avoiding difficulties with singularities and points
     where there is a discontinuity in the derivative.

     After a successful computation, the value of ISTATE will be 2
     (consistent with the Fortran version of LSODE).

     If the computation is not successful, ISTATE will be something
     other than 2 and MSG will contain additional information.

     You can use the function ‘lsode_options’ to set optional parameters
     for ‘lsode’.

     See also: *note daspk: XREFdaspk, *note dassl: XREFdassl, *note
     dasrt: XREFdasrt.

 -- : lsode_options ()
 -- : val = lsode_options (OPT)
 -- : lsode_options (OPT, VAL)
     Query or set options for the function ‘lsode’.

     When called with no arguments, the names of all available options
     and their current values are displayed.

     Given one argument, return the value of the option OPT.

     When called with two arguments, ‘lsode_options’ sets the option OPT
     to value VAL.

     Options include

     "absolute tolerance"
          Absolute tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector.

     "relative tolerance"
          Relative tolerance parameter.  Unlike the absolute tolerance,
          this parameter may only be a scalar.

          The local error test applied at each integration step is

                 abs (local error in x(i)) <= ...
                     rtol * abs (y(i)) + atol(i)

     "integration method"
          A string specifying the method of integration to use to solve
          the ODE system.  Valid values are

          "adams"
          "non-stiff"
               No Jacobian used (even if it is available).

          "bdf"
          "stiff"
               Use stiff backward differentiation formula (BDF) method.
               If a function to compute the Jacobian is not supplied,
               ‘lsode’ will compute a finite difference approximation of
               the Jacobian matrix.

     "initial step size"
          The step size to be attempted on the first step (default is
          determined automatically).

     "maximum order"
          Restrict the maximum order of the solution method.  If using
          the Adams method, this option must be between 1 and 12.
          Otherwise, it must be between 1 and 5, inclusive.

     "maximum step size"
          Setting the maximum stepsize will avoid passing over very
          large regions (default is not specified).

     "minimum step size"
          The minimum absolute step size allowed (default is 0).

     "step limit"
          Maximum number of steps allowed (default is 100000).

   Here is an example of solving a set of three differential equations
using ‘lsode’.  Given the function

     ## oregonator differential equation
     function xdot = f (x, t)

       xdot = zeros (3,1);

       xdot(1) = 77.27 * (x(2) - x(1)*x(2) + x(1) ...
                 - 8.375e-06*x(1)^2);
       xdot(2) = (x(3) - x(1)*x(2) - x(2)) / 77.27;
       xdot(3) = 0.161*(x(1) - x(3));

     endfunction

and the initial condition ‘x0 = [ 4; 1.1; 4 ]’, the set of equations can
be integrated using the command

     t = linspace (0, 500, 1000);

     y = lsode ("f", x0, t);

   If you try this, you will see that the value of the result changes
dramatically between T = 0 and 5, and again around T = 305.  A more
efficient set of output points might be

     t = [0, logspace(-1, log10(303), 150), ...
             logspace(log10(304), log10(500), 150)];

   See Alan C. Hindmarsh, ‘ODEPACK, A Systematized Collection of ODE
Solvers’, in Scientific Computing, R. S. Stepleman, editor, (1983) for
more information about the inner workings of ‘lsode’.

   An m-file for the differential equation used above is included with
the Octave distribution in the examples directory under the name
‘oregonator.m’.

* Menu:

* Matlab-compatible solvers::


File: octave.info,  Node: Matlab-compatible solvers,  Up: Ordinary Differential Equations

24.1.1 Matlab-compatible solvers
--------------------------------

Octave also provides a set of solvers for initial value problems for
Ordinary Differential Equations that have a MATLAB-compatible interface.
The options for this class of methods are set using the functions.

   • ‘odeset’

   • ‘odeget’

   Currently implemented solvers are:

   • Runge-Kutta methods

        • ‘ode23’ integrates a system of non-stiff ordinary differential
          equations (ODEs) or index-1 differential-algebraic equations
          (DAEs).  It uses the third-order Bogacki-Shampine method and
          adapts the local step size in order to satisfy a
          user-specified tolerance.  The solver requires three function
          evaluations per integration step.

        • ‘ode45’ integrates a system of non-stiff ODEs (or index-1
          DAEs) using the high-order, variable-step Dormand-Prince
          method.  It requires six function evaluations per integration
          step, but may take larger steps on smooth problems than
          ‘ode23’: potentially offering improved efficiency at smaller
          tolerances.

   • Linear multistep methods

        • ‘ode15s’ integrates a system of stiff ODEs (or index-1 DAEs)
          using a variable step, variable order method based on Backward
          Difference Formulas (BDF).

        • ‘ode15i’ integrates a system of fully-implicit ODEs (or
          index-1 DAEs) using the same variable step, variable order
          method as ‘ode15s’.  The function ‘decic’ can be used to
          compute consistent initial conditions.

 -- : [T, Y] = ode45 (FUN, TRANGE, INIT)
 -- : [T, Y] = ode45 (FUN, TRANGE, INIT, ODE_OPT)
 -- : [T, Y, TE, YE, IE] = ode45 (...)
 -- : SOLUTION = ode45 (...)
 -- : ode45 (...)

     Solve a set of non-stiff Ordinary Differential Equations (non-stiff
     ODEs) with the well known explicit Dormand-Prince method of order
     4.

     FUN is a function handle, inline function, or string containing the
     name of the function that defines the ODE: ‘y' = f(t,y)’.  The
     function must accept two inputs where the first is time T and the
     second is a column vector of unknowns Y.

     TRANGE specifies the time interval over which the ODE will be
     evaluated.  Typically, it is a two-element vector specifying the
     initial and final times (‘[tinit, tfinal]’).  If there are more
     than two elements then the solution will also be evaluated at these
     intermediate time instances.

     By default, ‘ode45’ uses an adaptive timestep with the
     ‘integrate_adaptive’ algorithm.  The tolerance for the timestep
     computation may be changed by using the options "RelTol" and
     "AbsTol".

     INIT contains the initial value for the unknowns.  If it is a row
     vector then the solution Y will be a matrix in which each column is
     the solution for the corresponding initial value in INIT.

     The optional fourth argument ODE_OPT specifies non-default options
     to the ODE solver.  It is a structure generated by ‘odeset’.

     The function typically returns two outputs.  Variable T is a column
     vector and contains the times where the solution was found.  The
     output Y is a matrix in which each column refers to a different
     unknown of the problem and each row corresponds to a time in T.

     The output can also be returned as a structure SOLUTION which has a
     field X containing a row vector of times where the solution was
     evaluated and a field Y containing the solution matrix such that
     each column corresponds to a time in X.  Use
     ‘fieldnames (SOLUTION)’ to see the other fields and additional
     information returned.

     If no output arguments are requested, and no ‘OutputFcn’ is
     specified in ODE_OPT, then the ‘OutputFcn’ is set to ‘odeplot’ and
     the results of the solver are plotted immediately.

     If using the "Events" option then three additional outputs may be
     returned.  TE holds the time when an Event function returned a
     zero.  YE holds the value of the solution at time TE.  IE contains
     an index indicating which Event function was triggered in the case
     of multiple Event functions.

     Example: Solve the Van der Pol equation

          fvdp = @(T,Y) [Y(2); (1 - Y(1)^2) * Y(2) - Y(1)];
          [T,Y] = ode45 (fvdp, [0, 20], [2, 0]);

     See also: *note odeset: XREFodeset, *note odeget: XREFodeget, *note
     ode23: XREFode23, *note ode15s: XREFode15s.

 -- : [T, Y] = ode23 (FUN, TRANGE, INIT)
 -- : [T, Y] = ode23 (FUN, TRANGE, INIT, ODE_OPT)
 -- : [T, Y, TE, YE, IE] = ode23 (...)
 -- : SOLUTION = ode23 (...)
 -- : ode23 (...)

     Solve a set of non-stiff Ordinary Differential Equations (non-stiff
     ODEs) with the well known explicit Bogacki-Shampine method of order
     3.

     FUN is a function handle, inline function, or string containing the
     name of the function that defines the ODE: ‘y' = f(t,y)’.  The
     function must accept two inputs where the first is time T and the
     second is a column vector of unknowns Y.

     TRANGE specifies the time interval over which the ODE will be
     evaluated.  Typically, it is a two-element vector specifying the
     initial and final times (‘[tinit, tfinal]’).  If there are more
     than two elements then the solution will also be evaluated at these
     intermediate time instances.

     By default, ‘ode23’ uses an adaptive timestep with the
     ‘integrate_adaptive’ algorithm.  The tolerance for the timestep
     computation may be changed by using the options "RelTol" and
     "AbsTol".

     INIT contains the initial value for the unknowns.  If it is a row
     vector then the solution Y will be a matrix in which each column is
     the solution for the corresponding initial value in INIT.

     The optional fourth argument ODE_OPT specifies non-default options
     to the ODE solver.  It is a structure generated by ‘odeset’.

     The function typically returns two outputs.  Variable T is a column
     vector and contains the times where the solution was found.  The
     output Y is a matrix in which each column refers to a different
     unknown of the problem and each row corresponds to a time in T.

     The output can also be returned as a structure SOLUTION which has a
     field X containing a row vector of times where the solution was
     evaluated and a field Y containing the solution matrix such that
     each column corresponds to a time in X.  Use
     ‘fieldnames (SOLUTION)’ to see the other fields and additional
     information returned.

     If no output arguments are requested, and no ‘OutputFcn’ is
     specified in ODE_OPT, then the ‘OutputFcn’ is set to ‘odeplot’ and
     the results of the solver are plotted immediately.

     If using the "Events" option then three additional outputs may be
     returned.  TE holds the time when an Event function returned a
     zero.  YE holds the value of the solution at time TE.  IE contains
     an index indicating which Event function was triggered in the case
     of multiple Event functions.

     Example: Solve the Van der Pol equation

          fvdp = @(T,Y) [Y(2); (1 - Y(1)^2) * Y(2) - Y(1)];
          [T,Y] = ode23 (fvdp, [0, 20], [2, 0]);

     Reference: For the definition of this method see
     <https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods>.

     See also: *note odeset: XREFodeset, *note odeget: XREFodeget, *note
     ode45: XREFode45, *note ode15s: XREFode15s.

 -- : [T, Y] = ode15s (FUN, TRANGE, Y0)
 -- : [T, Y] = ode15s (FUN, TRANGE, Y0, ODE_OPT)
 -- : [T, Y, TE, YE, IE] = ode15s (...)
 -- : SOLUTION = ode15s (...)
 -- : ode15s (...)
     Solve a set of stiff Ordinary Differential Equations (ODEs) or
     stiff semi-explicit index 1 Differential Algebraic Equations
     (DAEs).

     ‘ode15s’ uses a variable step, variable order BDF (Backward
     Differentiation Formula) method that ranges from order 1 to 5.

     FUN is a function handle, inline function, or string containing the
     name of the function that defines the ODE: ‘y' = f(t,y)’.  The
     function must accept two inputs where the first is time T and the
     second is a column vector of unknowns Y.

     TRANGE specifies the time interval over which the ODE will be
     evaluated.  Typically, it is a two-element vector specifying the
     initial and final times (‘[tinit, tfinal]’).  If there are more
     than two elements then the solution will also be evaluated at these
     intermediate time instances.

     INIT contains the initial value for the unknowns.  If it is a row
     vector then the solution Y will be a matrix in which each column is
     the solution for the corresponding initial value in INIT.

     The optional fourth argument ODE_OPT specifies non-default options
     to the ODE solver.  It is a structure generated by ‘odeset’.

     The function typically returns two outputs.  Variable T is a column
     vector and contains the times where the solution was found.  The
     output Y is a matrix in which each column refers to a different
     unknown of the problem and each row corresponds to a time in T.

     The output can also be returned as a structure SOLUTION which has a
     field X containing a row vector of times where the solution was
     evaluated and a field Y containing the solution matrix such that
     each column corresponds to a time in X.  Use
     ‘fieldnames (SOLUTION)’ to see the other fields and additional
     information returned.

     If no output arguments are requested, and no ‘OutputFcn’ is
     specified in ODE_OPT, then the ‘OutputFcn’ is set to ‘odeplot’ and
     the results of the solver are plotted immediately.

     If using the "Events" option then three additional outputs may be
     returned.  TE holds the time when an Event function returned a
     zero.  YE holds the value of the solution at time TE.  IE contains
     an index indicating which Event function was triggered in the case
     of multiple Event functions.

     Example: Solve Robertson’s equations:

          function r = robertson_dae (T, Y)
            r = [ -0.04*Y(1) + 1e4*Y(2)*Y(3)
                   0.04*Y(1) - 1e4*Y(2)*Y(3) - 3e7*Y(2)^2
          Y(1) + Y(2) + Y(3) - 1 ];
          endfunction
          opt = odeset ("Mass", [1 0 0; 0 1 0; 0 0 0], "MStateDependence", "none");
          [T,Y] = ode15s (@robertson_dae, [0, 1e3], [1; 0; 0], opt);

     See also: *note decic: XREFdecic, *note odeset: XREFodeset, *note
     odeget: XREFodeget, *note ode23: XREFode23, *note ode45: XREFode45.

 -- : [T, Y] = ode15i (FUN, TRANGE, Y0, YP0)
 -- : [T, Y] = ode15i (FUN, TRANGE, Y0, YP0, ODE_OPT)
 -- : [T, Y, TE, YE, IE] = ode15i (...)
 -- : SOLUTION = ode15i (...)
 -- : ode15i (...)
     Solve a set of fully-implicit Ordinary Differential Equations
     (ODEs) or index 1 Differential Algebraic Equations (DAEs).

     ‘ode15i’ uses a variable step, variable order BDF (Backward
     Differentiation Formula) method that ranges from order 1 to 5.

     FUN is a function handle, inline function, or string containing the
     name of the function that defines the ODE: ‘0 = f(t,y,yp)’.  The
     function must accept three inputs where the first is time T, the
     second is the function value Y (a column vector), and the third is
     the derivative value YP (a column vector).

     TRANGE specifies the time interval over which the ODE will be
     evaluated.  Typically, it is a two-element vector specifying the
     initial and final times (‘[tinit, tfinal]’).  If there are more
     than two elements then the solution will also be evaluated at these
     intermediate time instances.

     Y0 and YP0 contain the initial values for the unknowns Y and YP.
     If they are row vectors then the solution Y will be a matrix in
     which each column is the solution for the corresponding initial
     value in Y0 and YP0.

     Y0 and YP0 must be consistent initial conditions, meaning that
     ‘f(t,y0,yp0) = 0’ is satisfied.  The function ‘decic’ may be used
     to compute consistent initial conditions given initial guesses.

     The optional fifth argument ODE_OPT specifies non-default options
     to the ODE solver.  It is a structure generated by ‘odeset’.

     The function typically returns two outputs.  Variable T is a column
     vector and contains the times where the solution was found.  The
     output Y is a matrix in which each column refers to a different
     unknown of the problem and each row corresponds to a time in T.

     The output can also be returned as a structure SOLUTION which has a
     field X containing a row vector of times where the solution was
     evaluated and a field Y containing the solution matrix such that
     each column corresponds to a time in X.  Use
     ‘fieldnames (SOLUTION)’ to see the other fields and additional
     information returned.

     If no output arguments are requested, and no ‘OutputFcn’ is
     specified in ODE_OPT, then the ‘OutputFcn’ is set to ‘odeplot’ and
     the results of the solver are plotted immediately.

     If using the "Events" option then three additional outputs may be
     returned.  TE holds the time when an Event function returned a
     zero.  YE holds the value of the solution at time TE.  IE contains
     an index indicating which Event function was triggered in the case
     of multiple Event functions.

     Example: Solve Robertson’s equations:

          function r = robertson_dae (T, Y, YP)
            r = [ -(YP(1) + 0.04*Y(1) - 1e4*Y(2)*Y(3))
                  -(YP(2) - 0.04*Y(1) + 1e4*Y(2)*Y(3) + 3e7*Y(2)^2)
          Y(1) + Y(2) + Y(3) - 1 ];
          endfunction
          [T,Y] = ode15i (@robertson_dae, [0, 1e3], [1; 0; 0], [-1e-4; 1e-4; 0]);

     See also: *note decic: XREFdecic, *note odeset: XREFodeset, *note
     odeget: XREFodeget.

 -- : [Y0_NEW, YP0_NEW] = decic (FUN, T0, Y0, FIXED_Y0, YP0, FIXED_YP0)
 -- : [Y0_NEW, YP0_NEW] = decic (FUN, T0, Y0, FIXED_Y0, YP0, FIXED_YP0,
          OPTIONS)
 -- : [Y0_NEW, YP0_NEW, RESNORM] = decic (...)

     Compute consistent implicit ODE initial conditions Y0_NEW and
     YP0_NEW given initial guesses Y0 and YP0.

     A maximum of ‘length (Y0)’ components between FIXED_Y0 and
     FIXED_YP0 may be chosen as fixed values.

     FUN is a function handle.  The function must accept three inputs
     where the first is time T, the second is a column vector of
     unknowns Y, and the third is a column vector of unknowns YP.

     T0 is the initial time such that ‘FUN(T0, Y0_NEW, YP0_NEW) = 0’,
     specified as a scalar.

     Y0 is a vector used as the initial guess for Y.

     FIXED_Y0 is a vector which specifies the components of Y0 to hold
     fixed.  Choose a maximum of ‘length (Y0)’ components between
     FIXED_Y0 and FIXED_YP0 as fixed values.  Set FIXED_Y0(i) component
     to 1 if you want to fix the value of Y0(i).  Set FIXED_Y0(i)
     component to 0 if you want to allow the value of Y0(i) to change.

     YP0 is a vector used as the initial guess for YP.

     FIXED_YP0 is a vector which specifies the components of YP0 to hold
     fixed.  Choose a maximum of ‘length (YP0)’ components between
     FIXED_Y0 and FIXED_YP0 as fixed values.  Set FIXED_YP0(i) component
     to 1 if you want to fix the value of YP0(i).  Set FIXED_YP0(i)
     component to 0 if you want to allow the value of YP0(i) to change.

     The optional seventh argument OPTIONS is a structure array.  Use
     ‘odeset’ to generate this structure.  The relevant options are
     ‘RelTol’ and ‘AbsTol’ which specify the error thresholds used to
     compute the initial conditions.

     The function typically returns two outputs.  Variable Y0_NEW is a
     column vector and contains the consistent initial value of Y.  The
     output YP0_NEW is a column vector and contains the consistent
     initial value of YP.

     The optional third output RESNORM is the norm of the vector of
     residuals.  If RESNORM is small, ‘decic’ has successfully computed
     the initial conditions.  If the value of RESNORM is large, use
     ‘RelTol’ and ‘AbsTol’ to adjust it.

     Example: Compute initial conditions for Robertson’s equations:

          function r = robertson_dae (T, Y, YP)
            r = [ -(YP(1) + 0.04*Y(1) - 1e4*Y(2)*Y(3))
                  -(YP(2) - 0.04*Y(1) + 1e4*Y(2)*Y(3) + 3e7*Y(2)^2)
          Y(1) + Y(2) + Y(3) - 1 ];
          endfunction
          [Y0_NEW,YP0_NEW] = decic (@robertson_dae, 0, [1; 0; 0], [1; 1; 0],
          [-1e-4; 1; 0], [0; 0; 0]);

     See also: *note ode15i: XREFode15i, *note odeset: XREFodeset.

 -- : ODESTRUCT = odeset ()
 -- : ODESTRUCT = odeset ("FIELD1", VALUE1, "FIELD2", VALUE2, ...)
 -- : ODESTRUCT = odeset (OLDSTRUCT, "FIELD1", VALUE1, "FIELD2", VALUE2,
          ...)
 -- : ODESTRUCT = odeset (OLDSTRUCT, NEWSTRUCT)
 -- : odeset ()

     Create or modify an ODE options structure.

     When called with no input argument and one output argument, return
     a new ODE options structure that contains all possible fields
     initialized to their default values.  If no output argument is
     requested, display a list of the common ODE solver options along
     with their default value.

     If called with name-value input argument pairs "FIELD1", "VALUE1",
     "FIELD2", "VALUE2", ... return a new ODE options structure with all
     the most common option fields initialized, *and* set the values of
     the fields "FIELD1", "FIELD2", ... to the values VALUE1, VALUE2,
     ....

     If called with an input structure OLDSTRUCT then overwrite the
     values of the options "FIELD1", "FIELD2", ... with new values
     VALUE1, VALUE2, ... and return the modified structure.

     When called with two input ODE options structures OLDSTRUCT and
     NEWSTRUCT overwrite all values from the structure OLDSTRUCT with
     new values from the structure NEWSTRUCT.  Empty values in NEWSTRUCT
     will not overwrite values in OLDSTRUCT.

     The most commonly used ODE options, which are always assigned a
     value by ‘odeset’, are the following:

     AbsTol
          Absolute error tolerance.

     BDF
          Use BDF formulas in implicit multistep methods.  _Note_: This
          option is not yet implemented.

     Events
          Event function.  An event function must have the form ‘[value,
          isterminal, direction] = my_events_f (t, y)’

     InitialSlope
          Consistent initial slope vector for DAE solvers.

     InitialStep
          Initial time step size.

     Jacobian
          Jacobian matrix, specified as a constant matrix or a function
          of time and state.

     JConstant
          Specify whether the Jacobian is a constant matrix or depends
          on the state.

     JPattern
          If the Jacobian matrix is sparse and non-constant but
          maintains a constant sparsity pattern, specify the sparsity
          pattern.

     Mass
          Mass matrix, specified as a constant matrix or a function of
          time and state.

     MassSingular
          Specify whether the mass matrix is singular.  Accepted values
          include "yes", "no", "maybe".

     MaxOrder
          Maximum order of formula.

     MaxStep
          Maximum time step value.

     MStateDependence
          Specify whether the mass matrix depends on the state or only
          on time.

     MvPattern
          If the mass matrix is sparse and non-constant but maintains a
          constant sparsity pattern, specify the sparsity pattern.
          _Note_: This option is not yet implemented.

     NonNegative
          Specify elements of the state vector that are expected to
          remain non-negative during the simulation.

     NormControl
          Control error relative to the 2-norm of the solution, rather
          than its absolute value.

     OutputFcn
          Function to monitor the state during the simulation.  For the
          form of the function to use see ‘odeplot’.

     OutputSel
          Indices of elements of the state vector to be passed to the
          output monitoring function.

     Refine
          Specify whether output should be returned only at the end of
          each time step or also at intermediate time instances.  The
          value should be a scalar indicating the number of equally
          spaced time points to use within each timestep at which to
          return output.  _Note_: This option is not yet implemented.

     RelTol
          Relative error tolerance.

     Stats
          Print solver statistics after simulation.

     Vectorized
          Specify whether ‘odefun’ can be passed multiple values of the
          state at once.

     Field names that are not in the above list are also accepted and
     added to the result structure.

     See also: *note odeget: XREFodeget.

 -- : VAL = odeget (ODE_OPT, FIELD)
 -- : VAL = odeget (ODE_OPT, FIELD, DEFAULT)

     Query the value of the property FIELD in the ODE options structure
     ODE_OPT.

     If called with two input arguments and the first input argument
     ODE_OPT is an ODE option structure and the second input argument
     FIELD is a string specifying an option name, then return the option
     value VAL corresponding to FIELD from ODE_OPT.

     If called with an optional third input argument, and FIELD is not
     set in the structure ODE_OPT, then return the default value DEFAULT
     instead.

     See also: *note odeset: XREFodeset.

 -- : STOP_SOLVE = odeplot (T, Y, FLAG)

     Open a new figure window and plot the solution of an ode problem at
     each time step during the integration.

     The types and values of the input parameters T and Y depend on the
     input FLAG that is of type string.  Valid values of FLAG are:

     ‘"init"’
          The input T must be a column vector of length 2 with the first
          and last time step (‘[TFIRST TLAST]’.  The input Y contains
          the initial conditions for the ode problem (Y0).

     ‘""’
          The input T must be a scalar double specifying the time for
          which the solution in input Y was calculated.

     ‘"done"’
          The inputs should be empty, but are ignored if they are
          present.

     ‘odeplot’ always returns false, i.e., don’t stop the ode solver.

     Example: solve an anonymous implementation of the "Van der Pol"
     equation and display the results while solving.

          fvdp = @(t,y) [y(2); (1 - y(1)^2) * y(2) - y(1)];

          opt = odeset ("OutputFcn", @odeplot, "RelTol", 1e-6);
          sol = ode45 (fvdp, [0 20], [2 0], opt);

     Background Information: This function is called by an ode solver
     function if it was specified in the "OutputFcn" property of an
     options structure created with ‘odeset’.  The ode solver will
     initially call the function with the syntax ‘odeplot ([TFIRST,
     TLAST], Y0, "init")’.  The function initializes internal variables,
     creates a new figure window, and sets the x limits of the plot.
     Subsequently, at each time step during the integration the ode
     solver calls ‘odeplot (T, Y, [])’.  At the end of the solution the
     ode solver calls ‘odeplot ([], [], "done")’ so that odeplot can
     perform any clean-up actions required.

     See also: *note odeset: XREFodeset, *note odeget: XREFodeget, *note
     ode23: XREFode23, *note ode45: XREFode45.


File: octave.info,  Node: Differential-Algebraic Equations,  Prev: Ordinary Differential Equations,  Up: Differential Equations

24.2 Differential-Algebraic Equations
=====================================

The function ‘daspk’ can be used to solve DAEs of the form

     0 = f (x-dot, x, t),    x(t=0) = x_0, x-dot(t=0) = x-dot_0

where x-dot is the derivative of x.  The equation is solved using
Petzold’s DAE solver DASPK.

 -- : [X, XDOT, ISTATE, MSG] = daspk (FCN, X_0, XDOT_0, T, T_CRIT)
     Solve a set of differential-algebraic equations.

     ‘daspk’ solves the set of equations

          0 = f (x, xdot, t)

     with

          x(t_0) = x_0, xdot(t_0) = xdot_0

     The solution is returned in the matrices X and XDOT, with each row
     in the result matrices corresponding to one of the elements in the
     vector T.  The first element of T should be t_0 and correspond to
     the initial state of the system X_0 and its derivative XDOT_0, so
     that the first row of the output X is X_0 and the first row of the
     output XDOT is XDOT_0.

     The first argument, FCN, is a string, inline, or function handle
     that names the function f to call to compute the vector of
     residuals for the set of equations.  It must have the form

          RES = f (X, XDOT, T)

     in which X, XDOT, and RES are vectors, and T is a scalar.

     If FCN is a two-element string array or a two-element cell array of
     strings, inline functions, or function handles, the first element
     names the function f described above, and the second element names
     a function to compute the modified Jacobian

                df       df
          jac = -- + c ------
                dx     d xdot

     The modified Jacobian function must have the form


          JAC = j (X, XDOT, T, C)


     The second and third arguments to ‘daspk’ specify the initial
     condition of the states and their derivatives, and the fourth
     argument specifies a vector of output times at which the solution
     is desired, including the time corresponding to the initial
     condition.

     The set of initial states and derivatives are not strictly required
     to be consistent.  If they are not consistent, you must use the
     ‘daspk_options’ function to provide additional information so that
     ‘daspk’ can compute a consistent starting point.

     The fifth argument is optional, and may be used to specify a set of
     times that the DAE solver should not integrate past.  It is useful
     for avoiding difficulties with singularities and points where there
     is a discontinuity in the derivative.

     After a successful computation, the value of ISTATE will be greater
     than zero (consistent with the Fortran version of DASPK).

     If the computation is not successful, the value of ISTATE will be
     less than zero and MSG will contain additional information.

     You can use the function ‘daspk_options’ to set optional parameters
     for ‘daspk’.

     See also: *note dassl: XREFdassl.

 -- : daspk_options ()
 -- : val = daspk_options (OPT)
 -- : daspk_options (OPT, VAL)
     Query or set options for the function ‘daspk’.

     When called with no arguments, the names of all available options
     and their current values are displayed.

     Given one argument, return the value of the option OPT.

     When called with two arguments, ‘daspk_options’ sets the option OPT
     to value VAL.

     Options include

     "absolute tolerance"
          Absolute tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector, and
          the relative tolerance must also be a vector of the same
          length.

     "relative tolerance"
          Relative tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector, and
          the absolute tolerance must also be a vector of the same
          length.

          The local error test applied at each integration step is

                 abs (local error in x(i))
                      <= rtol(i) * abs (Y(i)) + atol(i)

     "compute consistent initial condition"
          Denoting the differential variables in the state vector by
          ‘Y_d’ and the algebraic variables by ‘Y_a’, ‘ddaspk’ can solve
          one of two initialization problems:

            1. Given Y_d, calculate Y_a and Y’_d

            2. Given Y’, calculate Y.

          In either case, initial values for the given components are
          input, and initial guesses for the unknown components must
          also be provided as input.  Set this option to 1 to solve the
          first problem, or 2 to solve the second (the default is 0, so
          you must provide a set of initial conditions that are
          consistent).

          If this option is set to a nonzero value, you must also set
          the "algebraic variables" option to declare which variables in
          the problem are algebraic.

     "use initial condition heuristics"
          Set to a nonzero value to use the initial condition heuristics
          options described below.

     "initial condition heuristics"
          A vector of the following parameters that can be used to
          control the initial condition calculation.

          ‘MXNIT’
               Maximum number of Newton iterations (default is 5).

          ‘MXNJ’
               Maximum number of Jacobian evaluations (default is 6).

          ‘MXNH’
               Maximum number of values of the artificial stepsize
               parameter to be tried if the "compute consistent initial
               condition" option has been set to 1 (default is 5).

               Note that the maximum total number of Newton iterations
               allowed is ‘MXNIT*MXNJ*MXNH’ if the "compute consistent
               initial condition" option has been set to 1 and
               ‘MXNIT*MXNJ’ if it is set to 2.

          ‘LSOFF’
               Set to a nonzero value to disable the linesearch
               algorithm (default is 0).

          ‘STPTOL’
               Minimum scaled step in linesearch algorithm (default is
               eps^(2/3)).

          ‘EPINIT’
               Swing factor in the Newton iteration convergence test.
               The test is applied to the residual vector, premultiplied
               by the approximate Jacobian.  For convergence, the
               weighted RMS norm of this vector (scaled by the error
               weights) must be less than ‘EPINIT*EPCON’, where ‘EPCON’
               = 0.33 is the analogous test constant used in the time
               steps.  The default is ‘EPINIT’ = 0.01.

     "print initial condition info"
          Set this option to a nonzero value to display detailed
          information about the initial condition calculation (default
          is 0).

     "exclude algebraic variables from error test"
          Set to a nonzero value to exclude algebraic variables from the
          error test.  You must also set the "algebraic variables"
          option to declare which variables in the problem are algebraic
          (default is 0).

     "algebraic variables"
          A vector of the same length as the state vector.  A nonzero
          element indicates that the corresponding element of the state
          vector is an algebraic variable (i.e., its derivative does not
          appear explicitly in the equation set).

          This option is required by the "compute consistent initial
          condition" and "exclude algebraic variables from error test"
          options.

     "enforce inequality constraints"
          Set to one of the following values to enforce the inequality
          constraints specified by the "inequality constraint types"
          option (default is 0).

            1. To have constraint checking only in the initial condition
               calculation.

            2. To enforce constraint checking during the integration.

            3. To enforce both options 1 and 2.

     "inequality constraint types"
          A vector of the same length as the state specifying the type
          of inequality constraint.  Each element of the vector
          corresponds to an element of the state and should be assigned
          one of the following codes

          -2
               Less than zero.

          -1
               Less than or equal to zero.

          0
               Not constrained.

          1
               Greater than or equal to zero.

          2
               Greater than zero.

          This option only has an effect if the "enforce inequality
          constraints" option is nonzero.

     "initial step size"
          Differential-algebraic problems may occasionally suffer from
          severe scaling difficulties on the first step.  If you know a
          great deal about the scaling of your problem, you can help to
          alleviate this problem by specifying an initial stepsize
          (default is computed automatically).

     "maximum order"
          Restrict the maximum order of the solution method.  This
          option must be between 1 and 5, inclusive (default is 5).

     "maximum step size"
          Setting the maximum stepsize will avoid passing over very
          large regions (default is not specified).

   Octave also includes DASSL, an earlier version of DASPK, and DASRT,
which can be used to solve DAEs with constraints (stopping conditions).

 -- : [X, XDOT, ISTATE, MSG] = dassl (FCN, X_0, XDOT_0, T, T_CRIT)
     Solve a set of differential-algebraic equations.

     ‘dassl’ solves the set of equations

          0 = f (x, xdot, t)

     with

          x(t_0) = x_0, xdot(t_0) = xdot_0

     The solution is returned in the matrices X and XDOT, with each row
     in the result matrices corresponding to one of the elements in the
     vector T.  The first element of T should be t_0 and correspond to
     the initial state of the system X_0 and its derivative XDOT_0, so
     that the first row of the output X is X_0 and the first row of the
     output XDOT is XDOT_0.

     The first argument, FCN, is a string, inline, or function handle
     that names the function f to call to compute the vector of
     residuals for the set of equations.  It must have the form

          RES = f (X, XDOT, T)

     in which X, XDOT, and RES are vectors, and T is a scalar.

     If FCN is a two-element string array or a two-element cell array of
     strings, inline functions, or function handles, the first element
     names the function f described above, and the second element names
     a function to compute the modified Jacobian

                df       df
          jac = -- + c ------
                dx     d xdot

     The modified Jacobian function must have the form


          JAC = j (X, XDOT, T, C)


     The second and third arguments to ‘dassl’ specify the initial
     condition of the states and their derivatives, and the fourth
     argument specifies a vector of output times at which the solution
     is desired, including the time corresponding to the initial
     condition.

     The set of initial states and derivatives are not strictly required
     to be consistent.  In practice, however, DASSL is not very good at
     determining a consistent set for you, so it is best if you ensure
     that the initial values result in the function evaluating to zero.

     The fifth argument is optional, and may be used to specify a set of
     times that the DAE solver should not integrate past.  It is useful
     for avoiding difficulties with singularities and points where there
     is a discontinuity in the derivative.

     After a successful computation, the value of ISTATE will be greater
     than zero (consistent with the Fortran version of DASSL).

     If the computation is not successful, the value of ISTATE will be
     less than zero and MSG will contain additional information.

     You can use the function ‘dassl_options’ to set optional parameters
     for ‘dassl’.

     See also: *note daspk: XREFdaspk, *note dasrt: XREFdasrt, *note
     lsode: XREFlsode.

 -- : dassl_options ()
 -- : val = dassl_options (OPT)
 -- : dassl_options (OPT, VAL)
     Query or set options for the function ‘dassl’.

     When called with no arguments, the names of all available options
     and their current values are displayed.

     Given one argument, return the value of the option OPT.

     When called with two arguments, ‘dassl_options’ sets the option OPT
     to value VAL.

     Options include

     "absolute tolerance"
          Absolute tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector, and
          the relative tolerance must also be a vector of the same
          length.

     "relative tolerance"
          Relative tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector, and
          the absolute tolerance must also be a vector of the same
          length.

          The local error test applied at each integration step is

                 abs (local error in x(i))
                      <= rtol(i) * abs (Y(i)) + atol(i)

     "compute consistent initial condition"
          If nonzero, ‘dassl’ will attempt to compute a consistent set
          of initial conditions.  This is generally not reliable, so it
          is best to provide a consistent set and leave this option set
          to zero.

     "enforce nonnegativity constraints"
          If you know that the solutions to your equations will always
          be non-negative, it may help to set this parameter to a
          nonzero value.  However, it is probably best to try leaving
          this option set to zero first, and only setting it to a
          nonzero value if that doesn’t work very well.

     "initial step size"
          Differential-algebraic problems may occasionally suffer from
          severe scaling difficulties on the first step.  If you know a
          great deal about the scaling of your problem, you can help to
          alleviate this problem by specifying an initial stepsize.

     "maximum order"
          Restrict the maximum order of the solution method.  This
          option must be between 1 and 5, inclusive.

     "maximum step size"
          Setting the maximum stepsize will avoid passing over very
          large regions (default is not specified).

     "step limit"
          Maximum number of integration steps to attempt on a single
          call to the underlying Fortran code.

 -- : [X, XDOT, T_OUT, ISTAT, MSG] = dasrt (FCN, G, X_0, XDOT_0, T)
 -- : ... = dasrt (FCN, G, X_0, XDOT_0, T, T_CRIT)
 -- : ... = dasrt (FCN, X_0, XDOT_0, T)
 -- : ... = dasrt (FCN, X_0, XDOT_0, T, T_CRIT)
     Solve a set of differential-algebraic equations.

     ‘dasrt’ solves the set of equations

          0 = f (x, xdot, t)

     with

          x(t_0) = x_0, xdot(t_0) = xdot_0

     with functional stopping criteria (root solving).

     The solution is returned in the matrices X and XDOT, with each row
     in the result matrices corresponding to one of the elements in the
     vector T_OUT.  The first element of T should be t_0 and correspond
     to the initial state of the system X_0 and its derivative XDOT_0,
     so that the first row of the output X is X_0 and the first row of
     the output XDOT is XDOT_0.

     The vector T provides an upper limit on the length of the
     integration.  If the stopping condition is met, the vector T_OUT
     will be shorter than T, and the final element of T_OUT will be the
     point at which the stopping condition was met, and may not
     correspond to any element of the vector T.

     The first argument, FCN, is a string, inline, or function handle
     that names the function f to call to compute the vector of
     residuals for the set of equations.  It must have the form

          RES = f (X, XDOT, T)

     in which X, XDOT, and RES are vectors, and T is a scalar.

     If FCN is a two-element string array or a two-element cell array of
     strings, inline functions, or function handles, the first element
     names the function f described above, and the second element names
     a function to compute the modified Jacobian

                df       df
          jac = -- + c ------
                dx     d xdot

     The modified Jacobian function must have the form


          JAC = j (X, XDOT, T, C)


     The optional second argument names a function that defines the
     constraint functions whose roots are desired during the
     integration.  This function must have the form

          G_OUT = g (X, T)

     and return a vector of the constraint function values.  If the
     value of any of the constraint functions changes sign, DASRT will
     attempt to stop the integration at the point of the sign change.

     If the name of the constraint function is omitted, ‘dasrt’ solves
     the same problem as ‘daspk’ or ‘dassl’.

     Note that because of numerical errors in the constraint functions
     due to round-off and integration error, DASRT may return false
     roots, or return the same root at two or more nearly equal values
     of T.  If such false roots are suspected, the user should consider
     smaller error tolerances or higher precision in the evaluation of
     the constraint functions.

     If a root of some constraint function defines the end of the
     problem, the input to DASRT should nevertheless allow integration
     to a point slightly past that root, so that DASRT can locate the
     root by interpolation.

     The third and fourth arguments to ‘dasrt’ specify the initial
     condition of the states and their derivatives, and the fourth
     argument specifies a vector of output times at which the solution
     is desired, including the time corresponding to the initial
     condition.

     The set of initial states and derivatives are not strictly required
     to be consistent.  In practice, however, DASSL is not very good at
     determining a consistent set for you, so it is best if you ensure
     that the initial values result in the function evaluating to zero.

     The sixth argument is optional, and may be used to specify a set of
     times that the DAE solver should not integrate past.  It is useful
     for avoiding difficulties with singularities and points where there
     is a discontinuity in the derivative.

     After a successful computation, the value of ISTATE will be greater
     than zero (consistent with the Fortran version of DASSL).

     If the computation is not successful, the value of ISTATE will be
     less than zero and MSG will contain additional information.

     You can use the function ‘dasrt_options’ to set optional parameters
     for ‘dasrt’.

     See also: *note dasrt_options: XREFdasrt_options, *note daspk:
     XREFdaspk, *note dasrt: XREFdasrt, *note lsode: XREFlsode.

 -- : dasrt_options ()
 -- : val = dasrt_options (OPT)
 -- : dasrt_options (OPT, VAL)
     Query or set options for the function ‘dasrt’.

     When called with no arguments, the names of all available options
     and their current values are displayed.

     Given one argument, return the value of the option OPT.

     When called with two arguments, ‘dasrt_options’ sets the option OPT
     to value VAL.

     Options include

     "absolute tolerance"
          Absolute tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector, and
          the relative tolerance must also be a vector of the same
          length.

     "relative tolerance"
          Relative tolerance.  May be either vector or scalar.  If a
          vector, it must match the dimension of the state vector, and
          the absolute tolerance must also be a vector of the same
          length.

          The local error test applied at each integration step is

                 abs (local error in x(i)) <= ...
                     rtol(i) * abs (Y(i)) + atol(i)

     "initial step size"
          Differential-algebraic problems may occasionally suffer from
          severe scaling difficulties on the first step.  If you know a
          great deal about the scaling of your problem, you can help to
          alleviate this problem by specifying an initial stepsize.

     "maximum order"
          Restrict the maximum order of the solution method.  This
          option must be between 1 and 5, inclusive.

     "maximum step size"
          Setting the maximum stepsize will avoid passing over very
          large regions.

     "step limit"
          Maximum number of integration steps to attempt on a single
          call to the underlying Fortran code.

   See K. E. Brenan, et al., ‘Numerical Solution of Initial-Value
Problems in Differential-Algebraic Equations’, North-Holland (1989) for
more information about the implementation of DASSL.


File: octave.info,  Node: Optimization,  Next: Statistics,  Prev: Differential Equations,  Up: Top

25 Optimization
***************

Octave comes with support for solving various kinds of optimization
problems.  Specifically Octave can solve problems in Linear Programming,
Quadratic Programming, Nonlinear Programming, and Linear Least Squares
Minimization.

* Menu:

* Linear Programming::
* Quadratic Programming::
* Nonlinear Programming::
* Linear Least Squares::


File: octave.info,  Node: Linear Programming,  Next: Quadratic Programming,  Up: Optimization

25.1 Linear Programming
=======================

Octave can solve Linear Programming problems using the ‘glpk’ function.
That is, Octave can solve

     min C'*x

   subject to the linear constraints A*x = b where x ≥ 0.

The ‘glpk’ function also supports variations of this problem.

 -- : [XOPT, FMIN, ERRNUM, EXTRA] = glpk (C, A, B, LB, UB, CTYPE,
          VARTYPE, SENSE, PARAM)
     Solve a linear program using the GNU GLPK library.

     Given three arguments, ‘glpk’ solves the following standard LP:

          min C'*x

     subject to

          A*x  = b
            x >= 0

     but may also solve problems of the form

          [ min | max ] C'*x

     subject to

          A*x [ "=" | "<=" | ">=" ] b
            x >= LB
            x <= UB

     Input arguments:

     C
          A column array containing the objective function coefficients.

     A
          A matrix containing the constraints coefficients.

     B
          A column array containing the right-hand side value for each
          constraint in the constraint matrix.

     LB
          An array containing the lower bound on each of the variables.
          If LB is not supplied, the default lower bound for the
          variables is zero.

     UB
          An array containing the upper bound on each of the variables.
          If UB is not supplied, the default upper bound is assumed to
          be infinite.

     CTYPE
          An array of characters containing the sense of each constraint
          in the constraint matrix.  Each element of the array may be
          one of the following values

          "F"
               A free (unbounded) constraint (the constraint is
               ignored).

          "U"
               An inequality constraint with an upper bound (‘A(i,:)*x
               <= b(i)’).

          "S"
               An equality constraint (‘A(i,:)*x = b(i)’).

          "L"
               An inequality with a lower bound (‘A(i,:)*x >= b(i)’).

          "D"
               An inequality constraint with both upper and lower bounds
               (‘A(i,:)*x >= -b(i)’) _and_ (‘A(i,:)*x <= b(i)’).

     VARTYPE
          A column array containing the types of the variables.

          "C"
               A continuous variable.

          "I"
               An integer variable.

     SENSE
          If SENSE is 1, the problem is a minimization.  If SENSE is -1,
          the problem is a maximization.  The default value is 1.

     PARAM
          A structure containing the following parameters used to define
          the behavior of solver.  Missing elements in the structure
          take on default values, so you only need to set the elements
          that you wish to change from the default.

          Integer parameters:

          ‘msglev (default: 1)’
               Level of messages output by solver routines:

               0 (‘GLP_MSG_OFF’)
                    No output.

               1 (‘GLP_MSG_ERR’)
                    Error and warning messages only.

               2 (‘GLP_MSG_ON’)
                    Normal output.

               3 (‘GLP_MSG_ALL’)
                    Full output (includes informational messages).

          ‘scale (default: 16)’
               Scaling option.  The values can be combined with the
               bitwise OR operator and may be the following:

               1 (‘GLP_SF_GM’)
                    Geometric mean scaling.

               16 (‘GLP_SF_EQ’)
                    Equilibration scaling.

               32 (‘GLP_SF_2N’)
                    Round scale factors to power of two.

               64 (‘GLP_SF_SKIP’)
                    Skip if problem is well scaled.

               Alternatively, a value of 128 (‘GLP_SF_AUTO’) may be also
               specified, in which case the routine chooses the scaling
               options automatically.

          ‘dual (default: 1)’
               Simplex method option:

               1 (‘GLP_PRIMAL’)
                    Use two-phase primal simplex.

               2 (‘GLP_DUALP’)
                    Use two-phase dual simplex, and if it fails, switch
                    to the primal simplex.

               3 (‘GLP_DUAL’)
                    Use two-phase dual simplex.

          ‘price (default: 34)’
               Pricing option (for both primal and dual simplex):

               17 (‘GLP_PT_STD’)
                    Textbook pricing.

               34 (‘GLP_PT_PSE’)
                    Steepest edge pricing.

          ‘itlim (default: intmax)’
               Simplex iterations limit.  It is decreased by one each
               time when one simplex iteration has been performed, and
               reaching zero value signals the solver to stop the
               search.

          ‘outfrq (default: 200)’
               Output frequency, in iterations.  This parameter
               specifies how frequently the solver sends information
               about the solution to the standard output.

          ‘branch (default: 4)’
               Branching technique option (for MIP only):

               1 (‘GLP_BR_FFV’)
                    First fractional variable.

               2 (‘GLP_BR_LFV’)
                    Last fractional variable.

               3 (‘GLP_BR_MFV’)
                    Most fractional variable.

               4 (‘GLP_BR_DTH’)
                    Heuristic by Driebeck and Tomlin.

               5 (‘GLP_BR_PCH’)
                    Hybrid pseudocost heuristic.

          ‘btrack (default: 4)’
               Backtracking technique option (for MIP only):

               1 (‘GLP_BT_DFS’)
                    Depth first search.

               2 (‘GLP_BT_BFS’)
                    Breadth first search.

               3 (‘GLP_BT_BLB’)
                    Best local bound.

               4 (‘GLP_BT_BPH’)
                    Best projection heuristic.

          ‘presol (default: 1)’
               If this flag is set, the simplex solver uses the built-in
               LP presolver.  Otherwise the LP presolver is not used.

          ‘lpsolver (default: 1)’
               Select which solver to use.  If the problem is a MIP
               problem this flag will be ignored.

               1
                    Revised simplex method.

               2
                    Interior point method.

          ‘rtest (default: 34)’
               Ratio test technique:

               17 (‘GLP_RT_STD’)
                    Standard ("textbook").

               34 (‘GLP_RT_HAR’)
                    Harris’ two-pass ratio test.

          ‘tmlim (default: intmax)’
               Searching time limit, in milliseconds.

          ‘outdly (default: 0)’
               Output delay, in seconds.  This parameter specifies how
               long the solver should delay sending information about
               the solution to the standard output.

          ‘save (default: 0)’
               If this parameter is nonzero, save a copy of the problem
               in CPLEX LP format to the file ‘"outpb.lp"’.  There is
               currently no way to change the name of the output file.

          Real parameters:

          ‘tolbnd (default: 1e-7)’
               Relative tolerance used to check if the current basic
               solution is primal feasible.  It is not recommended that
               you change this parameter unless you have a detailed
               understanding of its purpose.

          ‘toldj (default: 1e-7)’
               Absolute tolerance used to check if the current basic
               solution is dual feasible.  It is not recommended that
               you change this parameter unless you have a detailed
               understanding of its purpose.

          ‘tolpiv (default: 1e-10)’
               Relative tolerance used to choose eligible pivotal
               elements of the simplex table.  It is not recommended
               that you change this parameter unless you have a detailed
               understanding of its purpose.

          ‘objll (default: -DBL_MAX)’
               Lower limit of the objective function.  If the objective
               function reaches this limit and continues decreasing, the
               solver stops the search.  This parameter is used in the
               dual simplex method only.

          ‘objul (default: +DBL_MAX)’
               Upper limit of the objective function.  If the objective
               function reaches this limit and continues increasing, the
               solver stops the search.  This parameter is used in the
               dual simplex only.

          ‘tolint (default: 1e-5)’
               Relative tolerance used to check if the current basic
               solution is integer feasible.  It is not recommended that
               you change this parameter unless you have a detailed
               understanding of its purpose.

          ‘tolobj (default: 1e-7)’
               Relative tolerance used to check if the value of the
               objective function is not better than in the best known
               integer feasible solution.  It is not recommended that
               you change this parameter unless you have a detailed
               understanding of its purpose.

     Output values:

     XOPT
          The optimizer (the value of the decision variables at the
          optimum).

     FOPT
          The optimum value of the objective function.

     ERRNUM
          Error code.

          0
               No error.

          1 (‘GLP_EBADB’)
               Invalid basis.

          2 (‘GLP_ESING’)
               Singular matrix.

          3 (‘GLP_ECOND’)
               Ill-conditioned matrix.

          4 (‘GLP_EBOUND’)
               Invalid bounds.

          5 (‘GLP_EFAIL’)
               Solver failed.

          6 (‘GLP_EOBJLL’)
               Objective function lower limit reached.

          7 (‘GLP_EOBJUL’)
               Objective function upper limit reached.

          8 (‘GLP_EITLIM’)
               Iterations limit exhausted.

          9 (‘GLP_ETMLIM’)
               Time limit exhausted.

          10 (‘GLP_ENOPFS’)
               No primal feasible solution.

          11 (‘GLP_ENODFS’)
               No dual feasible solution.

          12 (‘GLP_EROOT’)
               Root LP optimum not provided.

          13 (‘GLP_ESTOP’)
               Search terminated by application.

          14 (‘GLP_EMIPGAP’)
               Relative MIP gap tolerance reached.

          15 (‘GLP_ENOFEAS’)
               No primal/dual feasible solution.

          16 (‘GLP_ENOCVG’)
               No convergence.

          17 (‘GLP_EINSTAB’)
               Numerical instability.

          18 (‘GLP_EDATA’)
               Invalid data.

          19 (‘GLP_ERANGE’)
               Result out of range.

     EXTRA
          A data structure containing the following fields:

          ‘lambda’
               Dual variables.

          ‘redcosts’
               Reduced Costs.

          ‘time’
               Time (in seconds) used for solving LP/MIP problem.

          ‘status’
               Status of the optimization.

               1 (‘GLP_UNDEF’)
                    Solution status is undefined.

               2 (‘GLP_FEAS’)
                    Solution is feasible.

               3 (‘GLP_INFEAS’)
                    Solution is infeasible.

               4 (‘GLP_NOFEAS’)
                    Problem has no feasible solution.

               5 (‘GLP_OPT’)
                    Solution is optimal.

               6 (‘GLP_UNBND’)
                    Problem has no unbounded solution.

     Example:

          c = [10, 6, 4]';
          A = [ 1, 1, 1;
               10, 4, 5;
                2, 2, 6];
          b = [100, 600, 300]';
          lb = [0, 0, 0]';
          ub = [];
          ctype = "UUU";
          vartype = "CCC";
          s = -1;

          param.msglev = 1;
          param.itlim = 100;

          [xmin, fmin, status, extra] = ...
             glpk (c, A, b, lb, ub, ctype, vartype, s, param);


File: octave.info,  Node: Quadratic Programming,  Next: Nonlinear Programming,  Prev: Linear Programming,  Up: Optimization

25.2 Quadratic Programming
==========================

Octave can also solve Quadratic Programming problems, this is

     min 0.5 x'*H*x + x'*q

   subject to

          A*x = b
          lb <= x <= ub
          A_lb <= A_in*x <= A_ub

 -- : [X, OBJ, INFO, LAMBDA] = qp (X0, H)
 -- : [X, OBJ, INFO, LAMBDA] = qp (X0, H, Q)
 -- : [X, OBJ, INFO, LAMBDA] = qp (X0, H, Q, A, B)
 -- : [X, OBJ, INFO, LAMBDA] = qp (X0, H, Q, A, B, LB, UB)
 -- : [X, OBJ, INFO, LAMBDA] = qp (X0, H, Q, A, B, LB, UB, A_LB, A_IN,
          A_UB)
 -- : [X, OBJ, INFO, LAMBDA] = qp (..., OPTIONS)
     Solve a quadratic program (QP).

     Solve the quadratic program defined by

          min 0.5 x'*H*x + x'*q
           x

     subject to

          A*x = b
          lb <= x <= ub
          A_lb <= A_in*x <= A_ub

     using a null-space active-set method.

     Any bound (A, B, LB, UB, A_IN, A_LB, A_UB) may be set to the empty
     matrix (‘[]’) if not present.  The constraints A and A_IN are
     matrices with each row representing a single constraint.  The other
     bounds are scalars or vectors depending on the number of
     constraints.  The algorithm is faster if the initial guess is
     feasible.

     OPTIONS
          An optional structure containing the following parameter(s)
          used to define the behavior of the solver.  Missing elements
          in the structure take on default values, so you only need to
          set the elements that you wish to change from the default.

          ‘MaxIter (default: 200)’
               Maximum number of iterations.

     INFO
          Structure containing run-time information about the algorithm.
          The following fields are defined:

          ‘solveiter’
               The number of iterations required to find the solution.

          ‘info’
               An integer indicating the status of the solution.

               0
                    The problem is feasible and convex.  Global solution
                    found.

               1
                    The problem is not convex.  Local solution found.

               2
                    The problem is not convex and unbounded.

               3
                    Maximum number of iterations reached.

               6
                    The problem is infeasible.

 -- : X = pqpnonneg (C, D)
 -- : X = pqpnonneg (C, D, X0)
 -- : X = pqpnonneg (C, D, X0, OPTIONS)
 -- : [X, MINVAL] = pqpnonneg (...)
 -- : [X, MINVAL, EXITFLAG] = pqpnonneg (...)
 -- : [X, MINVAL, EXITFLAG, OUTPUT] = pqpnonneg (...)
 -- : [X, MINVAL, EXITFLAG, OUTPUT, LAMBDA] = pqpnonneg (...)

     Minimize ‘1/2*X'*C*X + D'*X’ subject to ‘X >= 0’.

     C and D must be real matrices, and C must be symmetric and positive
     definite.

     X0 is an optional initial guess for the solution X.

     OPTIONS is an options structure to change the behavior of the
     algorithm (*note optimset: XREFoptimset.).  ‘pqpnonneg’ recognizes
     one option: "MaxIter".

     Outputs:

     X
          The solution matrix

     MINVAL
          The minimum attained model value, ‘1/2*XMIN'*C*XMIN + D'*XMIN’

     EXITFLAG
          An indicator of convergence.  0 indicates that the iteration
          count was exceeded, and therefore convergence was not reached;
          >0 indicates that the algorithm converged.  (The algorithm is
          stable and will converge given enough iterations.)

     OUTPUT
          A structure with two fields:

             • "algorithm": The algorithm used ("nnls")

             • "iterations": The number of iterations taken.

     LAMBDA
          Undocumented output

     See also: *note lsqnonneg: XREFlsqnonneg, *note qp: XREFqp, *note
     optimset: XREFoptimset.


File: octave.info,  Node: Nonlinear Programming,  Next: Linear Least Squares,  Prev: Quadratic Programming,  Up: Optimization

25.3 Nonlinear Programming
==========================

Octave can also perform general nonlinear minimization using a
successive quadratic programming solver.

 -- : [X, OBJ, INFO, ITER, NF, LAMBDA] = sqp (X0, PHI)
 -- : [...] = sqp (X0, PHI, G)
 -- : [...] = sqp (X0, PHI, G, H)
 -- : [...] = sqp (X0, PHI, G, H, LB, UB)
 -- : [...] = sqp (X0, PHI, G, H, LB, UB, MAXITER)
 -- : [...] = sqp (X0, PHI, G, H, LB, UB, MAXITER, TOL)
     Minimize an objective function using sequential quadratic
     programming (SQP).

     Solve the nonlinear program

          min phi (x)
           x

     subject to

          g(x)  = 0
          h(x) >= 0
          lb <= x <= ub

     using a sequential quadratic programming method.

     The first argument is the initial guess for the vector X0.

     The second argument is a function handle pointing to the objective
     function PHI.  The objective function must accept one vector
     argument and return a scalar.

     The second argument may also be a 2- or 3-element cell array of
     function handles.  The first element should point to the objective
     function, the second should point to a function that computes the
     gradient of the objective function, and the third should point to a
     function that computes the Hessian of the objective function.  If
     the gradient function is not supplied, the gradient is computed by
     finite differences.  If the Hessian function is not supplied, a
     BFGS update formula is used to approximate the Hessian.

     When supplied, the gradient function ‘PHI{2}’ must accept one
     vector argument and return a vector.  When supplied, the Hessian
     function ‘PHI{3}’ must accept one vector argument and return a
     matrix.

     The third and fourth arguments G and H are function handles
     pointing to functions that compute the equality constraints and the
     inequality constraints, respectively.  If the problem does not have
     equality (or inequality) constraints, then use an empty matrix ([])
     for G (or H).  When supplied, these equality and inequality
     constraint functions must accept one vector argument and return a
     vector.

     The third and fourth arguments may also be 2-element cell arrays of
     function handles.  The first element should point to the constraint
     function and the second should point to a function that computes
     the gradient of the constraint function:

                      [ d f(x)   d f(x)        d f(x) ]
          transpose ( [ ------   -----   ...   ------ ] )
                      [  dx_1     dx_2          dx_N  ]

     The fifth and sixth arguments, LB and UB, contain lower and upper
     bounds on X.  These must be consistent with the equality and
     inequality constraints G and H.  If the arguments are vectors then
     X(i) is bound by LB(i) and UB(i).  A bound can also be a scalar in
     which case all elements of X will share the same bound.  If only
     one bound (lb, ub) is specified then the other will default to
     (-REALMAX, +REALMAX).

     The seventh argument MAXITER specifies the maximum number of
     iterations.  The default value is 100.

     The eighth argument TOL specifies the tolerance for the stopping
     criteria.  The default value is ‘sqrt (eps)’.

     The value returned in INFO may be one of the following:

     101
          The algorithm terminated normally.  All constraints meet the
          specified tolerance.

     102
          The BFGS update failed.

     103
          The maximum number of iterations was reached.

     104
          The stepsize has become too small, i.e., delta X, is less than
          ‘TOL * norm (x)’.

     An example of calling ‘sqp’:

          function r = g (x)
            r = [ sumsq(x)-10;
                  x(2)*x(3)-5*x(4)*x(5);
                  x(1)^3+x(2)^3+1 ];
          endfunction

          function obj = phi (x)
            obj = exp (prod (x)) - 0.5*(x(1)^3+x(2)^3+1)^2;
          endfunction

          x0 = [-1.8; 1.7; 1.9; -0.8; -0.8];

          [x, obj, info, iter, nf, lambda] = sqp (x0, @phi, @g, [])

          x =

            -1.71714
             1.59571
             1.82725
            -0.76364
            -0.76364

          obj = 0.053950
          info = 101
          iter = 8
          nf = 10
          lambda =

            -0.0401627
             0.0379578
            -0.0052227

     See also: *note qp: XREFqp.


File: octave.info,  Node: Linear Least Squares,  Prev: Nonlinear Programming,  Up: Optimization

25.4 Linear Least Squares
=========================

Octave also supports linear least squares minimization.  That is, Octave
can find the parameter b such that the model y = x*b fits data (x,y) as
well as possible, assuming zero-mean Gaussian noise.  If the noise is
assumed to be isotropic the problem can be solved using the ‘\’ or ‘/’
operators, or the ‘ols’ function.  In the general case where the noise
is assumed to be anisotropic the ‘gls’ is needed.

 -- : [BETA, SIGMA, R] = ols (Y, X)
     Ordinary least squares (OLS) estimation.

     OLS applies to the multivariate model Y = X*B + E where Y is a
     t-by-p matrix, X is a t-by-k matrix, B is a k-by-p matrix, and E is
     a t-by-p matrix.

     Each row of Y is a p-variate observation in which each column
     represents a variable.  Likewise, the rows of X represent k-variate
     observations or possibly designed values.  Furthermore, the
     collection of observations X must be of adequate rank, k, otherwise
     B cannot be uniquely estimated.

     The observation errors, E, are assumed to originate from an
     underlying p-variate distribution with zero mean and p-by-p
     covariance matrix S, both constant conditioned on X.  Furthermore,
     the matrix S is constant with respect to each observation such that
     ‘mean (E) = 0’ and ‘cov (vec (E)) = kron (S, I)’.  (For cases that
     don’t meet this criteria, such as autocorrelated errors, see
     generalized least squares, gls, for more efficient estimations.)

     The return values BETA, SIGMA, and R are defined as follows.

     BETA
          The OLS estimator for matrix B.  BETA is calculated directly
          via ‘inv (X'*X) * X' * Y’ if the matrix ‘X'*X’ is of full
          rank.  Otherwise, ‘BETA = pinv (X) * Y’ where ‘pinv (X)’
          denotes the pseudoinverse of X.

     SIGMA
          The OLS estimator for the matrix S,

               SIGMA = (Y-X*BETA)' * (Y-X*BETA) / (t-rank(X))

     R
          The matrix of OLS residuals, ‘R = Y - X*BETA’.

     See also: *note gls: XREFgls, *note pinv: XREFpinv.

 -- : [BETA, V, R] = gls (Y, X, O)
     Generalized least squares (GLS) model.

     Perform a generalized least squares estimation for the multivariate
     model Y = X*B + E where Y is a t-by-p matrix, X is a t-by-k matrix,
     B is a k-by-p matrix and E is a t-by-p matrix.

     Each row of Y is a p-variate observation in which each column
     represents a variable.  Likewise, the rows of X represent k-variate
     observations or possibly designed values.  Furthermore, the
     collection of observations X must be of adequate rank, k, otherwise
     B cannot be uniquely estimated.

     The observation errors, E, are assumed to originate from an
     underlying p-variate distribution with zero mean but possibly
     heteroscedastic observations.  That is, in general, ‘mean (E) = 0’
     and ‘cov (vec (E)) = (s^2)*O’ in which s is a scalar and O is a
     t*p-by-t*p matrix.

     The return values BETA, V, and R are defined as follows.

     BETA
          The GLS estimator for matrix B.

     V
          The GLS estimator for scalar s^2.

     R
          The matrix of GLS residuals, R = Y - X*BETA.

     See also: *note ols: XREFols.

 -- : X = lsqnonneg (C, D)
 -- : X = lsqnonneg (C, D, X0)
 -- : X = lsqnonneg (C, D, X0, OPTIONS)
 -- : [X, RESNORM] = lsqnonneg (...)
 -- : [X, RESNORM, RESIDUAL] = lsqnonneg (...)
 -- : [X, RESNORM, RESIDUAL, EXITFLAG] = lsqnonneg (...)
 -- : [X, RESNORM, RESIDUAL, EXITFLAG, OUTPUT] = lsqnonneg (...)
 -- : [X, RESNORM, RESIDUAL, EXITFLAG, OUTPUT, LAMBDA] = lsqnonneg (...)

     Minimize ‘norm (C*X - D)’ subject to ‘X >= 0’.

     C and D must be real matrices.

     X0 is an optional initial guess for the solution X.

     OPTIONS is an options structure to change the behavior of the
     algorithm (*note optimset: XREFoptimset.).  ‘lsqnonneg’ recognizes
     these options: "MaxIter", "TolX".

     Outputs:

     RESNORM
          The squared 2-norm of the residual: ‘norm (C*X-D)^2’

     RESIDUAL
          The residual: ‘D-C*X’

     EXITFLAG
          An indicator of convergence.  0 indicates that the iteration
          count was exceeded, and therefore convergence was not reached;
          >0 indicates that the algorithm converged.  (The algorithm is
          stable and will converge given enough iterations.)

     OUTPUT
          A structure with two fields:

             • "algorithm": The algorithm used ("nnls")

             • "iterations": The number of iterations taken.

     LAMBDA
          Undocumented output

     See also: *note pqpnonneg: XREFpqpnonneg, *note lscov: XREFlscov,
     *note optimset: XREFoptimset.

 -- : X = lscov (A, B)
 -- : X = lscov (A, B, V)
 -- : X = lscov (A, B, V, ALG)
 -- : [X, STDX, MSE, S] = lscov (...)

     Compute a generalized linear least squares fit.

     Estimate X under the model B = AX + W, where the noise W is assumed
     to follow a normal distribution with covariance matrix {\sigma^2}
     V.

     If the size of the coefficient matrix A is n-by-p, the size of the
     vector/array of constant terms B must be n-by-k.

     The optional input argument V may be an n-element vector of
     positive weights (inverse variances), or an n-by-n symmetric
     positive semi-definite matrix representing the covariance of B.  If
     V is not supplied, the ordinary least squares solution is returned.

     The ALG input argument, a guidance on solution method to use, is
     currently ignored.

     Besides the least-squares estimate matrix X (p-by-k), the function
     also returns STDX (p-by-k), the error standard deviation of
     estimated X; MSE (k-by-1), the estimated data error covariance
     scale factors (\sigma^2); and S (p-by-p, or p-by-p-by-k if k > 1),
     the error covariance of X.

     Reference: Golub and Van Loan (1996), ‘Matrix Computations (3rd
     Ed.)’, Johns Hopkins, Section 5.6.3

     See also: *note ols: XREFols, *note gls: XREFgls, *note lsqnonneg:
     XREFlsqnonneg.

 -- : optimset ()
 -- : OPTIONS = optimset ()
 -- : OPTIONS = optimset (PAR, VAL, ...)
 -- : OPTIONS = optimset (OLD, PAR, VAL, ...)
 -- : OPTIONS = optimset (OLD, NEW)
     Create options structure for optimization functions.

     When called without any input or output arguments, ‘optimset’
     prints a list of all valid optimization parameters.

     When called with one output and no inputs, return an options
     structure with all valid option parameters initialized to ‘[]’.

     When called with a list of parameter/value pairs, return an options
     structure with only the named parameters initialized.

     When the first input is an existing options structure OLD, the
     values are updated from either the PAR/VAL list or from the options
     structure NEW.

     Valid parameters are:

     AutoScaling

     ComplexEqn

     Display
          Request verbose display of results from optimizations.  Values
          are:

          "off" [default]
               No display.

          "iter"
               Display intermediate results for every loop iteration.

          "final"
               Display the result of the final loop iteration.

          "notify"
               Display the result of the final loop iteration if the
               function has failed to converge.

     FinDiffType

     FunValCheck
          When enabled, display an error if the objective function
          returns an invalid value (a complex number, NaN, or Inf).
          Must be set to "on" or "off" [default].  Note: the functions
          ‘fzero’ and ‘fminbnd’ correctly handle Inf values and only
          complex values or NaN will cause an error in this case.

     GradObj
          When set to "on", the function to be minimized must return a
          second argument which is the gradient, or first derivative, of
          the function at the point X.  If set to "off" [default], the
          gradient is computed via finite differences.

     Jacobian
          When set to "on", the function to be minimized must return a
          second argument which is the Jacobian, or first derivative, of
          the function at the point X.  If set to "off" [default], the
          Jacobian is computed via finite differences.

     MaxFunEvals
          Maximum number of function evaluations before optimization
          stops.  Must be a positive integer.

     MaxIter
          Maximum number of algorithm iterations before optimization
          stops.  Must be a positive integer.

     OutputFcn
          A user-defined function executed once per algorithm iteration.

     TolFun
          Termination criterion for the function output.  If the
          difference in the calculated objective function between one
          algorithm iteration and the next is less than ‘TolFun’ the
          optimization stops.  Must be a positive scalar.

     TolX
          Termination criterion for the function input.  If the
          difference in X, the current search point, between one
          algorithm iteration and the next is less than ‘TolX’ the
          optimization stops.  Must be a positive scalar.

     TypicalX

     Updating

     See also: *note optimget: XREFoptimget.

 -- : optimget (OPTIONS, PARNAME)
 -- : optimget (OPTIONS, PARNAME, DEFAULT)
     Return the specific option PARNAME from the optimization options
     structure OPTIONS created by ‘optimset’.

     If PARNAME is not defined then return DEFAULT if supplied,
     otherwise return an empty matrix.

     See also: *note optimset: XREFoptimset.


File: octave.info,  Node: Statistics,  Next: Sets,  Prev: Optimization,  Up: Top

26 Statistics
*************

Octave has support for various statistical methods.  The emphasis is on
basic descriptive statistics, but the Octave Forge statistics package
includes probability distributions, statistical tests, random number
generation, and much more.

   The functions that analyze data all assume that multi-dimensional
data is arranged in a matrix where each row is an observation, and each
column is a variable.  Thus, the matrix defined by

     a = [ 0.9, 0.7;
           0.1, 0.1;
           0.5, 0.4 ];

contains three observations from a two-dimensional distribution.  While
this is the default data arrangement, most functions support different
arrangements.

   It should be noted that the statistics functions don’t test for data
containing NaN, NA, or Inf.  These values need to be detected and dealt
with explicitly.  See *note isnan: XREFisnan, *note isna: XREFisna,
*note isinf: XREFisinf, *note isfinite: XREFisfinite.

* Menu:

* Descriptive Statistics::
* Basic Statistical Functions::
* Correlation and Regression Analysis::
* Distributions::
* Random Number Generation::


File: octave.info,  Node: Descriptive Statistics,  Next: Basic Statistical Functions,  Up: Statistics

26.1 Descriptive Statistics
===========================

One principal goal of descriptive statistics is to represent the essence
of a large data set concisely.  Octave provides the mean, median, and
mode functions which all summarize a data set with just a single number
corresponding to the central tendency of the data.

 -- : mean (X)
 -- : mean (X, DIM)
 -- : mean (X, OPT)
 -- : mean (X, DIM, OPT)
 -- : mean (..., OUTTYPE)
     Compute the mean of the elements of the vector X.

     The mean is defined as

          mean (X) = SUM_i X(i) / N

     where N is the length of the X vector.

     If X is a matrix, compute the mean for each column and return them
     in a row vector.

     If the optional argument DIM is given, operate along this
     dimension.

     The optional argument OPT selects the type of mean to compute.  The
     following options are recognized:

     "a"
          Compute the (ordinary) arithmetic mean.  [default]

     "g"
          Compute the geometric mean.

     "h"
          Compute the harmonic mean.

     The optional argument OUTTYPE selects the data type of the output
     value.  The following options are recognized:

     "default"
          Output will be of class double unless X is of class single, in
          which case the output will also be single.

     "double"
          Output will be of class double.

     "native"
          Output will be the same class as X unless X is of class
          logical in which case it returns of class double.

     Both DIM and OPT are optional.  If both are supplied, either may
     appear first.

     See also: *note median: XREFmedian, *note mode: XREFmode.

 -- : median (X)
 -- : median (X, DIM)
     Compute the median value of the elements of the vector X.

     When the elements of X are sorted, say ‘S = sort (X)’, the median
     is defined as

                       |  S(ceil(N/2))           N odd
          median (X) = |
                       | (S(N/2) + S(N/2+1))/2   N even

     If X is of a discrete type such as integer or logical, then the
     case of even N rounds up (or toward ‘true’).

     If X is a matrix, compute the median value for each column and
     return them in a row vector.

     If the optional DIM argument is given, operate along this
     dimension.

     See also: *note mean: XREFmean, *note mode: XREFmode.

 -- : mode (X)
 -- : mode (X, DIM)
 -- : [M, F, C] = mode (...)
     Compute the most frequently occurring value in a dataset (mode).

     ‘mode’ determines the frequency of values along the first
     non-singleton dimension and returns the value with the highest
     frequency.  If two, or more, values have the same frequency ‘mode’
     returns the smallest.

     If the optional argument DIM is given, operate along this
     dimension.

     The return variable F is the number of occurrences of the mode in
     the dataset.

     The cell array C contains all of the elements with the maximum
     frequency.

     See also: *note mean: XREFmean, *note median: XREFmedian.

   Using just one number, such as the mean, to represent an entire data
set may not give an accurate picture of the data.  One way to
characterize the fit is to measure the dispersion of the data.  Octave
provides several functions for measuring dispersion.

 -- : [S, L] = bounds (X)
 -- : [S, L] = bounds (X, DIM)
 -- : [S, L] = bounds (..., "nanflag")
     Return the smallest and largest values of the input data X.

     If X is a vector, the bounds are calculated over the elements of X.
     If X is a matrix, the bounds are calculated for each column.  For a
     multi-dimensional array, the bounds are calculated over the first
     non-singleton dimension.

     If the optional argument DIM is given, operate along this
     dimension.

     The optional argument "nanflag" defaults to "omitnan" which does
     not include NaN values in the result.  If the argument "includenan"
     is given, and there is a NaN present, then the result for both
     smallest (S) and largest (L) elements will be NaN.

     The bounds are a quickly computed measure of the dispersion of a
     data set, but are less accurate than ‘iqr’ if there are outlying
     data points.

     See also: *note range: XREFrange, *note iqr: XREFiqr, *note mad:
     XREFmad, *note std: XREFstd.

 -- : range (X)
 -- : range (X, DIM)
     Return the range, i.e., the difference between the maximum and the
     minimum of the input data.

     If X is a vector, the range is calculated over the elements of X.
     If X is a matrix, the range is calculated over each column of X.

     If the optional argument DIM is given, operate along this
     dimension.

     The range is a quickly computed measure of the dispersion of a data
     set, but is less accurate than ‘iqr’ if there are outlying data
     points.

     See also: *note bounds: XREFbounds, *note iqr: XREFiqr, *note mad:
     XREFmad, *note std: XREFstd.

 -- : iqr (X)
 -- : iqr (X, DIM)
     Return the interquartile range, i.e., the difference between the
     upper and lower quartile of the input data.

     If X is a matrix, do the above for first non-singleton dimension of
     X.

     If the optional argument DIM is given, operate along this
     dimension.

     As a measure of dispersion, the interquartile range is less
     affected by outliers than either ‘range’ or ‘std’.

     See also: *note bounds: XREFbounds, *note mad: XREFmad, *note
     range: XREFrange, *note std: XREFstd.

 -- : mad (X)
 -- : mad (X, OPT)
 -- : mad (X, OPT, DIM)
     Compute the mean or median absolute deviation of the elements of X.

     The mean absolute deviation is defined as

          MAD = mean (abs (X - mean (X)))

     The median absolute deviation is defined as

          MAD = median (abs (X - median (X)))

     If X is a matrix, compute ‘mad’ for each column and return results
     in a row vector.  For a multi-dimensional array, the calculation is
     done over the first non-singleton dimension.

     The optional argument OPT determines whether mean or median
     absolute deviation is calculated.  The default is 0 which
     corresponds to mean absolute deviation; A value of 1 corresponds to
     median absolute deviation.

     If the optional argument DIM is given, operate along this
     dimension.

     As a measure of dispersion, ‘mad’ is less affected by outliers than
     ‘std’.

     See also: *note bounds: XREFbounds, *note range: XREFrange, *note
     iqr: XREFiqr, *note std: XREFstd, *note mean: XREFmean, *note
     median: XREFmedian.

 -- : meansq (X)
 -- : meansq (X, DIM)
     Compute the mean square of the elements of the vector X.

     The mean square is defined as

          meansq (X) = 1/N SUM_i X(i)^2

     where N is the length of the X vector.

     If X is a matrix, return a row vector containing the mean square of
     each column.

     If the optional argument DIM is given, operate along this
     dimension.

     See also: *note var: XREFvar, *note std: XREFstd, *note moment:
     XREFmoment.

 -- : std (X)
 -- : std (X, OPT)
 -- : std (X, OPT, DIM)
     Compute the standard deviation of the elements of the vector X.

     The standard deviation is defined as

          std (X) = sqrt ( 1/(N-1) SUM_i (X(i) - mean(X))^2 )

     where N is the number of elements of the X vector.

     If X is a matrix, compute the standard deviation for each column
     and return them in a row vector.

     The argument OPT determines the type of normalization to use.
     Valid values are

     0:
          normalize with N-1, provides the square root of the best
          unbiased estimator of the variance [default]

     1:
          normalize with N, this provides the square root of the second
          moment around the mean

     If the optional argument DIM is given, operate along this
     dimension.

     See also: *note var: XREFvar, *note bounds: XREFbounds, *note mad:
     XREFmad, *note range: XREFrange, *note iqr: XREFiqr, *note mean:
     XREFmean, *note median: XREFmedian.

   In addition to knowing the size of a dispersion it is useful to know
the shape of the data set.  For example, are data points massed to the
left or right of the mean?  Octave provides several common measures to
describe the shape of the data set.  Octave can also calculate moments
allowing arbitrary shape measures to be developed.

 -- : var (X)
 -- : var (X, OPT)
 -- : var (X, OPT, DIM)
     Compute the variance of the elements of the vector X.

     The variance is defined as

          var (X) = 1/(N-1) SUM_i (X(i) - mean(X))^2

     where N is the length of the X vector.

     If X is a matrix, compute the variance for each column and return
     them in a row vector.

     The argument OPT determines the type of normalization to use.
     Valid values are

     0:
          normalize with N-1, provides the best unbiased estimator of
          the variance [default]

     1:
          normalizes with N, this provides the second moment around the
          mean

     If N is equal to 1 the value of OPT is ignored and normalization by
     N is used.

     If the optional argument DIM is given, operate along this
     dimension.

     See also: *note cov: XREFcov, *note std: XREFstd, *note skewness:
     XREFskewness, *note kurtosis: XREFkurtosis, *note moment:
     XREFmoment.

 -- : skewness (X)
 -- : skewness (X, FLAG)
 -- : skewness (X, FLAG, DIM)
     Compute the sample skewness of the elements of X.

     The sample skewness is defined as

                         mean ((X - mean (X)).^3)
          skewness (X) = ------------------------.
                                std (X).^3

     The optional argument FLAG controls which normalization is used.
     If FLAG is equal to 1 (default value, used when FLAG is omitted or
     empty), return the sample skewness as defined above.  If FLAG is
     equal to 0, return the adjusted skewness coefficient instead:

                            sqrt (N*(N-1))   mean ((X - mean (X)).^3)
          skewness (X, 0) = -------------- * ------------------------.
                                (N - 2)             std (X).^3

     where N is the length of the X vector.

     The adjusted skewness coefficient is obtained by replacing the
     sample second and third central moments by their bias-corrected
     versions.

     If X is a matrix, or more generally a multi-dimensional array,
     return the skewness along the first non-singleton dimension.  If
     the optional DIM argument is given, operate along this dimension.

     See also: *note var: XREFvar, *note kurtosis: XREFkurtosis, *note
     moment: XREFmoment.

 -- : kurtosis (X)
 -- : kurtosis (X, FLAG)
 -- : kurtosis (X, FLAG, DIM)
     Compute the sample kurtosis of the elements of X.

     The sample kurtosis is defined as

               mean ((X - mean (X)).^4)
          k1 = ------------------------
                      std (X).^4

     The optional argument FLAG controls which normalization is used.
     If FLAG is equal to 1 (default value, used when FLAG is omitted or
     empty), return the sample kurtosis as defined above.  If FLAG is
     equal to 0, return the "bias-corrected" kurtosis coefficient
     instead:

                        N - 1
          k0 = 3 + -------------- * ((N + 1) * k1 - 3 * (N - 1))
                   (N - 2)(N - 3)

     where N is the length of the X vector.

     The bias-corrected kurtosis coefficient is obtained by replacing
     the sample second and fourth central moments by their unbiased
     versions.  It is an unbiased estimate of the population kurtosis
     for normal populations.

     If X is a matrix, or more generally a multi-dimensional array,
     return the kurtosis along the first non-singleton dimension.  If
     the optional DIM argument is given, operate along this dimension.

     See also: *note var: XREFvar, *note skewness: XREFskewness, *note
     moment: XREFmoment.

 -- : moment (X, P)
 -- : moment (X, P, TYPE)
 -- : moment (X, P, DIM)
 -- : moment (X, P, TYPE, DIM)
 -- : moment (X, P, DIM, TYPE)
     Compute the P-th central moment of the vector X.

     The P-th central moment of X is defined as:

          1/N SUM_i (X(i) - mean(X))^P

     where N is the length of the X vector.

     If X is a matrix, return the row vector containing the P-th central
     moment of each column.

     If the optional argument DIM is given, operate along this
     dimension.

     The optional string TYPE specifies the type of moment to be
     computed.  Valid options are:

     "c"
          Central Moment (default).

     "a"
     "ac"
          Absolute Central Moment.  The moment about the mean ignoring
          sign defined as

               1/N SUM_i (abs (X(i) - mean(X)))^P

     "r"
          Raw Moment.  The moment about zero defined as

               moment (X) = 1/N SUM_i X(i)^P

     "ar"
          Absolute Raw Moment.  The moment about zero ignoring sign
          defined as

               1/N SUM_i ( abs (X(i)) )^P

     If both TYPE and DIM are given they may appear in any order.

     See also: *note var: XREFvar, *note skewness: XREFskewness, *note
     kurtosis: XREFkurtosis.

 -- : Q = quantile (X)
 -- : Q = quantile (X, P)
 -- : Q = quantile (X, P, DIM)
 -- : Q = quantile (X, P, DIM, METHOD)
     For a sample, X, calculate the quantiles, Q, corresponding to the
     cumulative probability values in P.  All non-numeric values (NaNs)
     of X are ignored.

     If X is a matrix, compute the quantiles for each column and return
     them in a matrix, such that the i-th row of Q contains the P(i)th
     quantiles of each column of X.

     If P is unspecified, return the quantiles for ‘[0.00 0.25 0.50 0.75
     1.00]’.  The optional argument DIM determines the dimension along
     which the quantiles are calculated.  If DIM is omitted it defaults
     to the first non-singleton dimension.

     The methods available to calculate sample quantiles are the nine
     methods used by R (<https://www.r-project.org/>).  The default
     value is METHOD = 5.

     Discontinuous sample quantile methods 1, 2, and 3

       1. Method 1: Inverse of empirical distribution function.

       2. Method 2: Similar to method 1 but with averaging at
          discontinuities.

       3. Method 3: SAS definition: nearest even order statistic.

     Continuous sample quantile methods 4 through 9, where P(k) is the
     linear interpolation function respecting each method’s
     representative cdf.

       4. Method 4: P(k) = k / N. That is, linear interpolation of the
          empirical cdf, where N is the length of P.

       5. Method 5: P(k) = (k - 0.5) / N. That is, a piecewise linear
          function where the knots are the values midway through the
          steps of the empirical cdf.

       6. Method 6: P(k) = k / (N + 1).

       7. Method 7: P(k) = (k - 1) / (N - 1).

       8. Method 8: P(k) = (k - 1/3) / (N + 1/3).  The resulting
          quantile estimates are approximately median-unbiased
          regardless of the distribution of X.

       9. Method 9: P(k) = (k - 3/8) / (N + 1/4).  The resulting
          quantile estimates are approximately unbiased for the expected
          order statistics if X is normally distributed.

     Hyndman and Fan (1996) recommend method 8.  Maxima, S, and R
     (versions prior to 2.0.0) use 7 as their default.  Minitab and SPSS
     use method 6.  MATLAB uses method 5.

     References:

        • Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) The New
          S Language.  Wadsworth & Brooks/Cole.

        • Hyndman, R. J. and Fan, Y. (1996) Sample quantiles in
          statistical packages, American Statistician, 50, 361–365.

        • R: A Language and Environment for Statistical Computing;
          <https://cran.r-project.org/doc/manuals/fullrefman.pdf>.

     Examples:

          x = randi (1000, [10, 1]);  # Create empirical data in range 1-1000
          q = quantile (x, [0, 1]);   # Return minimum, maximum of distribution
          q = quantile (x, [0.25 0.5 0.75]); # Return quartiles of distribution

     See also: *note prctile: XREFprctile.

 -- : Q = prctile (X)
 -- : Q = prctile (X, P)
 -- : Q = prctile (X, P, DIM)
     For a sample X, compute the quantiles, Q, corresponding to the
     cumulative probability values, P, in percent.

     If X is a matrix, compute the percentiles for each column and
     return them in a matrix, such that the i-th row of Q contains the
     P(i)th percentiles of each column of X.

     If P is unspecified, return the quantiles for ‘[0 25 50 75 100]’.

     The optional argument DIM determines the dimension along which the
     percentiles are calculated.  If DIM is omitted it defaults to the
     first non-singleton dimension.

     Programming Note: All non-numeric values (NaNs) of X are ignored.

     See also: *note quantile: XREFquantile.

   A summary view of a data set can be generated quickly with the
‘statistics’ function.

 -- : statistics (X)
 -- : statistics (X, DIM)
     Return a vector with the minimum, first quartile, median, third
     quartile, maximum, mean, standard deviation, skewness, and kurtosis
     of the elements of the vector X.

     If X is a matrix, calculate statistics over the first non-singleton
     dimension.

     If the optional argument DIM is given, operate along this
     dimension.

     See also: *note min: XREFmin, *note max: XREFmax, *note median:
     XREFmedian, *note mean: XREFmean, *note std: XREFstd, *note
     skewness: XREFskewness, *note kurtosis: XREFkurtosis.


File: octave.info,  Node: Basic Statistical Functions,  Next: Correlation and Regression Analysis,  Prev: Descriptive Statistics,  Up: Statistics

26.2 Basic Statistical Functions
================================

Octave supports various helpful statistical functions.  Many are useful
as initial steps to prepare a data set for further analysis.  Others
provide different measures from those of the basic descriptive
statistics.

 -- : center (X)
 -- : center (X, DIM)
     Center data by subtracting its mean.

     If X is a vector, subtract its mean.

     If X is a matrix, do the above for each column.

     If the optional argument DIM is given, operate along this
     dimension.

     Programming Note: ‘center’ has obvious application for normalizing
     statistical data.  It is also useful for improving the precision of
     general numerical calculations.  Whenever there is a large value
     that is common to a batch of data, the mean can be subtracted off,
     the calculation performed, and then the mean added back to obtain
     the final answer.

     See also: *note zscore: XREFzscore.

 -- : Z = zscore (X)
 -- : Z = zscore (X, OPT)
 -- : Z = zscore (X, OPT, DIM)
 -- : [Z, MU, SIGMA] = zscore (...)
     Compute the Z score of X.

     If X is a vector, subtract its mean and divide by its standard
     deviation.  If the standard deviation is zero, divide by 1 instead.

     The optional parameter OPT determines the normalization to use when
     computing the standard deviation and has the same definition as the
     corresponding parameter for ‘std’.

     If X is a matrix, calculate along the first non-singleton
     dimension.  If the third optional argument DIM is given, operate
     along this dimension.

     The optional outputs MU and SIGMA contain the mean and standard
     deviation.

     See also: *note mean: XREFmean, *note std: XREFstd, *note center:
     XREFcenter.

 -- : N = histc (X, EDGES)
 -- : N = histc (X, EDGES, DIM)
 -- : [N, IDX] = histc (...)
     Compute histogram counts.

     When X is a vector, the function counts the number of elements of X
     that fall in the histogram bins defined by EDGES.  This must be a
     vector of monotonically increasing values that define the edges of
     the histogram bins.  ‘N(k)’ contains the number of elements in X
     for which ‘EDGES(k) <= X < EDGES(k+1)’.  The final element of N
     contains the number of elements of X exactly equal to the last
     element of EDGES.

     When X is an N-dimensional array, the computation is carried out
     along dimension DIM.  If not specified DIM defaults to the first
     non-singleton dimension.

     When a second output argument is requested an index matrix is also
     returned.  The IDX matrix has the same size as X.  Each element of
     IDX contains the index of the histogram bin in which the
     corresponding element of X was counted.

     See also: *note hist: XREFhist.

‘unique’ function documented at *note unique: XREFunique. is often
useful for statistics.

 -- : C = nchoosek (N, K)
 -- : C = nchoosek (SET, K)

     Compute the binomial coefficient of N or list all possible
     combinations of a SET of items.

     If N is a scalar then calculate the binomial coefficient of N and K
     which is defined as

           /   \
           | n |    n (n-1) (n-2) ... (n-k+1)       n!
           |   |  = ------------------------- =  ---------
           | k |               k!                k! (n-k)!
           \   /

     This is the number of combinations of N items taken in groups of
     size K.

     If the first argument is a vector, SET, then generate all
     combinations of the elements of SET, taken K at a time, with one
     row per combination.  The result C has K columns and
     ‘nchoosek (length (SET), K)’ rows.

     For example:

     How many ways can three items be grouped into pairs?

          nchoosek (3, 2)
             ⇒ 3

     What are the possible pairs?

          nchoosek (1:3, 2)
             ⇒  1   2
                 1   3
                 2   3

     Programming Note: When calculating the binomial coefficient
     ‘nchoosek’ works only for non-negative, integer arguments.  Use
     ‘bincoeff’ for non-integer and negative scalar arguments, or for
     computing many binomial coefficients at once with vector inputs for
     N or K.

     See also: *note bincoeff: XREFbincoeff, *note perms: XREFperms.

 -- : perms (V)
     Generate all permutations of vector V with one row per permutation.

     Results are returned in inverse lexicographic order.  The result
     has size ‘factorial (N) * N’, where N is the length of V.  Any
     repetitions are included in the output.  To generate just the
     unique permutations use ‘unique (perms (V), "rows")(end:-1:1,:)’.

     Example

          perms ([1, 2, 3])
          ⇒
            3   2   1
            3   1   2
            2   3   1
            2   1   3
            1   3   2
            1   2   3

     Programming Note: The maximum length of V should be less than or
     equal to 10 to limit memory consumption.

     See also: *note permute: XREFpermute, *note randperm: XREFrandperm,
     *note nchoosek: XREFnchoosek.

 -- : ranks (X, DIM)
     Return the ranks of X along the first non-singleton dimension
     adjusted for ties.

     If the optional argument DIM is given, operate along this
     dimension.

     See also: *note spearman: XREFspearman, *note kendall: XREFkendall.

 -- : run_count (X, N)
 -- : run_count (X, N, DIM)
     Count the upward runs along the first non-singleton dimension of X
     of length 1, 2, ..., N-1 and greater than or equal to N.

     If the optional argument DIM is given then operate along this
     dimension.

     See also: *note runlength: XREFrunlength.

 -- : count = runlength (X)
 -- : [count, value] = runlength (X)
     Find the lengths of all sequences of common values.

     COUNT is a vector with the lengths of each repeated value.

     The optional output VALUE contains the value that was repeated in
     the sequence.

          runlength ([2, 2, 0, 4, 4, 4, 0, 1, 1, 1, 1])
          ⇒  [2, 1, 3, 1, 4]

     See also: *note run_count: XREFrun_count.


File: octave.info,  Node: Correlation and Regression Analysis,  Next: Distributions,  Prev: Basic Statistical Functions,  Up: Statistics

26.3 Correlation and Regression Analysis
========================================

 -- : cov (X)
 -- : cov (X, OPT)
 -- : cov (X, Y)
 -- : cov (X, Y, OPT)
     Compute the covariance matrix.

     If each row of X and Y is an observation, and each column is a
     variable, then the (I, J)-th entry of ‘cov (X, Y)’ is the
     covariance between the I-th variable in X and the J-th variable in
     Y.

          cov (X) = 1/(N-1) * SUM_i (X(i) - mean(X)) * (Y(i) - mean(Y))

     where N is the length of the X and Y vectors.

     If called with one argument, compute ‘cov (X, X)’, the covariance
     between the columns of X.

     The argument OPT determines the type of normalization to use.
     Valid values are

     0:
          normalize with N-1, provides the best unbiased estimator of
          the covariance [default]

     1:
          normalize with N, this provides the second moment around the
          mean

     Compatibility Note:: Octave always treats rows of X and Y as
     multivariate random variables.  For two inputs, however, MATLAB
     treats X and Y as two univariate distributions regardless of their
     shapes, and will calculate ‘cov ([X(:), Y(:)])’ whenever the number
     of elements in X and Y are equal.  This will result in a 2x2
     matrix.  Code relying on MATLAB’s definition will need to be
     changed when running in Octave.

     See also: *note corr: XREFcorr.

 -- : corr (X)
 -- : corr (X, Y)
     Compute matrix of correlation coefficients.

     If each row of X and Y is an observation and each column is a
     variable, then the (I, J)-th entry of ‘corr (X, Y)’ is the
     correlation between the I-th variable in X and the J-th variable in
     Y.

          corr (X,Y) = cov (X,Y) / (std (X) * std (Y))

     If called with one argument, compute ‘corr (X, X)’, the correlation
     between the columns of X.

     See also: *note cov: XREFcov.

 -- : R = corrcoef (X)
 -- : R = corrcoef (X, Y)
 -- : [R, P] = corrcoef (...)
 -- : [R, P, LCI, HCI] = corrcoef (...)
 -- : [...] = corrcoef (..., PARAM, VALUE, ...)
     Compute a matrix of correlation coefficients.

     X is an array where each column contains a variable and each row is
     an observation.

     If a second input Y (of the same size as X) is given then calculate
     the correlation coefficients between X and Y.

     R is a matrix of Pearson’s product moment correlation coefficients
     for each pair of variables.

     P is a matrix of pair-wise p-values testing for the null hypothesis
     of a correlation coefficient of zero.

     LCI and HCI are matrices containing, respectively, the lower and
     higher bounds of the 95% confidence interval of each correlation
     coefficient.

     PARAM, VALUE are pairs of optional parameters and values.  Valid
     options are:

     "alpha"
          Confidence level used for the definition of the bounds of the
          confidence interval, LCI and HCI.  Default is 0.05, i.e., 95%
          confidence interval.

     "rows"
          Determine processing of NaN values.  Acceptable values are
          "all", "complete", and "pairwise".  Default is "all".  With
          "complete", only the rows without NaN values are considered.
          With "pairwise", the selection of NaN-free rows is made for
          each pair of variables.

     See also: *note corr: XREFcorr, *note cov: XREFcov.

 -- : spearman (X)
 -- : spearman (X, Y)
     Compute Spearman’s rank correlation coefficient RHO.

     For two data vectors X and Y, Spearman’s RHO is the correlation
     coefficient of the ranks of X and Y.

     If X and Y are drawn from independent distributions, RHO has zero
     mean and variance ‘1 / (N - 1)’, where N is the length of the X and
     Y vectors, and is asymptotically normally distributed.

     ‘spearman (X)’ is equivalent to ‘spearman (X, X)’.

     See also: *note ranks: XREFranks, *note kendall: XREFkendall.

 -- : kendall (X)
 -- : kendall (X, Y)
     Compute Kendall’s TAU.

     For two data vectors X, Y of common length N, Kendall’s TAU is the
     correlation of the signs of all rank differences of X and Y; i.e.,
     if both X and Y have distinct entries, then

                   1
          TAU = -------   SUM sign (Q(i) - Q(j)) * sign (R(i) - R(j))
                N (N-1)   i,j

     in which the Q(i) and R(i) are the ranks of X and Y, respectively.

     If X and Y are drawn from independent distributions, Kendall’s TAU
     is asymptotically normal with mean 0 and variance ‘(2 * (2N+5)) /
     (9 * N * (N-1))’.

     ‘kendall (X)’ is equivalent to ‘kendall (X, X)’.

     See also: *note ranks: XREFranks, *note spearman: XREFspearman.


File: octave.info,  Node: Distributions,  Next: Random Number Generation,  Prev: Correlation and Regression Analysis,  Up: Statistics

26.4 Distributions
==================

Octave has functions for computing the Probability Density Function
(PDF), the Cumulative Distribution function (CDF), and the quantile (the
inverse of the CDF) for arbitrary user-defined distributions (discrete)
and for experimental data (empirical).

   The following table summarizes the supported distributions (in
alphabetical order).

Distribution           PDF               CDF               Quantile
-----------------------------------------------------------------------------
Univariate Discrete    ‘discrete_pdf’    ‘discrete_cdf’    ‘discrete_inv’
Distribution
Empirical              ‘empirical_pdf’   ‘empirical_cdf’   ‘empirical_inv’
Distribution

 -- : discrete_pdf (X, V, P)
     For each element of X, compute the probability density function
     (PDF) at X of a univariate discrete distribution which assumes the
     values in V with probabilities P.

 -- : discrete_cdf (X, V, P)
     For each element of X, compute the cumulative distribution function
     (CDF) at X of a univariate discrete distribution which assumes the
     values in V with probabilities P.

 -- : discrete_inv (X, V, P)
     For each element of X, compute the quantile (the inverse of the
     CDF) at X of the univariate distribution which assumes the values
     in V with probabilities P.

 -- : empirical_pdf (X, DATA)
     For each element of X, compute the probability density function
     (PDF) at X of the empirical distribution obtained from the
     univariate sample DATA.

 -- : empirical_cdf (X, DATA)
     For each element of X, compute the cumulative distribution function
     (CDF) at X of the empirical distribution obtained from the
     univariate sample DATA.

 -- : empirical_inv (X, DATA)
     For each element of X, compute the quantile (the inverse of the
     CDF) at X of the empirical distribution obtained from the
     univariate sample DATA.


File: octave.info,  Node: Random Number Generation,  Prev: Distributions,  Up: Statistics

26.5 Random Number Generation
=============================

Octave can generate random numbers from a large number of distributions.
The random number generators are based on the random number generators
described in *note Special Utility Matrices::.

   The following table summarizes the available random number generators
(in alphabetical order).

Distribution                  Function
-----------------------------------------------------
Univariate Discrete           ‘discrete_rnd’
Distribution
Empirical Distribution        ‘empirical_rnd’
Exponential Distribution      ‘rande’
Gamma Distribution            ‘randg’
Poisson Distribution          ‘randp’
Standard Normal               ‘randn’
Distribution
Uniform Distribution          ‘rand’
Uniform Distribution          ‘randi’
(integers)

 -- : discrete_rnd (V, P)
 -- : discrete_rnd (V, P, R)
 -- : discrete_rnd (V, P, R, C, ...)
 -- : discrete_rnd (V, P, [SZ])
     Return a matrix of random samples from the univariate distribution
     which assumes the values in V with probabilities P.

     When called with a single size argument, return a square matrix
     with the dimension specified.  When called with more than one
     scalar argument the first two arguments are taken as the number of
     rows and columns and any further arguments specify additional
     matrix dimensions.  The size may also be specified with a vector of
     dimensions SZ.

     If no size arguments are given then the result matrix is the common
     size of V and P.

 -- : empirical_rnd (DATA)
 -- : empirical_rnd (DATA, R)
 -- : empirical_rnd (DATA, R, C, ...)
 -- : empirical_rnd (DATA, [SZ])
     Return a matrix of random samples from the empirical distribution
     obtained from the univariate sample DATA.

     When called with a single size argument, return a square matrix
     with the dimension specified.  When called with more than one
     scalar argument the first two arguments are taken as the number of
     rows and columns and any further arguments specify additional
     matrix dimensions.  The size may also be specified with a vector of
     dimensions SZ.

     If no size arguments are given then the result matrix is a random
     ordering of the sample DATA.


File: octave.info,  Node: Sets,  Next: Polynomial Manipulations,  Prev: Statistics,  Up: Top

27 Sets
*******

Octave has a number of functions for managing sets of data.  A set is
defined as a collection of unique elements and is typically represented
by a vector of numbers sorted in ascending order.  Any vector or matrix
can be converted to a set by removing duplicates through the use of the
‘unique’ function.  However, it isn’t necessary to explicitly create a
set as all of the functions which operate on sets will convert their
input to a set before proceeding.

 -- : unique (X)
 -- : unique (X, "rows")
 -- : [Y, I, J] = unique (...)
 -- : [Y, I, J] = unique (..., "first")
 -- : [Y, I, J] = unique (..., "last")
     Return the unique elements of X sorted in ascending order.

     If the input X is a column vector then return a column vector;
     Otherwise, return a row vector.  X may also be a cell array of
     strings.

     If the optional argument "rows" is given then return the unique
     rows of X sorted in ascending order.  The input must be a 2-D
     matrix to use this option.

     If requested, return index vectors I and J such that ‘Y = X(I)’ and
     ‘X = Y(J)’.

     Additionally, if I is a requested output then one of "first" or
     "last" may be given as an input.  If "last" is specified, return
     the highest possible indices in I, otherwise, if "first" is
     specified, return the lowest.  The default is "last".

     See also: *note union: XREFunion, *note intersect: XREFintersect,
     *note setdiff: XREFsetdiff, *note setxor: XREFsetxor, *note
     ismember: XREFismember.

* Menu:

* Set Operations::


File: octave.info,  Node: Set Operations,  Up: Sets

27.1 Set Operations
===================

Octave supports several basic set operations.  Octave can compute the
union, intersection, and difference of two sets.  Octave also supports
the _Exclusive Or_ set operation.

   The functions for set operations all work in the same way by
accepting two input sets and returning a third set.  As an example,
assume that ‘a’ and ‘b’ contains two sets, then

     union (a, b)

computes the union of the two sets.

   Finally, determining whether elements belong to a set can be done
with the ‘ismember’ function.  Because sets are ordered this operation
is very efficient and is of order O(log2(n)) which is preferable to the
‘find’ function which is of order O(n).

 -- : C = intersect (A, B)
 -- : C = intersect (A, B, "rows")
 -- : [C, IA, IB] = intersect (...)

     Return the unique elements common to both A and B sorted in
     ascending order.

     If A and B are both row vectors then return a row vector;
     Otherwise, return a column vector.  The inputs may also be cell
     arrays of strings.

     If the optional input "rows" is given then return the common rows
     of A and B.  The inputs must be 2-D matrices to use this option.

     If requested, return index vectors IA and IB such that ‘C = A(IA)’
     and ‘C = B(IB)’.

     See also: *note unique: XREFunique, *note union: XREFunion, *note
     setdiff: XREFsetdiff, *note setxor: XREFsetxor, *note ismember:
     XREFismember.

 -- : C = union (A, B)
 -- : C = union (A, B, "rows")
 -- : [C, IA, IB] = union (...)

     Return the unique elements that are in either A or B sorted in
     ascending order.

     If A and B are both row vectors then return a row vector;
     Otherwise, return a column vector.  The inputs may also be cell
     arrays of strings.

     If the optional input "rows" is given then return rows that are in
     either A or B.  The inputs must be 2-D matrices to use this option.

     The optional outputs IA and IB are index vectors such that ‘A(IA)’
     and ‘B(IB)’ are disjoint sets whose union is C.

     See also: *note unique: XREFunique, *note intersect: XREFintersect,
     *note setdiff: XREFsetdiff, *note setxor: XREFsetxor, *note
     ismember: XREFismember.

 -- : C = setdiff (A, B)
 -- : C = setdiff (A, B, "rows")
 -- : [C, IA] = setdiff (...)
     Return the unique elements in A that are not in B sorted in
     ascending order.

     If A is a row vector return a row vector; Otherwise, return a
     column vector.  The inputs may also be cell arrays of strings.

     If the optional input "rows" is given then return the rows in A
     that are not in B.  The inputs must be 2-D matrices to use this
     option.

     If requested, return the index vector IA such that ‘C = A(IA)’.

     See also: *note unique: XREFunique, *note union: XREFunion, *note
     intersect: XREFintersect, *note setxor: XREFsetxor, *note ismember:
     XREFismember.

 -- : C = setxor (A, B)
 -- : C = setxor (A, B, "rows")
 -- : [C, IA, IB] = setxor (...)

     Return the unique elements exclusive to sets A or B sorted in
     ascending order.

     If A and B are both row vectors then return a row vector;
     Otherwise, return a column vector.  The inputs may also be cell
     arrays of strings.

     If the optional input "rows" is given then return the rows
     exclusive to sets A and B.  The inputs must be 2-D matrices to use
     this option.

     If requested, return index vectors IA and IB such that ‘A(IA)’ and
     ‘B(IB)’ are disjoint sets whose union is C.

     See also: *note unique: XREFunique, *note union: XREFunion, *note
     intersect: XREFintersect, *note setdiff: XREFsetdiff, *note
     ismember: XREFismember.

 -- : TF = ismember (A, S)
 -- : TF = ismember (A, S, "rows")
 -- : [TF, S_IDX] = ismember (...)

     Return a logical matrix TF with the same shape as A which is true
     (1) if the element in A is found in S and false (0) if it is not.

     If a second output argument is requested then the index into S of
     each matching element is also returned.

          a = [3, 10, 1];
          s = [0:9];
          [tf, s_idx] = ismember (a, s)
               ⇒ tf = [1, 0, 1]
               ⇒ s_idx = [4, 0, 2]

     The inputs A and S may also be cell arrays.

          a = {"abc"};
          s = {"abc", "def"};
          [tf, s_idx] = ismember (a, s)
               ⇒ tf = [1, 0]
               ⇒ s_idx = [1, 0]

     If the optional third argument "rows" is given then compare rows in
     A with rows in S.  The inputs must be 2-D matrices with the same
     number of columns to use this option.

          a = [1:3; 5:7; 4:6];
          s = [0:2; 1:3; 2:4; 3:5; 4:6];
          [tf, s_idx] = ismember (a, s, "rows")
               ⇒ tf = logical ([1; 0; 1])
               ⇒ s_idx = [2; 0; 5];

     See also: *note lookup: XREFlookup, *note unique: XREFunique, *note
     union: XREFunion, *note intersect: XREFintersect, *note setdiff:
     XREFsetdiff, *note setxor: XREFsetxor.

 -- : powerset (A)
 -- : powerset (A, "rows")
     Compute the powerset (all subsets) of the set A.

     The set A must be a numerical matrix or a cell array of strings.
     The output will always be a cell array of either vectors or
     strings.

     With the optional argument "rows", each row of the set A is
     considered one element of the set.  The input must be a 2-D numeric
     matrix to use this argument.

     See also: *note unique: XREFunique, *note union: XREFunion, *note
     intersect: XREFintersect, *note setdiff: XREFsetdiff, *note setxor:
     XREFsetxor, *note ismember: XREFismember.


File: octave.info,  Node: Polynomial Manipulations,  Next: Interpolation,  Prev: Sets,  Up: Top

28 Polynomial Manipulations
***************************

In Octave, a polynomial is represented by its coefficients (arranged in
descending order).  For example, a vector C of length N+1 corresponds to
the following polynomial of order N

     p(x) = C(1) x^N + ... + C(N) x + C(N+1).

* Menu:

* Evaluating Polynomials::
* Finding Roots::
* Products of Polynomials::
* Derivatives / Integrals / Transforms::
* Polynomial Interpolation::
* Miscellaneous Functions::


File: octave.info,  Node: Evaluating Polynomials,  Next: Finding Roots,  Up: Polynomial Manipulations

28.1 Evaluating Polynomials
===========================

The value of a polynomial represented by the vector C can be evaluated
at the point X very easily, as the following example shows:

     N = length (c) - 1;
     val = dot (x.^(N:-1:0), c);

While the above example shows how easy it is to compute the value of a
polynomial, it isn’t the most stable algorithm.  With larger polynomials
you should use more elegant algorithms, such as Horner’s Method, which
is exactly what the Octave function ‘polyval’ does.

   In the case where X is a square matrix, the polynomial given by C is
still well-defined.  As when X is a scalar the obvious implementation is
easily expressed in Octave, but also in this case more elegant
algorithms perform better.  The ‘polyvalm’ function provides such an
algorithm.

 -- : Y = polyval (P, X)
 -- : Y = polyval (P, X, [], MU)
 -- : [Y, DY] = polyval (P, X, S)
 -- : [Y, DY] = polyval (P, X, S, MU)

     Evaluate the polynomial P at the specified values of X.

     If X is a vector or matrix, the polynomial is evaluated for each of
     the elements of X.

     When MU is present, evaluate the polynomial for (X-MU(1))/MU(2).

     In addition to evaluating the polynomial, the second output
     represents the prediction interval, Y +/- DY, which contains at
     least 50% of the future predictions.  To calculate the prediction
     interval, the structured variable S, originating from ‘polyfit’,
     must be supplied.

     See also: *note polyvalm: XREFpolyvalm, *note polyaffine:
     XREFpolyaffine, *note polyfit: XREFpolyfit, *note roots: XREFroots,
     *note poly: XREFpoly.

 -- : polyvalm (C, X)
     Evaluate a polynomial in the matrix sense.

     ‘polyvalm (C, X)’ will evaluate the polynomial in the matrix sense,
     i.e., matrix multiplication is used instead of element by element
     multiplication as used in ‘polyval’.

     The argument X must be a square matrix.

     See also: *note polyval: XREFpolyval, *note roots: XREFroots, *note
     poly: XREFpoly.


File: octave.info,  Node: Finding Roots,  Next: Products of Polynomials,  Prev: Evaluating Polynomials,  Up: Polynomial Manipulations

28.2 Finding Roots
==================

Octave can find the roots of a given polynomial.  This is done by
computing the companion matrix of the polynomial (see the ‘compan’
function for a definition), and then finding its eigenvalues.

 -- : roots (C)

     Compute the roots of the polynomial C.

     For a vector C with N components, return the roots of the
     polynomial

          c(1) * x^(N-1) + ... + c(N-1) * x + c(N)

     As an example, the following code finds the roots of the quadratic
     polynomial

          p(x) = x^2 - 5.

          c = [1, 0, -5];
          roots (c)
          ⇒  2.2361
          ⇒ -2.2361

     Note that the true result is +/- sqrt(5) which is roughly +/-
     2.2361.

     See also: *note poly: XREFpoly, *note compan: XREFcompan, *note
     fzero: XREFfzero.

 -- : Z = polyeig (C0, C1, ..., CL)
 -- : [V, Z] = polyeig (C0, C1, ..., CL)

     Solve the polynomial eigenvalue problem of degree L.

     Given an N*N matrix polynomial

     ‘C(s) = C0 + C1 s + ... + CL s^l’

     ‘polyeig’ solves the eigenvalue problem

     ‘(C0 + C1 + ... + CL)v = 0’.

     Note that the eigenvalues Z are the zeros of the matrix polynomial.
     Z is a row vector with N*L elements.  V is a matrix (N x N*L) with
     columns that correspond to the eigenvectors.

     See also: *note eig: XREFeig, *note eigs: XREFeigs, *note compan:
     XREFcompan.

 -- : compan (C)
     Compute the companion matrix corresponding to polynomial
     coefficient vector C.

     The companion matrix is

               _                                                        _
              |  -c(2)/c(1)   -c(3)/c(1)  ...  -c(N)/c(1)  -c(N+1)/c(1)  |
              |       1            0      ...       0             0      |
              |       0            1      ...       0             0      |
          A = |       .            .      .         .             .      |
              |       .            .       .        .             .      |
              |       .            .        .       .             .      |
              |_      0            0      ...       1             0     _|

     The eigenvalues of the companion matrix are equal to the roots of
     the polynomial.

     See also: *note roots: XREFroots, *note poly: XREFpoly, *note eig:
     XREFeig.

 -- : [MULTP, IDXP] = mpoles (P)
 -- : [MULTP, IDXP] = mpoles (P, TOL)
 -- : [MULTP, IDXP] = mpoles (P, TOL, REORDER)
     Identify unique poles in P and their associated multiplicity.

     The output is ordered from largest pole to smallest pole.

     If the relative difference of two poles is less than TOL then they
     are considered to be multiples.  The default value for TOL is
     0.001.

     If the optional parameter REORDER is zero, poles are not sorted.

     The output MULTP is a vector specifying the multiplicity of the
     poles.  ‘MULTP(n)’ refers to the multiplicity of the Nth pole
     ‘P(IDXP(n))’.

     For example:

          p = [2 3 1 1 2];
          [m, n] = mpoles (p)
             ⇒ m = [1; 1; 2; 1; 2]
             ⇒ n = [2; 5; 1; 4; 3]
             ⇒ p(n) = [3, 2, 2, 1, 1]

     See also: *note residue: XREFresidue, *note poly: XREFpoly, *note
     roots: XREFroots, *note conv: XREFconv, *note deconv: XREFdeconv.


File: octave.info,  Node: Products of Polynomials,  Next: Derivatives / Integrals / Transforms,  Prev: Finding Roots,  Up: Polynomial Manipulations

28.3 Products of Polynomials
============================

 -- : conv (A, B)
 -- : conv (A, B, SHAPE)
     Convolve two vectors A and B.

     When A and B are the coefficient vectors of two polynomials, the
     convolution represents the coefficient vector of the product
     polynomial.

     The size of the result is determined by the optional SHAPE argument
     which takes the following values

     SHAPE = "full"
          Return the full convolution.  (default) The result is a vector
          with length equal to ‘length (A) + length (B) - 1’.

     SHAPE = "same"
          Return the central part of the convolution with the same size
          as A.

     SHAPE = "valid"
          Return only the parts which do not include zero-padded edges.
          The size of the result is ‘max (size (A) - size (B) + 1, 0)’.

     See also: *note deconv: XREFdeconv, *note conv2: XREFconv2, *note
     convn: XREFconvn, *note fftconv: XREFfftconv.

 -- : C = convn (A, B)
 -- : C = convn (A, B, SHAPE)
     Return the n-D convolution of A and B.

     The size of the result is determined by the optional SHAPE argument
     which takes the following values

     SHAPE = "full"
          Return the full convolution.  (default)

     SHAPE = "same"
          Return central part of the convolution with the same size as
          A.  The central part of the convolution begins at the indices
          ‘floor ([size(B)/2] + 1)’.

     SHAPE = "valid"
          Return only the parts which do not include zero-padded edges.
          The size of the result is ‘max (size (A) - size (B) + 1, 0)’.

     See also: *note conv2: XREFconv2, *note conv: XREFconv.

 -- : B = deconv (Y, A)
 -- : [B, R] = deconv (Y, A)
     Deconvolve two vectors (polynomial division).

     ‘[B, R] = deconv (Y, A)’ solves for B and R such that ‘Y = conv (A,
     B) + R’.

     If Y and A are polynomial coefficient vectors, B will contain the
     coefficients of the polynomial quotient and R will be a remainder
     polynomial of lowest order.

     See also: *note conv: XREFconv, *note residue: XREFresidue.

 -- : conv2 (A, B)
 -- : conv2 (V1, V2, M)
 -- : conv2 (..., SHAPE)
     Return the 2-D convolution of A and B.

     The size of the result is determined by the optional SHAPE argument
     which takes the following values

     SHAPE = "full"
          Return the full convolution.  (default)

     SHAPE = "same"
          Return the central part of the convolution with the same size
          as A.  The central part of the convolution begins at the
          indices ‘floor ([size(B)/2] + 1)’.

     SHAPE = "valid"
          Return only the parts which do not include zero-padded edges.
          The size of the result is ‘max (size (A) - size (B) + 1, 0)’.

     When the third argument is a matrix, return the convolution of the
     matrix M by the vector V1 in the column direction and by the vector
     V2 in the row direction.

     See also: *note conv: XREFconv, *note convn: XREFconvn.

 -- : Q = polygcd (B, A)
 -- : Q = polygcd (B, A, TOL)

     Find the greatest common divisor of two polynomials.

     This is equivalent to the polynomial found by multiplying together
     all the common roots.  Together with deconv, you can reduce a ratio
     of two polynomials.

     The tolerance TOL defaults to ‘sqrt (eps)’.

     *Caution:* This is a numerically unstable algorithm and should not
     be used on large polynomials.

     Example code:

          polygcd (poly (1:8), poly (3:12)) - poly (3:8)
          ⇒ [ 0, 0, 0, 0, 0, 0, 0 ]
          deconv (poly (1:8), polygcd (poly (1:8), poly (3:12))) - poly (1:2)
          ⇒ [ 0, 0, 0 ]

     See also: *note poly: XREFpoly, *note roots: XREFroots, *note conv:
     XREFconv, *note deconv: XREFdeconv, *note residue: XREFresidue.

 -- : [R, P, K, E] = residue (B, A)
 -- : [B, A] = residue (R, P, K)
 -- : [B, A] = residue (R, P, K, E)
     The first calling form computes the partial fraction expansion for
     the quotient of the polynomials, B and A.

     The quotient is defined as

          B(s)    M       r(m)        N
          ---- = SUM ------------- + SUM k(i)*s^(N-i)
          A(s)   m=1 (s-p(m))^e(m)   i=1

     where M is the number of poles (the length of the R, P, and E), the
     K vector is a polynomial of order N-1 representing the direct
     contribution, and the E vector specifies the multiplicity of the
     m-th residue’s pole.

     For example,

          b = [1, 1, 1];
          a = [1, -5, 8, -4];
          [r, p, k, e] = residue (b, a)
             ⇒ r = [-2; 7; 3]
             ⇒ p = [2; 2; 1]
             ⇒ k = [](0x0)
             ⇒ e = [1; 2; 1]

     which represents the following partial fraction expansion

                  s^2 + s + 1       -2        7        3
             ------------------- = ----- + ------- + -----
             s^3 - 5s^2 + 8s - 4   (s-2)   (s-2)^2   (s-1)

     The second calling form performs the inverse operation and computes
     the reconstituted quotient of polynomials, B(s)/A(s), from the
     partial fraction expansion; represented by the residues, poles, and
     a direct polynomial specified by R, P and K, and the pole
     multiplicity E.

     If the multiplicity, E, is not explicitly specified the
     multiplicity is determined by the function ‘mpoles’.

     For example:

          r = [-2; 7; 3];
          p = [2; 2; 1];
          k = [1, 0];
          [b, a] = residue (r, p, k)
             ⇒ b = [1, -5, 9, -3, 1]
             ⇒ a = [1, -5, 8, -4]

          where mpoles is used to determine e = [1; 2; 1]

     Alternatively the multiplicity may be defined explicitly, for
     example,

          r = [7; 3; -2];
          p = [2; 1; 2];
          k = [1, 0];
          e = [2; 1; 1];
          [b, a] = residue (r, p, k, e)
             ⇒ b = [1, -5, 9, -3, 1]
             ⇒ a = [1, -5, 8, -4]

     which represents the following partial fraction expansion

           -2        7        3         s^4 - 5s^3 + 9s^2 - 3s + 1
          ----- + ------- + ----- + s = --------------------------
          (s-2)   (s-2)^2   (s-1)          s^3 - 5s^2 + 8s - 4

     See also: *note mpoles: XREFmpoles, *note poly: XREFpoly, *note
     roots: XREFroots, *note conv: XREFconv, *note deconv: XREFdeconv.


File: octave.info,  Node: Derivatives / Integrals / Transforms,  Next: Polynomial Interpolation,  Prev: Products of Polynomials,  Up: Polynomial Manipulations

28.4 Derivatives / Integrals / Transforms
=========================================

Octave comes with functions for computing the derivative and the
integral of a polynomial.  The functions ‘polyder’ and ‘polyint’ both
return new polynomials describing the result.  As an example we’ll
compute the definite integral of p(x) = x^2 + 1 from 0 to 3.

     c = [1, 0, 1];
     integral = polyint (c);
     area = polyval (integral, 3) - polyval (integral, 0)
     ⇒ 12

 -- : polyder (P)
 -- : [K] = polyder (A, B)
 -- : [Q, D] = polyder (B, A)
     Return the coefficients of the derivative of the polynomial whose
     coefficients are given by the vector P.

     If a pair of polynomials is given, return the derivative of the
     product A*B.

     If two inputs and two outputs are given, return the derivative of
     the polynomial quotient B/A.  The quotient numerator is in Q and
     the denominator in D.

     See also: *note polyint: XREFpolyint, *note polyval: XREFpolyval,
     *note polyreduce: XREFpolyreduce.

 -- : polyint (P)
 -- : polyint (P, K)
     Return the coefficients of the integral of the polynomial whose
     coefficients are represented by the vector P.

     The variable K is the constant of integration, which by default is
     set to zero.

     See also: *note polyder: XREFpolyder, *note polyval: XREFpolyval.

 -- : polyaffine (F, MU)
     Return the coefficients of the polynomial vector F after an affine
     transformation.

     If F is the vector representing the polynomial f(x), then ‘G =
     polyaffine (F, MU)’ is the vector representing:

          g(x) = f( (x - MU(1)) / MU(2) )

     See also: *note polyval: XREFpolyval, *note polyfit: XREFpolyfit.


File: octave.info,  Node: Polynomial Interpolation,  Next: Miscellaneous Functions,  Prev: Derivatives / Integrals / Transforms,  Up: Polynomial Manipulations

28.5 Polynomial Interpolation
=============================

Octave comes with good support for various kinds of interpolation, most
of which are described in *note Interpolation::.  One simple alternative
to the functions described in the aforementioned chapter, is to fit a
single polynomial, or a piecewise polynomial (spline) to some given data
points.  To avoid a highly fluctuating polynomial, one most often wants
to fit a low-order polynomial to data.  This usually means that it is
necessary to fit the polynomial in a least-squares sense, which just is
what the ‘polyfit’ function does.

 -- : P = polyfit (X, Y, N)
 -- : [P, S] = polyfit (X, Y, N)
 -- : [P, S, MU] = polyfit (X, Y, N)
     Return the coefficients of a polynomial P(X) of degree N that
     minimizes the least-squares-error of the fit to the points ‘[X,
     Y]’.

     If N is a logical vector, it is used as a mask to selectively force
     the corresponding polynomial coefficients to be used or ignored.

     The polynomial coefficients are returned in a row vector.

     The optional output S is a structure containing the following
     fields:

     ‘R’
          Triangular factor R from the QR decomposition.

     ‘X’
          The Vandermonde matrix used to compute the polynomial
          coefficients.

     ‘C’
          The unscaled covariance matrix, formally equal to the inverse
          of X’*X, but computed in a way minimizing roundoff error
          propagation.

     ‘df’
          The degrees of freedom.

     ‘normr’
          The norm of the residuals.

     ‘yf’
          The values of the polynomial for each value of X.

     The second output may be used by ‘polyval’ to calculate the
     statistical error limits of the predicted values.  In particular,
     the standard deviation of P coefficients is given by

     ‘sqrt (diag (s.C)/s.df)*s.normr’.

     When the third output, MU, is present the coefficients, P, are
     associated with a polynomial in

     ‘XHAT = (X - MU(1)) / MU(2)’
     where MU(1) = mean (X), and MU(2) = std (X).

     This linear transformation of X improves the numerical stability of
     the fit.

     See also: *note polyval: XREFpolyval, *note polyaffine:
     XREFpolyaffine, *note roots: XREFroots, *note vander: XREFvander,
     *note zscore: XREFzscore.

   In situations where a single polynomial isn’t good enough, a solution
is to use several polynomials pieced together.  The function ‘splinefit’
fits a piecewise polynomial (spline) to a set of data.

 -- : PP = splinefit (X, Y, BREAKS)
 -- : PP = splinefit (X, Y, P)
 -- : PP = splinefit (..., "periodic", PERIODIC)
 -- : PP = splinefit (..., "robust", ROBUST)
 -- : PP = splinefit (..., "beta", BETA)
 -- : PP = splinefit (..., "order", ORDER)
 -- : PP = splinefit (..., "constraints", CONSTRAINTS)

     Fit a piecewise cubic spline with breaks (knots) BREAKS to the
     noisy data, X and Y.

     X is a vector, and Y is a vector or N-D array.  If Y is an N-D
     array, then X(j) is matched to Y(:,...,:,j).

     P is a positive integer defining the number of intervals along X,
     and P+1 is the number of breaks.  The number of points in each
     interval differ by no more than 1.

     The optional property PERIODIC is a logical value which specifies
     whether a periodic boundary condition is applied to the spline.
     The length of the period is ‘max (BREAKS) - min (BREAKS)’.  The
     default value is ‘false’.

     The optional property ROBUST is a logical value which specifies if
     robust fitting is to be applied to reduce the influence of outlying
     data points.  Three iterations of weighted least squares are
     performed.  Weights are computed from previous residuals.  The
     sensitivity of outlier identification is controlled by the property
     BETA.  The value of BETA is restricted to the range, 0 < BETA < 1.
     The default value is BETA = 1/2.  Values close to 0 give all data
     equal weighting.  Increasing values of BETA reduce the influence of
     outlying data.  Values close to unity may cause instability or rank
     deficiency.

     The fitted spline is returned as a piecewise polynomial, PP, and
     may be evaluated using ‘ppval’.

     The splines are constructed of polynomials with degree ORDER.  The
     default is a cubic, ORDER=3.  A spline with P pieces has P+ORDER
     degrees of freedom.  With periodic boundary conditions the degrees
     of freedom are reduced to P.

     The optional property, CONSTAINTS, is a structure specifying linear
     constraints on the fit.  The structure has three fields, "xc",
     "yc", and "cc".

     "xc"
          Vector of the x-locations of the constraints.

     "yc"
          Constraining values at the locations XC.  The default is an
          array of zeros.

     "cc"
          Coefficients (matrix).  The default is an array of ones.  The
          number of rows is limited to the order of the piecewise
          polynomials, ORDER.

     Constraints are linear combinations of derivatives of order 0 to
     ORDER-1 according to

          cc(1,j) * y(xc(j)) + cc(2,j) * y'(xc(j)) + ... = yc(:,...,:,j).

     See also: *note interp1: XREFinterp1, *note unmkpp: XREFunmkpp,
     *note ppval: XREFppval, *note spline: XREFspline, *note pchip:
     XREFpchip, *note ppder: XREFppder, *note ppint: XREFppint, *note
     ppjumps: XREFppjumps.

   The number of BREAKS (or knots) used to construct the piecewise
polynomial is a significant factor in suppressing the noise present in
the input data, X and Y.  This is demonstrated by the example below.

     x = 2 * pi * rand (1, 200);
     y = sin (x) + sin (2 * x) + 0.2 * randn (size (x));
     ## Uniform breaks
     breaks = linspace (0, 2 * pi, 41); % 41 breaks, 40 pieces
     pp1 = splinefit (x, y, breaks);
     ## Breaks interpolated from data
     pp2 = splinefit (x, y, 10);  % 11 breaks, 10 pieces
     ## Plot
     xx = linspace (0, 2 * pi, 400);
     y1 = ppval (pp1, xx);
     y2 = ppval (pp2, xx);
     plot (x, y, ".", xx, [y1; y2])
     axis tight
     ylim auto
     legend ({"data", "41 breaks, 40 pieces", "11 breaks, 10 pieces"})

   The piecewise polynomial fit, provided by ‘splinefit’, has continuous
derivatives up to the ORDER-1.  For example, a cubic fit has continuous
first and second derivatives.  This is demonstrated by the code

     ## Data (200 points)
     x = 2 * pi * rand (1, 200);
     y = sin (x) + sin (2 * x) + 0.1 * randn (size (x));
     ## Piecewise constant
     pp1 = splinefit (x, y, 8, "order", 0);
     ## Piecewise linear
     pp2 = splinefit (x, y, 8, "order", 1);
     ## Piecewise quadratic
     pp3 = splinefit (x, y, 8, "order", 2);
     ## Piecewise cubic
     pp4 = splinefit (x, y, 8, "order", 3);
     ## Piecewise quartic
     pp5 = splinefit (x, y, 8, "order", 4);
     ## Plot
     xx = linspace (0, 2 * pi, 400);
     y1 = ppval (pp1, xx);
     y2 = ppval (pp2, xx);
     y3 = ppval (pp3, xx);
     y4 = ppval (pp4, xx);
     y5 = ppval (pp5, xx);
     plot (x, y, ".", xx, [y1; y2; y3; y4; y5])
     axis tight
     ylim auto
     legend ({"data", "order 0", "order 1", "order 2", "order 3", "order 4"})

   When the underlying function to provide a fit to is periodic,
‘splinefit’ is able to apply the boundary conditions needed to manifest
a periodic fit.  This is demonstrated by the code below.

     ## Data (100 points)
     x = 2 * pi * [0, (rand (1, 98)), 1];
     y = sin (x) - cos (2 * x) + 0.2 * randn (size (x));
     ## No constraints
     pp1 = splinefit (x, y, 10, "order", 5);
     ## Periodic boundaries
     pp2 = splinefit (x, y, 10, "order", 5, "periodic", true);
     ## Plot
     xx = linspace (0, 2 * pi, 400);
     y1 = ppval (pp1, xx);
     y2 = ppval (pp2, xx);
     plot (x, y, ".", xx, [y1; y2])
     axis tight
     ylim auto
     legend ({"data", "no constraints", "periodic"})

   More complex constraints may be added as well.  For example, the code
below illustrates a periodic fit with values that have been clamped at
the endpoints, and a second periodic fit which is hinged at the
endpoints.

     ## Data (200 points)
     x = 2 * pi * rand (1, 200);
     y = sin (2 * x) + 0.1 * randn (size (x));
     ## Breaks
     breaks = linspace (0, 2 * pi, 10);
     ## Clamped endpoints, y = y' = 0
     xc = [0, 0, 2*pi, 2*pi];
     cc = [(eye (2)), (eye (2))];
     con = struct ("xc", xc, "cc", cc);
     pp1 = splinefit (x, y, breaks, "constraints", con);
     ## Hinged periodic endpoints, y = 0
     con = struct ("xc", 0);
     pp2 = splinefit (x, y, breaks, "constraints", con, "periodic", true);
     ## Plot
     xx = linspace (0, 2 * pi, 400);
     y1 = ppval (pp1, xx);
     y2 = ppval (pp2, xx);
     plot (x, y, ".", xx, [y1; y2])
     axis tight
     ylim auto
     legend ({"data", "clamped", "hinged periodic"})

   The ‘splinefit’ function also provides the convenience of a ROBUST
fitting, where the effect of outlying data is reduced.  In the example
below, three different fits are provided.  Two with differing levels of
outlier suppression and a third illustrating the non-robust solution.

     ## Data
     x = linspace (0, 2*pi, 200);
     y = sin (x) + sin (2 * x) + 0.05 * randn (size (x));
     ## Add outliers
     x = [x, linspace(0,2*pi,60)];
     y = [y, -ones(1,60)];
     ## Fit splines with hinged conditions
     con = struct ("xc", [0, 2*pi]);
     ## Robust fitting, beta = 0.25
     pp1 = splinefit (x, y, 8, "constraints", con, "beta", 0.25);
     ## Robust fitting, beta = 0.75
     pp2 = splinefit (x, y, 8, "constraints", con, "beta", 0.75);
     ## No robust fitting
     pp3 = splinefit (x, y, 8, "constraints", con);
     ## Plot
     xx = linspace (0, 2*pi, 400);
     y1 = ppval (pp1, xx);
     y2 = ppval (pp2, xx);
     y3 = ppval (pp3, xx);
     plot (x, y, ".", xx, [y1; y2; y3])
     legend ({"data with outliers","robust, beta = 0.25", ...
              "robust, beta = 0.75", "no robust fitting"})
     axis tight
     ylim auto

   A very specific form of polynomial interpretation is the Padé
approximant.  For control systems, a continuous-time delay can be
modeled very simply with the approximant.

 -- : [NUM, DEN] = padecoef (T)
 -- : [NUM, DEN] = padecoef (T, N)
     Compute the Nth-order Padé approximant of the continuous-time delay
     T in transfer function form.

     The Padé approximant of ‘exp (-sT)’ is defined by the following
     equation

                       Pn(s)
          exp (-sT) ~ -------
                       Qn(s)

     Where both Pn(s) and Qn(s) are Nth-order rational functions defined
     by the following expressions

                   N    (2N - k)!N!        k
          Pn(s) = SUM --------------- (-sT)
                  k=0 (2N)!k!(N - k)!

          Qn(s) = Pn(-s)

     The inputs T and N must be non-negative numeric scalars.  If N is
     unspecified it defaults to 1.

     The output row vectors NUM and DEN contain the numerator and
     denominator coefficients in descending powers of s.  Both are
     Nth-order polynomials.

     For example:

          t = 0.1;
          n = 4;
          [num, den] = padecoef (t, n)
          ⇒ num =

                1.0000e-04  -2.0000e-02   1.8000e+00  -8.4000e+01   1.6800e+03

          ⇒ den =

                1.0000e-04   2.0000e-02   1.8000e+00   8.4000e+01   1.6800e+03

   The function, ‘ppval’, evaluates the piecewise polynomials, created
by ‘mkpp’ or other means, and ‘unmkpp’ returns detailed information
about the piecewise polynomial.

   The following example shows how to combine two linear functions and a
quadratic into one function.  Each of these functions is expressed on
adjoined intervals.

     x = [-2, -1, 1, 2];
     p = [ 0,  1, 0;
           1, -2, 1;
           0, -1, 1 ];
     pp = mkpp (x, p);
     xi = linspace (-2, 2, 50);
     yi = ppval (pp, xi);
     plot (xi, yi);

 -- : PP = mkpp (BREAKS, COEFS)
 -- : PP = mkpp (BREAKS, COEFS, D)

     Construct a piecewise polynomial (pp) structure from sample points
     BREAKS and coefficients COEFS.

     BREAKS must be a vector of strictly increasing values.  The number
     of intervals is given by ‘NI = length (BREAKS) - 1’.

     When M is the polynomial order COEFS must be of size:
     NI-by-(M + 1).

     The i-th row of COEFS, ‘COEFS (I,:)’, contains the coefficients for
     the polynomial over the I-th interval, ordered from highest (M) to
     lowest (0).

     COEFS may also be a multi-dimensional array, specifying a
     vector-valued or array-valued polynomial.  In that case the
     polynomial order M is defined by the length of the last dimension
     of COEFS.  The size of first dimension(s) are given by the scalar
     or vector D.  If D is not given it is set to ‘1’.  In any case
     COEFS is reshaped to a 2-D matrix of size ‘[NI*prod(D) M]’.

     See also: *note unmkpp: XREFunmkpp, *note ppval: XREFppval, *note
     spline: XREFspline, *note pchip: XREFpchip, *note ppder: XREFppder,
     *note ppint: XREFppint, *note ppjumps: XREFppjumps.

 -- : [X, P, N, K, D] = unmkpp (PP)

     Extract the components of a piecewise polynomial structure PP.

     The components are:

     X
          Sample points.

     P
          Polynomial coefficients for points in sample interval.  ‘P (I,
          :)’ contains the coefficients for the polynomial over interval
          I ordered from highest to lowest.  If ‘D > 1’, ‘P (R, I, :)’
          contains the coefficients for the r-th polynomial defined on
          interval I.

     N
          Number of polynomial pieces.

     K
          Order of the polynomial plus 1.

     D
          Number of polynomials defined for each interval.

     See also: *note mkpp: XREFmkpp, *note ppval: XREFppval, *note
     spline: XREFspline, *note pchip: XREFpchip.

 -- : YI = ppval (PP, XI)
     Evaluate the piecewise polynomial structure PP at the points XI.

     If PP describes a scalar polynomial function, the result is an
     array of the same shape as XI.  Otherwise, the size of the result
     is ‘[pp.dim, length(XI)]’ if XI is a vector, or ‘[pp.dim,
     size(XI)]’ if it is a multi-dimensional array.

     See also: *note mkpp: XREFmkpp, *note unmkpp: XREFunmkpp, *note
     spline: XREFspline, *note pchip: XREFpchip.

 -- : ppd = ppder (pp)
 -- : ppd = ppder (pp, m)
     Compute the piecewise M-th derivative of a piecewise polynomial
     struct PP.

     If M is omitted the first derivative is calculated.

     See also: *note mkpp: XREFmkpp, *note ppval: XREFppval, *note
     ppint: XREFppint.

 -- : PPI = ppint (PP)
 -- : PPI = ppint (PP, C)
     Compute the integral of the piecewise polynomial struct PP.

     C, if given, is the constant of integration.

     See also: *note mkpp: XREFmkpp, *note ppval: XREFppval, *note
     ppder: XREFppder.

 -- : JUMPS = ppjumps (PP)
     Evaluate the boundary jumps of a piecewise polynomial.

     If there are n intervals, and the dimensionality of PP is d, the
     resulting array has dimensions ‘[d, n-1]’.

     See also: *note mkpp: XREFmkpp.


File: octave.info,  Node: Miscellaneous Functions,  Prev: Polynomial Interpolation,  Up: Polynomial Manipulations

28.6 Miscellaneous Functions
============================

 -- : poly (A)
 -- : poly (X)
     If A is a square N-by-N matrix, ‘poly (A)’ is the row vector of the
     coefficients of ‘det (z * eye (N) - A)’, the characteristic
     polynomial of A.

     For example, the following code finds the eigenvalues of A which
     are the roots of ‘poly (A)’.

          roots (poly (eye (3)))
              ⇒ 1.00001 + 0.00001i
                 1.00001 - 0.00001i
                 0.99999 + 0.00000i

     In fact, all three eigenvalues are exactly 1 which emphasizes that
     for numerical performance the ‘eig’ function should be used to
     compute eigenvalues.

     If X is a vector, ‘poly (X)’ is a vector of the coefficients of the
     polynomial whose roots are the elements of X.  That is, if C is a
     polynomial, then the elements of ‘D = roots (poly (C))’ are
     contained in C.  The vectors C and D are not identical, however,
     due to sorting and numerical errors.

     See also: *note roots: XREFroots, *note eig: XREFeig.

 -- : polyout (C)
 -- : polyout (C, X)
 -- : STR = polyout (...)
     Display a formatted version of the polynomial C.

     The formatted polynomial

          c(x) = c(1) * x^n + ... + c(n) x + c(n+1)

     is returned as a string or written to the screen if ‘nargout’ is
     zero.

     The second argument X specifies the variable name to use for each
     term and defaults to the string "s".

     See also: *note polyreduce: XREFpolyreduce.

 -- : polyreduce (C)
     Reduce a polynomial coefficient vector to a minimum number of terms
     by stripping off any leading zeros.

     See also: *note polyout: XREFpolyout.


File: octave.info,  Node: Interpolation,  Next: Geometry,  Prev: Polynomial Manipulations,  Up: Top

29 Interpolation
****************

* Menu:

* One-dimensional Interpolation::
* Multi-dimensional Interpolation::


File: octave.info,  Node: One-dimensional Interpolation,  Next: Multi-dimensional Interpolation,  Up: Interpolation

29.1 One-dimensional Interpolation
==================================

Octave supports several methods for one-dimensional interpolation, most
of which are described in this section.  *note Polynomial
Interpolation:: and *note Interpolation on Scattered Data:: describe
additional methods.

 -- : YI = interp1 (X, Y, XI)
 -- : YI = interp1 (Y, XI)
 -- : YI = interp1 (..., METHOD)
 -- : YI = interp1 (..., EXTRAP)
 -- : YI = interp1 (..., "left")
 -- : YI = interp1 (..., "right")
 -- : PP = interp1 (..., "pp")

     One-dimensional interpolation.

     Interpolate input data to determine the value of YI at the points
     XI.  If not specified, X is taken to be the indices of Y (‘1:length
     (Y)’).  If Y is a matrix or an N-dimensional array, the
     interpolation is performed on each column of Y.

     The interpolation METHOD is one of:

     "nearest"
          Return the nearest neighbor.

     "previous"
          Return the previous neighbor.

     "next"
          Return the next neighbor.

     "linear" (default)
          Linear interpolation from nearest neighbors.

     "pchip"
          Piecewise cubic Hermite interpolating
          polynomial—shape-preserving interpolation with smooth first
          derivative.

     "cubic"
          Cubic interpolation (same as "pchip").

     "spline"
          Cubic spline interpolation—smooth first and second derivatives
          throughout the curve.

     Adding ’*’ to the start of any method above forces ‘interp1’ to
     assume that X is uniformly spaced, and only ‘X(1)’ and ‘X(2)’ are
     referenced.  This is usually faster, and is never slower.  The
     default method is "linear".

     If EXTRAP is the string "extrap", then extrapolate values beyond
     the endpoints using the current METHOD.  If EXTRAP is a number,
     then replace values beyond the endpoints with that number.  When
     unspecified, EXTRAP defaults to ‘NA’.

     If the string argument "pp" is specified, then XI should not be
     supplied and ‘interp1’ returns a piecewise polynomial object.  This
     object can later be used with ‘ppval’ to evaluate the
     interpolation.  There is an equivalence, such that ‘ppval (interp1
     (X, Y, METHOD, "pp"), XI) == interp1 (X, Y, XI, METHOD, "extrap")’.

     Duplicate points in X specify a discontinuous interpolant.  There
     may be at most 2 consecutive points with the same value.  If X is
     increasing, the default discontinuous interpolant is
     right-continuous.  If X is decreasing, the default discontinuous
     interpolant is left-continuous.  The continuity condition of the
     interpolant may be specified by using the options "left" or "right"
     to select a left-continuous or right-continuous interpolant,
     respectively.  Discontinuous interpolation is only allowed for
     "nearest" and "linear" methods; in all other cases, the X-values
     must be unique.

     An example of the use of ‘interp1’ is

          xf = [0:0.05:10];
          yf = sin (2*pi*xf/5);
          xp = [0:10];
          yp = sin (2*pi*xp/5);
          lin = interp1 (xp, yp, xf);
          near = interp1 (xp, yp, xf, "nearest");
          pch = interp1 (xp, yp, xf, "pchip");
          spl = interp1 (xp, yp, xf, "spline");
          plot (xf,yf,"r", xf,near,"g", xf,lin,"b", xf,pch,"c", xf,spl,"m",
                xp,yp,"r*");
          legend ("original", "nearest", "linear", "pchip", "spline");

     See also: *note pchip: XREFpchip, *note spline: XREFspline, *note
     interpft: XREFinterpft, *note interp2: XREFinterp2, *note interp3:
     XREFinterp3, *note interpn: XREFinterpn.

   There are some important differences between the various
interpolation methods.  The "spline" method enforces that both the first
and second derivatives of the interpolated values have a continuous
derivative, whereas the other methods do not.  This means that the
results of the "spline" method are generally smoother.  If the function
to be interpolated is in fact smooth, then "spline" will give excellent
results.  However, if the function to be evaluated is in some manner
discontinuous, then "pchip" interpolation might give better results.

   This can be demonstrated by the code

     t = -2:2;
     dt = 1;
     ti =-2:0.025:2;
     dti = 0.025;
     y = sign (t);
     ys = interp1 (t,y,ti,"spline");
     yp = interp1 (t,y,ti,"pchip");
     ddys = diff (diff (ys)./dti) ./ dti;
     ddyp = diff (diff (yp)./dti) ./ dti;
     figure (1);
     plot (ti,ys,"r-", ti,yp,"g-");
     legend ("spline", "pchip", 4);
     figure (2);
     plot (ti,ddys,"r+", ti,ddyp,"g*");
     legend ("spline", "pchip");

   Fourier interpolation, is a resampling technique where a signal is
converted to the frequency domain, padded with zeros and then
reconverted to the time domain.

 -- : interpft (X, N)
 -- : interpft (X, N, DIM)

     Fourier interpolation.

     If X is a vector then X is resampled with N points.  The data in X
     is assumed to be equispaced.  If X is a matrix or an N-dimensional
     array, the interpolation is performed on each column of X.

     If DIM is specified, then interpolate along the dimension DIM.

     ‘interpft’ assumes that the interpolated function is periodic, and
     so assumptions are made about the endpoints of the interpolation.

     See also: *note interp1: XREFinterp1.

   There are two significant limitations on Fourier interpolation.
First, the function signal is assumed to be periodic, and so
non-periodic signals will be poorly represented at the edges.  Second,
both the signal and its interpolation are required to be sampled at
equispaced points.  An example of the use of ‘interpft’ is

     t = 0 : 0.3 : pi; dt = t(2)-t(1);
     n = length (t); k = 100;
     ti = t(1) + [0 : k-1]*dt*n/k;
     y = sin (4*t + 0.3) .* cos (3*t - 0.1);
     yp = sin (4*ti + 0.3) .* cos (3*ti - 0.1);
     plot (ti, yp, "g", ti, interp1 (t, y, ti, "spline"), "b", ...
           ti, interpft (y, k), "c", t, y, "r+");
     legend ("sin(4t+0.3)cos(3t-0.1)", "spline", "interpft", "data");

which demonstrates the poor behavior of Fourier interpolation for
non-periodic functions.

   In addition, the support functions ‘spline’ and ‘lookup’ that
underlie the ‘interp1’ function can be called directly.

 -- : PP = spline (X, Y)
 -- : YI = spline (X, Y, XI)
     Return the cubic spline interpolant of points X and Y.

     When called with two arguments, return the piecewise polynomial PP
     that may be used with ‘ppval’ to evaluate the polynomial at
     specific points.

     When called with a third input argument, ‘spline’ evaluates the
     spline at the points XI.  The third calling form ‘spline (X, Y,
     XI)’ is equivalent to ‘ppval (spline (X, Y), XI)’.

     The variable X must be a vector of length N.

     Y can be either a vector or array.  If Y is a vector it must have a
     length of either N or ‘N + 2’.  If the length of Y is N, then the
     "not-a-knot" end condition is used.  If the length of Y is ‘N + 2’,
     then the first and last values of the vector Y are the values of
     the first derivative of the cubic spline at the endpoints.

     If Y is an array, then the size of Y must have the form ‘[S1, S2,
     ..., SK, N]’ or ‘[S1, S2, ..., SK, N + 2]’.  The array is reshaped
     internally to a matrix where the leading dimension is given by ‘S1
     * S2 * ... * SK’ and each row of this matrix is then treated
     separately.  Note that this is exactly the opposite of ‘interp1’
     but is done for MATLAB compatibility.

     See also: *note pchip: XREFpchip, *note ppval: XREFppval, *note
     mkpp: XREFmkpp, *note unmkpp: XREFunmkpp.


File: octave.info,  Node: Multi-dimensional Interpolation,  Prev: One-dimensional Interpolation,  Up: Interpolation

29.2 Multi-dimensional Interpolation
====================================

There are three multi-dimensional interpolation functions in Octave,
with similar capabilities.  Methods using Delaunay tessellation are
described in *note Interpolation on Scattered Data::.

 -- : ZI = interp2 (X, Y, Z, XI, YI)
 -- : ZI = interp2 (Z, XI, YI)
 -- : ZI = interp2 (Z, N)
 -- : ZI = interp2 (Z)
 -- : ZI = interp2 (..., METHOD)
 -- : ZI = interp2 (..., METHOD, EXTRAP)

     Two-dimensional interpolation.

     Interpolate reference data X, Y, Z to determine ZI at the
     coordinates XI, YI.  The reference data X, Y can be matrices, as
     returned by ‘meshgrid’, in which case the sizes of X, Y, and Z must
     be equal.  If X, Y are vectors describing a grid then ‘length (X)
     == columns (Z)’ and ‘length (Y) == rows (Z)’.  In either case the
     input data must be strictly monotonic.

     If called without X, Y, and just a single reference data matrix Z,
     the 2-D region ‘X = 1:columns (Z), Y = 1:rows (Z)’ is assumed.
     This saves memory if the grid is regular and the distance between
     points is not important.

     If called with a single reference data matrix Z and a refinement
     value N, then perform interpolation over a grid where each original
     interval has been recursively subdivided N times.  This results in
     ‘2^N-1’ additional points for every interval in the original grid.
     If N is omitted a value of 1 is used.  As an example, the interval
     [0,1] with ‘N==2’ results in a refined interval with points at [0,
     1/4, 1/2, 3/4, 1].

     The interpolation METHOD is one of:

     "nearest"
          Return the nearest neighbor.

     "linear" (default)
          Linear interpolation from nearest neighbors.

     "pchip"
          Piecewise cubic Hermite interpolating
          polynomial—shape-preserving interpolation with smooth first
          derivative.

     "cubic"
          Cubic interpolation (same as "pchip").

     "spline"
          Cubic spline interpolation—smooth first and second derivatives
          throughout the curve.

     EXTRAP is a scalar number.  It replaces values beyond the endpoints
     with EXTRAP.  Note that if EXTRAP is used, METHOD must be specified
     as well.  If EXTRAP is omitted and the METHOD is "spline", then the
     extrapolated values of the "spline" are used.  Otherwise the
     default EXTRAP value for any other METHOD is "NA".

     See also: *note interp1: XREFinterp1, *note interp3: XREFinterp3,
     *note interpn: XREFinterpn, *note meshgrid: XREFmeshgrid.

 -- : VI = interp3 (X, Y, Z, V, XI, YI, ZI)
 -- : VI = interp3 (V, XI, YI, ZI)
 -- : VI = interp3 (V, N)
 -- : VI = interp3 (V)
 -- : VI = interp3 (..., METHOD)
 -- : VI = interp3 (..., METHOD, EXTRAPVAL)

     Three-dimensional interpolation.

     Interpolate reference data X, Y, Z, V to determine VI at the
     coordinates XI, YI, ZI.  The reference data X, Y, Z can be
     matrices, as returned by ‘meshgrid’, in which case the sizes of X,
     Y, Z, and V must be equal.  If X, Y, Z are vectors describing a
     cubic grid then ‘length (X) == columns (V)’, ‘length (Y) == rows
     (V)’, and ‘length (Z) == size (V, 3)’.  In either case the input
     data must be strictly monotonic.

     If called without X, Y, Z, and just a single reference data matrix
     V, the 3-D region ‘X = 1:columns (V), Y = 1:rows (V), Z = 1:size
     (V, 3)’ is assumed.  This saves memory if the grid is regular and
     the distance between points is not important.

     If called with a single reference data matrix V and a refinement
     value N, then perform interpolation over a 3-D grid where each
     original interval has been recursively subdivided N times.  This
     results in ‘2^N-1’ additional points for every interval in the
     original grid.  If N is omitted a value of 1 is used.  As an
     example, the interval [0,1] with ‘N==2’ results in a refined
     interval with points at [0, 1/4, 1/2, 3/4, 1].

     The interpolation METHOD is one of:

     "nearest"
          Return the nearest neighbor.

     "linear" (default)
          Linear interpolation from nearest neighbors.

     "cubic"
          Piecewise cubic Hermite interpolating
          polynomial—shape-preserving interpolation with smooth first
          derivative (not implemented yet).

     "spline"
          Cubic spline interpolation—smooth first and second derivatives
          throughout the curve.

     EXTRAPVAL is a scalar number.  It replaces values beyond the
     endpoints with EXTRAPVAL.  Note that if EXTRAPVAL is used, METHOD
     must be specified as well.  If EXTRAPVAL is omitted and the METHOD
     is "spline", then the extrapolated values of the "spline" are used.
     Otherwise the default EXTRAPVAL value for any other METHOD is "NA".

     See also: *note interp1: XREFinterp1, *note interp2: XREFinterp2,
     *note interpn: XREFinterpn, *note meshgrid: XREFmeshgrid.

 -- : VI = interpn (X1, X2, ..., V, Y1, Y2, ...)
 -- : VI = interpn (V, Y1, Y2, ...)
 -- : VI = interpn (V, M)
 -- : VI = interpn (V)
 -- : VI = interpn (..., METHOD)
 -- : VI = interpn (..., METHOD, EXTRAPVAL)

     Perform N-dimensional interpolation, where N is at least two.

     Each element of the N-dimensional array V represents a value at a
     location given by the parameters X1, X2, ..., XN.  The parameters
     X1, X2, ..., XN are either N-dimensional arrays of the same size as
     the array V in the "ndgrid" format or vectors.  The parameters Y1,
     etc.  respect a similar format to X1, etc., and they represent the
     points at which the array VI is interpolated.

     If X1, ..., XN are omitted, they are assumed to be ‘x1 = 1 : size
     (V, 1)’, etc.  If M is specified, then the interpolation adds a
     point half way between each of the interpolation points.  This
     process is performed M times.  If only V is specified, then M is
     assumed to be ‘1’.

     The interpolation METHOD is one of:

     "nearest"
          Return the nearest neighbor.

     "linear" (default)
          Linear interpolation from nearest neighbors.

     "pchip"
          Piecewise cubic Hermite interpolating
          polynomial—shape-preserving interpolation with smooth first
          derivative (not implemented yet).

     "cubic"
          Cubic interpolation (same as "pchip" [not implemented yet]).

     "spline"
          Cubic spline interpolation—smooth first and second derivatives
          throughout the curve.

     The default method is "linear".

     EXTRAPVAL is a scalar number.  It replaces values beyond the
     endpoints with EXTRAPVAL.  Note that if EXTRAPVAL is used, METHOD
     must be specified as well.  If EXTRAPVAL is omitted and the METHOD
     is "spline", then the extrapolated values of the "spline" are used.
     Otherwise the default EXTRAPVAL value for any other METHOD is "NA".

     See also: *note interp1: XREFinterp1, *note interp2: XREFinterp2,
     *note interp3: XREFinterp3, *note spline: XREFspline, *note ndgrid:
     XREFndgrid.

   A significant difference between ‘interpn’ and the other two
multi-dimensional interpolation functions is the fashion in which the
dimensions are treated.  For ‘interp2’ and ‘interp3’, the y-axis is
considered to be the columns of the matrix, whereas the x-axis
corresponds to the rows of the array.  As Octave indexes arrays in
column major order, the first dimension of any array is the columns, and
so ‘interpn’ effectively reverses the ’x’ and ’y’ dimensions.  Consider
the example,

     x = y = z = -1:1;
     f = @(x,y,z) x.^2 - y - z.^2;
     [xx, yy, zz] = meshgrid (x, y, z);
     v = f (xx,yy,zz);
     xi = yi = zi = -1:0.1:1;
     [xxi, yyi, zzi] = meshgrid (xi, yi, zi);
     vi = interp3 (x, y, z, v, xxi, yyi, zzi, "spline");
     [xxi, yyi, zzi] = ndgrid (xi, yi, zi);
     vi2 = interpn (x, y, z, v, xxi, yyi, zzi, "spline");
     mesh (zi, yi, squeeze (vi2(1,:,:)));

where ‘vi’ and ‘vi2’ are identical.  The reversal of the dimensions is
treated in the ‘meshgrid’ and ‘ndgrid’ functions respectively.


File: octave.info,  Node: Geometry,  Next: Signal Processing,  Prev: Interpolation,  Up: Top

30 Geometry
***********

Much of the geometry code in Octave is based on the Qhull library(1).
Some of the documentation for Qhull, particularly for the options that
can be passed to ‘delaunay’, ‘voronoi’ and ‘convhull’, etc., is relevant
to Octave users.

* Menu:

* Delaunay Triangulation::
* Voronoi Diagrams::
* Convex Hull::
* Interpolation on Scattered Data::

   ---------- Footnotes ----------

   (1) Barber, C.B., Dobkin, D.P., and Huhdanpaa, H.T., ‘The Quickhull
Algorithm for Convex Hulls’, ACM Trans.  on Mathematical Software,
22(4):469–483, Dec 1996, <http://www.qhull.org>


File: octave.info,  Node: Delaunay Triangulation,  Next: Voronoi Diagrams,  Up: Geometry

30.1 Delaunay Triangulation
===========================

The Delaunay triangulation is constructed from a set of circum-circles.
These circum-circles are chosen so that there are at least three of the
points in the set to triangulation on the circumference of the
circum-circle.  None of the points in the set of points falls within any
of the circum-circles.

   In general there are only three points on the circumference of any
circum-circle.  However, in some cases, and in particular for the case
of a regular grid, 4 or more points can be on a single circum-circle.
In this case the Delaunay triangulation is not unique.

 -- : TRI = delaunay (X, Y)
 -- : TETR = delaunay (X, Y, Z)
 -- : TRI = delaunay (X)
 -- : TRI = delaunay (..., OPTIONS)
     Compute the Delaunay triangulation for a 2-D or 3-D set of points.

     For 2-D sets, the return value TRI is a set of triangles which
     satisfies the Delaunay circum-circle criterion, i.e., no data point
     from [X, Y] is within the circum-circle of the defining triangle.
     The set of triangles TRI is a matrix of size [n, 3].  Each row
     defines a triangle and the three columns are the three vertices of
     the triangle.  The value of ‘TRI(i,j)’ is an index into X and Y for
     the location of the j-th vertex of the i-th triangle.

     For 3-D sets, the return value TETR is a set of tetrahedrons which
     satisfies the Delaunay circum-circle criterion, i.e., no data point
     from [X, Y, Z] is within the circum-circle of the defining
     tetrahedron.  The set of tetrahedrons is a matrix of size [n, 4].
     Each row defines a tetrahedron and the four columns are the four
     vertices of the tetrahedron.  The value of ‘TETR(i,j)’ is an index
     into X, Y, Z for the location of the j-th vertex of the i-th
     tetrahedron.

     The input X may also be a matrix with two or three columns where
     the first column contains x-data, the second y-data, and the
     optional third column contains z-data.

     The optional last argument, which must be a string or cell array of
     strings, contains options passed to the underlying qhull command.
     See the documentation for the Qhull library for details
     <http://www.qhull.org/html/qh-quick.htm#options>.  The default
     options are ‘{"Qt", "Qbb", "Qc", "Qz"}’.

     If OPTIONS is not present or ‘[]’ then the default arguments are
     used.  Otherwise, OPTIONS replaces the default argument list.  To
     append user options to the defaults it is necessary to repeat the
     default arguments in OPTIONS.  Use a null string to pass no
     arguments.

          x = rand (1, 10);
          y = rand (1, 10);
          tri = delaunay (x, y);
          triplot (tri, x, y);
          hold on;
          plot (x, y, "r*");
          axis ([0,1,0,1]);

     See also: *note delaunayn: XREFdelaunayn, *note convhull:
     XREFconvhull, *note voronoi: XREFvoronoi, *note triplot:
     XREFtriplot, *note trimesh: XREFtrimesh, *note tetramesh:
     XREFtetramesh, *note trisurf: XREFtrisurf.

   For 3-D inputs ‘delaunay’ returns a set of tetrahedra that satisfy
the Delaunay circum-circle criteria.  Similarly, ‘delaunayn’ returns the
N-dimensional simplex satisfying the Delaunay circum-circle criteria.
The N-dimensional extension of a triangulation is called a tessellation.

 -- : T = delaunayn (PTS)
 -- : T = delaunayn (PTS, OPTIONS)
     Compute the Delaunay triangulation for an N-dimensional set of
     points.

     The Delaunay triangulation is a tessellation of the convex hull of
     a set of points such that no N-sphere defined by the N-triangles
     contains any other points from the set.

     The input matrix PTS of size [n, dim] contains n points in a space
     of dimension dim.  The return matrix T has size [m, dim+1].  Each
     row of T contains a set of indices back into the original set of
     points PTS which describes a simplex of dimension dim.  For
     example, a 2-D simplex is a triangle and 3-D simplex is a
     tetrahedron.

     An optional second argument, which must be a string or cell array
     of strings, contains options passed to the underlying qhull
     command.  See the documentation for the Qhull library for details
     <http://www.qhull.org/html/qh-quick.htm#options>.  The default
     options depend on the dimension of the input:

        • 2-D and 3-D: OPTIONS = ‘{"Qt", "Qbb", "Qc", "Qz"}’

        • 4-D and higher: OPTIONS = ‘{"Qt", "Qbb", "Qc", "Qx"}’

     If OPTIONS is not present or ‘[]’ then the default arguments are
     used.  Otherwise, OPTIONS replaces the default argument list.  To
     append user options to the defaults it is necessary to repeat the
     default arguments in OPTIONS.  Use a null string to pass no
     arguments.

     See also: *note delaunay: XREFdelaunay, *note convhulln:
     XREFconvhulln, *note voronoin: XREFvoronoin, *note trimesh:
     XREFtrimesh, *note tetramesh: XREFtetramesh.

   An example of a Delaunay triangulation of a set of points is

     rand ("state", 2);
     x = rand (10, 1);
     y = rand (10, 1);
     T = delaunay (x, y);
     X = [ x(T(:,1)); x(T(:,2)); x(T(:,3)); x(T(:,1)) ];
     Y = [ y(T(:,1)); y(T(:,2)); y(T(:,3)); y(T(:,1)) ];
     axis ([0, 1, 0, 1]);
     plot (X, Y, "b", x, y, "r*");

* Menu:

* Plotting the Triangulation::
* Identifying Points in Triangulation::


File: octave.info,  Node: Plotting the Triangulation,  Next: Identifying Points in Triangulation,  Up: Delaunay Triangulation

30.1.1 Plotting the Triangulation
---------------------------------

Octave has the functions ‘triplot’, ‘trimesh’, and ‘trisurf’ to plot the
Delaunay triangulation of a 2-dimensional set of points.  ‘tetramesh’
will plot the triangulation of a 3-dimensional set of points.

 -- : triplot (TRI, X, Y)
 -- : triplot (TRI, X, Y, LINESPEC)
 -- : H = triplot (...)
     Plot a 2-D triangular mesh.

     TRI is typically the output of a Delaunay triangulation over the
     grid of X, Y.  Every row of TRI represents one triangle and
     contains three indices into [X, Y] which are the vertices of the
     triangles in the x-y plane.

     The linestyle to use for the plot can be defined with the argument
     LINESPEC of the same format as the ‘plot’ command.

     The optional return value H is a graphics handle to the created
     patch object.

     See also: *note plot: XREFplot, *note trimesh: XREFtrimesh, *note
     trisurf: XREFtrisurf, *note delaunay: XREFdelaunay.

 -- : trimesh (TRI, X, Y, Z, C)
 -- : trimesh (TRI, X, Y, Z)
 -- : trimesh (TRI, X, Y)
 -- : trimesh (..., PROP, VAL, ...)
 -- : H = trimesh (...)
     Plot a 3-D triangular wireframe mesh.

     In contrast to ‘mesh’, which plots a mesh using rectangles,
     ‘trimesh’ plots the mesh using triangles.

     TRI is typically the output of a Delaunay triangulation over the
     grid of X, Y.  Every row of TRI represents one triangle and
     contains three indices into [X, Y] which are the vertices of the
     triangles in the x-y plane.  Z determines the height above the
     plane of each vertex.  If no Z input is given then the triangles
     are plotted as a 2-D figure.

     The color of the trimesh is computed by linearly scaling the Z
     values to fit the range of the current colormap.  Use ‘caxis’
     and/or change the colormap to control the appearance.

     Optionally, the color of the mesh can be specified independently of
     Z by supplying C, which is a vector for colormap data, or a matrix
     with three columns for RGB data.  The number of colors specified in
     C must either equal the number of vertices in Z or the number of
     triangles in TRI.

     Any property/value pairs are passed directly to the underlying
     patch object.

     The optional return value H is a graphics handle to the created
     patch object.

     See also: *note mesh: XREFmesh, *note tetramesh: XREFtetramesh,
     *note triplot: XREFtriplot, *note trisurf: XREFtrisurf, *note
     delaunay: XREFdelaunay, *note patch: XREFpatch, *note hidden:
     XREFhidden.

 -- : trisurf (TRI, X, Y, Z, C)
 -- : trisurf (TRI, X, Y, Z)
 -- : trisurf (..., PROP, VAL, ...)
 -- : H = trisurf (...)
     Plot a 3-D triangular surface.

     In contrast to ‘surf’, which plots a surface mesh using rectangles,
     ‘trisurf’ plots the mesh using triangles.

     TRI is typically the output of a Delaunay triangulation over the
     grid of X, Y.  Every row of TRI represents one triangle and
     contains three indices into [X, Y] which are the vertices of the
     triangles in the x-y plane.  Z determines the height above the
     plane of each vertex.

     The color of the trisurf is computed by linearly scaling the Z
     values to fit the range of the current colormap.  Use ‘caxis’
     and/or change the colormap to control the appearance.

     Optionally, the color of the mesh can be specified independently of
     Z by supplying C, which is a vector for colormap data, or a matrix
     with three columns for RGB data.  The number of colors specified in
     C must either equal the number of vertices in Z or the number of
     triangles in TRI.  When specifying the color at each vertex the
     triangle will be colored according to the color of the first vertex
     only (see patch documentation and the "FaceColor" property when set
     to "flat").

     Any property/value pairs are passed directly to the underlying
     patch object.

     The optional return value H is a graphics handle to the created
     patch object.

     See also: *note surf: XREFsurf, *note triplot: XREFtriplot, *note
     trimesh: XREFtrimesh, *note delaunay: XREFdelaunay, *note patch:
     XREFpatch, *note shading: XREFshading.

 -- : tetramesh (T, X)
 -- : tetramesh (T, X, C)
 -- : tetramesh (..., PROPERTY, VAL, ...)
 -- : H = tetramesh (...)
     Display the tetrahedrons defined in the m-by-4 matrix T as 3-D
     patches.

     T is typically the output of a Delaunay triangulation of a 3-D set
     of points.  Every row of T contains four indices into the n-by-3
     matrix X of the vertices of a tetrahedron.  Every row in X
     represents one point in 3-D space.

     The vector C specifies the color of each tetrahedron as an index
     into the current colormap.  The default value is 1:m where m is the
     number of tetrahedrons; the indices are scaled to map to the full
     range of the colormap.  If there are more tetrahedrons than colors
     in the colormap then the values in C are cyclically repeated.

     Calling ‘tetramesh (..., "property", "value", ...)’ passes all
     property/value pairs directly to the patch function as additional
     arguments.

     The optional return value H is a vector of patch handles where each
     handle represents one tetrahedron in the order given by T.  A
     typical use case for H is to turn the respective patch "visible"
     property "on" or "off".

     Type ‘demo tetramesh’ to see examples on using ‘tetramesh’.

     See also: *note trimesh: XREFtrimesh, *note delaunay: XREFdelaunay,
     *note delaunayn: XREFdelaunayn, *note patch: XREFpatch.

   The difference between ‘triplot’, and ‘trimesh’ or ‘trisurf’, is that
the former only plots the 2-dimensional triangulation itself, whereas
the second two plot the value of a function ‘f (X, Y)’.  An example of
the use of the ‘triplot’ function is

     rand ("state", 2)
     x = rand (20, 1);
     y = rand (20, 1);
     tri = delaunay (x, y);
     triplot (tri, x, y);

which plots the Delaunay triangulation of a set of random points in
2-dimensions.


File: octave.info,  Node: Identifying Points in Triangulation,  Prev: Plotting the Triangulation,  Up: Delaunay Triangulation

30.1.2 Identifying Points in Triangulation
------------------------------------------

It is often necessary to identify whether a particular point in the
N-dimensional space is within the Delaunay tessellation of a set of
points in this N-dimensional space, and if so which N-simplex contains
the point and which point in the tessellation is closest to the desired
point.  The functions ‘tsearch’ and ‘dsearch’ perform this function in a
triangulation, and ‘tsearchn’ and ‘dsearchn’ in an N-dimensional
tessellation.

   To identify whether a particular point represented by a vector P
falls within one of the simplices of an N-simplex, we can write the
Cartesian coordinates of the point in a parametric form with respect to
the N-simplex.  This parametric form is called the Barycentric
Coordinates of the point.  If the points defining the N-simplex are
given by N + 1 vectors ‘T(I,:)’, then the Barycentric coordinates
defining the point P are given by

     P = BETA * T

where BETA contains N + 1 values that together as a vector represent the
Barycentric coordinates of the point P.  To ensure a unique solution for
the values of BETA an additional criteria of

     sum (BETA) == 1

is imposed, and we can therefore write the above as

     P - T(end, :) = BETA(1:end-1) * (T(1:end-1, :)
                     - ones (N, 1) * T(end, :)

Solving for BETA we can then write

     BETA(1:end-1) = (P - T(end, :)) /
                     (T(1:end-1, :) - ones (N, 1) * T(end, :))
     BETA(end) = sum (BETA(1:end-1))

which gives the formula for the conversion of the Cartesian coordinates
of the point P to the Barycentric coordinates BETA.  An important
property of the Barycentric coordinates is that for all points in the
N-simplex

     0 <= BETA(I) <= 1

Therefore, the test in ‘tsearch’ and ‘tsearchn’ essentially only needs
to express each point in terms of the Barycentric coordinates of each of
the simplices of the N-simplex and test the values of BETA.  This is
exactly the implementation used in ‘tsearchn’.  ‘tsearch’ is optimized
for 2-dimensions and the Barycentric coordinates are not explicitly
formed.

 -- : IDX = tsearch (X, Y, T, XI, YI)
     Search for the enclosing Delaunay convex hull.

     For ‘T = delaunay (X, Y)’, finds the index in T containing the
     points ‘(XI, YI)’.  For points outside the convex hull, IDX is NaN.

     See also: *note delaunay: XREFdelaunay, *note delaunayn:
     XREFdelaunayn.

 -- : IDX = tsearchn (X, T, XI)
 -- : [IDX, P] = tsearchn (X, T, XI)
     Search for the enclosing Delaunay convex hull.

     For ‘T = delaunayn (X)’, finds the index in T containing the points
     XI.  For points outside the convex hull, IDX is NaN.

     If requested ‘tsearchn’ also returns the Barycentric coordinates P
     of the enclosing triangles.

     See also: *note delaunay: XREFdelaunay, *note delaunayn:
     XREFdelaunayn.

   An example of the use of ‘tsearch’ can be seen with the simple
triangulation

     X = [-1; -1; 1; 1];
     Y = [-1; 1; -1; 1];
     TRI = [1, 2, 3; 2, 3, 4];

consisting of two triangles defined by TRI.  We can then identify which
triangle a point falls in like

     tsearch (X, Y, TRI, -0.5, -0.5)
     ⇒ 1
     tsearch (X, Y, TRI, 0.5, 0.5)
     ⇒ 2

and we can confirm that a point doesn’t lie within one of the triangles
like

     tsearch (X, Y, TRI, 2, 2)
     ⇒ NaN

   The ‘dsearch’ and ‘dsearchn’ find the closest point in a tessellation
to the desired point.  The desired point does not necessarily have to be
in the tessellation, and even if it the returned point of the
tessellation does not have to be one of the vertexes of the N-simplex
within which the desired point is found.

 -- : IDX = dsearch (X, Y, TRI, XI, YI)
 -- : IDX = dsearch (X, Y, TRI, XI, YI, S)
     Return the index IDX of the closest point in ‘X, Y’ to the elements
     ‘[XI(:), YI(:)]’.

     The variable S is accepted for compatibility but is ignored.

     See also: *note dsearchn: XREFdsearchn, *note tsearch: XREFtsearch.

 -- : IDX = dsearchn (X, TRI, XI)
 -- : IDX = dsearchn (X, TRI, XI, OUTVAL)
 -- : IDX = dsearchn (X, XI)
 -- : [IDX, D] = dsearchn (...)
     Return the index IDX of the closest point in X to the elements XI.

     If OUTVAL is supplied, then the values of XI that are not contained
     within one of the simplices TRI are set to OUTVAL.  Generally, TRI
     is returned from ‘delaunayn (X)’.

     See also: *note dsearch: XREFdsearch, *note tsearch: XREFtsearch.

   An example of the use of ‘dsearch’, using the above values of X, Y
and TRI is

     dsearch (X, Y, TRI, -2, -2)
     ⇒ 1

   If you wish the points that are outside the tessellation to be
flagged, then ‘dsearchn’ can be used as

     dsearchn ([X, Y], TRI, [-2, -2], NaN)
     ⇒ NaN
     dsearchn ([X, Y], TRI, [-0.5, -0.5], NaN)
     ⇒ 1

where the point outside the tessellation are then flagged with ‘NaN’.


File: octave.info,  Node: Voronoi Diagrams,  Next: Convex Hull,  Prev: Delaunay Triangulation,  Up: Geometry

30.2 Voronoi Diagrams
=====================

A Voronoi diagram or Voronoi tessellation of a set of points S in an
N-dimensional space, is the tessellation of the N-dimensional space such
that all points in ‘V(P)’, a partitions of the tessellation where P is a
member of S, are closer to P than any other point in S.  The Voronoi
diagram is related to the Delaunay triangulation of a set of points, in
that the vertexes of the Voronoi tessellation are the centers of the
circum-circles of the simplices of the Delaunay tessellation.

 -- : voronoi (X, Y)
 -- : voronoi (X, Y, OPTIONS)
 -- : voronoi (..., "linespec")
 -- : voronoi (HAX, ...)
 -- : H = voronoi (...)
 -- : [VX, VY] = voronoi (...)
     Plot the Voronoi diagram of points ‘(X, Y)’.

     The Voronoi facets with points at infinity are not drawn.

     The OPTIONS argument, which must be a string or cell array of
     strings, contains options passed to the underlying qhull command.
     See the documentation for the Qhull library for details
     <http://www.qhull.org/html/qh-quick.htm#options>.

     If "linespec" is given it is used to set the color and line style
     of the plot.

     If an axes graphics handle HAX is supplied then the Voronoi diagram
     is drawn on the specified axes rather than in a new figure.

     If a single output argument is requested then the Voronoi diagram
     will be plotted and a graphics handle H to the plot is returned.

     [VX, VY] = voronoi (...) returns the Voronoi vertices instead of
     plotting the diagram.

          x = rand (10, 1);
          y = rand (size (x));
          h = convhull (x, y);
          [vx, vy] = voronoi (x, y);
          plot (vx, vy, "-b", x, y, "o", x(h), y(h), "-g");
          legend ("", "points", "hull");

     See also: *note voronoin: XREFvoronoin, *note delaunay:
     XREFdelaunay, *note convhull: XREFconvhull.

 -- : [C, F] = voronoin (PTS)
 -- : [C, F] = voronoin (PTS, OPTIONS)
     Compute N-dimensional Voronoi facets.

     The input matrix PTS of size [n, dim] contains n points in a space
     of dimension dim.

     C contains the points of the Voronoi facets.  The list F contains,
     for each facet, the indices of the Voronoi points.

     An optional second argument, which must be a string or cell array
     of strings, contains options passed to the underlying qhull
     command.  See the documentation for the Qhull library for details
     <http://www.qhull.org/html/qh-quick.htm#options>.

     The default options depend on the dimension of the input:

        • 2-D and 3-D: OPTIONS = ‘{"Qbb"}’

        • 4-D and higher: OPTIONS = ‘{"Qbb", "Qx"}’

     If OPTIONS is not present or ‘[]’ then the default arguments are
     used.  Otherwise, OPTIONS replaces the default argument list.  To
     append user options to the defaults it is necessary to repeat the
     default arguments in OPTIONS.  Use a null string to pass no
     arguments.

     See also: *note voronoi: XREFvoronoi, *note convhulln:
     XREFconvhulln, *note delaunayn: XREFdelaunayn.

   An example of the use of ‘voronoi’ is

     rand ("state",9);
     x = rand (10,1);
     y = rand (10,1);
     tri = delaunay (x, y);
     [vx, vy] = voronoi (x, y, tri);
     triplot (tri, x, y, "b");
     hold on;
     plot (vx, vy, "r");

   Additional information about the size of the facets of a Voronoi
diagram, and which points of a set of points is in a polygon can be had
with the ‘polyarea’ and ‘inpolygon’ functions respectively.

 -- : polyarea (X, Y)
 -- : polyarea (X, Y, DIM)

     Determine area of a polygon by triangle method.

     The variables X and Y define the vertex pairs, and must therefore
     have the same shape.  They can be either vectors or arrays.  If
     they are arrays then the columns of X and Y are treated separately
     and an area returned for each.

     If the optional DIM argument is given, then ‘polyarea’ works along
     this dimension of the arrays X and Y.

   An example of the use of ‘polyarea’ might be

     rand ("state", 2);
     x = rand (10, 1);
     y = rand (10, 1);
     [c, f] = voronoin ([x, y]);
     af = zeros (size (f));
     for i = 1 : length (f)
       af(i) = polyarea (c (f {i, :}, 1), c (f {i, :}, 2));
     endfor

   Facets of the Voronoi diagram with a vertex at infinity have infinity
area.  A simplified version of ‘polyarea’ for rectangles is available
with ‘rectint’

 -- : AREA = rectint (A, B)
     Compute area or volume of intersection of rectangles or N-D boxes.

     Compute the area of intersection of rectangles in A and rectangles
     in B.  N-dimensional boxes are supported in which case the volume,
     or hypervolume is computed according to the number of dimensions.

     2-dimensional rectangles are defined as ‘[xpos ypos width height]’
     where xpos and ypos are the position of the bottom left corner.
     Higher dimensions are supported where the coordinates for the
     minimum value of each dimension follow the length of the box in
     that dimension, e.g., ‘[xpos ypos zpos kpos ... width height depth
     k_length ...]’.

     Each row of A and B define a rectangle, and if both define multiple
     rectangles, then the output, AREA, is a matrix where the i-th row
     corresponds to the i-th row of a and the j-th column corresponds to
     the j-th row of b.

     See also: *note polyarea: XREFpolyarea.

 -- : IN = inpolygon (X, Y, XV, YV)
 -- : [IN, ON] = inpolygon (X, Y, XV, YV)

     For a polygon defined by vertex points ‘(XV, YV)’, return true if
     the points ‘(X, Y)’ are inside (or on the boundary) of the polygon;
     Otherwise, return false.

     The input variables X and Y, must have the same dimension.

     The optional output ON returns true if the points are exactly on
     the polygon edge, and false otherwise.

     See also: *note delaunay: XREFdelaunay.

   An example of the use of ‘inpolygon’ might be

     randn ("state", 2);
     x = randn (100, 1);
     y = randn (100, 1);
     vx = cos (pi * [-1 : 0.1: 1]);
     vy = sin (pi * [-1 : 0.1 : 1]);
     in = inpolygon (x, y, vx, vy);
     plot (vx, vy, x(in), y(in), "r+", x(!in), y(!in), "bo");
     axis ([-2, 2, -2, 2]);


File: octave.info,  Node: Convex Hull,  Next: Interpolation on Scattered Data,  Prev: Voronoi Diagrams,  Up: Geometry

30.3 Convex Hull
================

The convex hull of a set of points is the minimum convex envelope
containing all of the points.  Octave has the functions ‘convhull’ and
‘convhulln’ to calculate the convex hull of 2-dimensional and
N-dimensional sets of points.

 -- : H = convhull (X, Y)
 -- : H = convhull (X, Y, OPTIONS)
     Compute the convex hull of the set of points defined by the arrays
     X and Y.  The hull H is an index vector into the set of points and
     specifies which points form the enclosing hull.

     An optional third argument, which must be a string or cell array of
     strings, contains options passed to the underlying qhull command.
     See the documentation for the Qhull library for details
     <http://www.qhull.org/html/qh-quick.htm#options>.  The default
     option is ‘{"Qt"}’.

     If OPTIONS is not present or ‘[]’ then the default arguments are
     used.  Otherwise, OPTIONS replaces the default argument list.  To
     append user options to the defaults it is necessary to repeat the
     default arguments in OPTIONS.  Use a null string to pass no
     arguments.

     See also: *note convhulln: XREFconvhulln, *note delaunay:
     XREFdelaunay, *note voronoi: XREFvoronoi.

 -- : H = convhulln (PTS)
 -- : H = convhulln (PTS, OPTIONS)
 -- : [H, V] = convhulln (...)
     Compute the convex hull of the set of points PTS.

     PTS is a matrix of size [n, dim] containing n points in a space of
     dimension dim.

     The hull H is an index vector into the set of points and specifies
     which points form the enclosing hull.

     An optional second argument, which must be a string or cell array
     of strings, contains options passed to the underlying qhull
     command.  See the documentation for the Qhull library for details
     <http://www.qhull.org/html/qh-quick.htm#options>.  The default
     options depend on the dimension of the input:

        • 2D, 3D, 4D: OPTIONS = ‘{"Qt"}’

        • 5D and higher: OPTIONS = ‘{"Qt", "Qx"}’

     If OPTIONS is not present or ‘[]’ then the default arguments are
     used.  Otherwise, OPTIONS replaces the default argument list.  To
     append user options to the defaults it is necessary to repeat the
     default arguments in OPTIONS.  Use a null string to pass no
     arguments.

     If the second output V is requested the volume of the enclosing
     convex hull is calculated.

     See also: *note convhull: XREFconvhull, *note delaunayn:
     XREFdelaunayn, *note voronoin: XREFvoronoin.

   An example of the use of ‘convhull’ is

     x = -3:0.05:3;
     y = abs (sin (x));
     k = convhull (x, y);
     plot (x(k), y(k), "r-", x, y, "b+");
     axis ([-3.05, 3.05, -0.05, 1.05]);


File: octave.info,  Node: Interpolation on Scattered Data,  Prev: Convex Hull,  Up: Geometry

30.4 Interpolation on Scattered Data
====================================

An important use of the Delaunay tessellation is that it can be used to
interpolate from scattered data to an arbitrary set of points.  To do
this the N-simplex of the known set of points is calculated with
‘delaunay’ or ‘delaunayn’.  Then the simplices in to which the desired
points are found are identified.  Finally the vertices of the simplices
are used to interpolate to the desired points.  The functions that
perform this interpolation are ‘griddata’, ‘griddata3’ and ‘griddatan’.

 -- : ZI = griddata (X, Y, Z, XI, YI)
 -- : ZI = griddata (X, Y, Z, XI, YI, METHOD)
 -- : [XI, YI, ZI] = griddata (...)

     Generate a regular mesh from irregular data using interpolation.

     The function is defined by ‘Z = f (X, Y)’.  Inputs ‘X, Y, Z’ are
     vectors of the same length or ‘X, Y’ are vectors and ‘Z’ is matrix.

     The interpolation points are all ‘(XI, YI)’.  If XI, YI are vectors
     then they are made into a 2-D mesh.

     The interpolation method can be "nearest", "cubic" or "linear".  If
     method is omitted it defaults to "linear".

     See also: *note griddata3: XREFgriddata3, *note griddatan:
     XREFgriddatan, *note delaunay: XREFdelaunay.

 -- : VI = griddata3 (X, Y, Z, V, XI, YI, ZI)
 -- : VI = griddata3 (X, Y, Z, V, XI, YI, ZI, METHOD)
 -- : VI = griddata3 (X, Y, Z, V, XI, YI, ZI, METHOD, OPTIONS)

     Generate a regular mesh from irregular data using interpolation.

     The function is defined by ‘V = f (X, Y, Z)’.  The interpolation
     points are specified by XI, YI, ZI.

     The interpolation method can be "nearest" or "linear".  If method
     is omitted it defaults to "linear".

     The optional argument OPTIONS is passed directly to Qhull when
     computing the Delaunay triangulation used for interpolation.  See
     ‘delaunayn’ for information on the defaults and how to pass
     different values.

     See also: *note griddata: XREFgriddata, *note griddatan:
     XREFgriddatan, *note delaunayn: XREFdelaunayn.

 -- : YI = griddatan (X, Y, XI)
 -- : YI = griddatan (X, Y, XI, METHOD)
 -- : YI = griddatan (X, Y, XI, METHOD, OPTIONS)

     Generate a regular mesh from irregular data using interpolation.

     The function is defined by ‘Y = f (X)’.  The interpolation points
     are all XI.

     The interpolation method can be "nearest" or "linear".  If method
     is omitted it defaults to "linear".

     The optional argument OPTIONS is passed directly to Qhull when
     computing the Delaunay triangulation used for interpolation.  See
     ‘delaunayn’ for information on the defaults and how to pass
     different values.

     See also: *note griddata: XREFgriddata, *note griddata3:
     XREFgriddata3, *note delaunayn: XREFdelaunayn.

   An example of the use of the ‘griddata’ function is

     rand ("state", 1);
     x = 2*rand (1000,1) - 1;
     y = 2*rand (size (x)) - 1;
     z = sin (2*(x.^2+y.^2));
     [xx,yy] = meshgrid (linspace (-1,1,32));
     zz = griddata (x, y, z, xx, yy);
     mesh (xx, yy, zz);

that interpolates from a random scattering of points, to a uniform grid.


File: octave.info,  Node: Signal Processing,  Next: Image Processing,  Prev: Geometry,  Up: Top

31 Signal Processing
********************

This chapter describes the signal processing and fast Fourier transform
functions available in Octave.  Fast Fourier transforms are computed
with the FFTW or FFTPACK libraries depending on how Octave is built.

 -- : fft (X)
 -- : fft (X, N)
 -- : fft (X, N, DIM)
     Compute the discrete Fourier transform of X using a Fast Fourier
     Transform (FFT) algorithm.

     The FFT is calculated along the first non-singleton dimension of
     the array.  Thus if X is a matrix, ‘fft (X)’ computes the FFT for
     each column of X.

     If called with two arguments, N is expected to be an integer
     specifying the number of elements of X to use, or an empty matrix
     to specify that its value should be ignored.  If N is larger than
     the dimension along which the FFT is calculated, then X is resized
     and padded with zeros.  Otherwise, if N is smaller than the
     dimension along which the FFT is calculated, then X is truncated.

     If called with three arguments, DIM is an integer specifying the
     dimension of the matrix along which the FFT is performed.

     See also: *note ifft: XREFifft, *note fft2: XREFfft2, *note fftn:
     XREFfftn, *note fftw: XREFfftw.

 -- : ifft (X)
 -- : ifft (X, N)
 -- : ifft (X, N, DIM)
     Compute the inverse discrete Fourier transform of X using a Fast
     Fourier Transform (FFT) algorithm.

     The inverse FFT is calculated along the first non-singleton
     dimension of the array.  Thus if X is a matrix, ‘fft (X)’ computes
     the inverse FFT for each column of X.

     If called with two arguments, N is expected to be an integer
     specifying the number of elements of X to use, or an empty matrix
     to specify that its value should be ignored.  If N is larger than
     the dimension along which the inverse FFT is calculated, then X is
     resized and padded with zeros.  Otherwise, if N is smaller than the
     dimension along which the inverse FFT is calculated, then X is
     truncated.

     If called with three arguments, DIM is an integer specifying the
     dimension of the matrix along which the inverse FFT is performed.

     See also: *note fft: XREFfft, *note ifft2: XREFifft2, *note ifftn:
     XREFifftn, *note fftw: XREFfftw.

 -- : fft2 (A)
 -- : fft2 (A, M, N)
     Compute the two-dimensional discrete Fourier transform of A using a
     Fast Fourier Transform (FFT) algorithm.

     The optional arguments M and N may be used specify the number of
     rows and columns of A to use.  If either of these is larger than
     the size of A, A is resized and padded with zeros.

     If A is a multi-dimensional matrix, each two-dimensional sub-matrix
     of A is treated separately.

     See also: *note ifft2: XREFifft2, *note fft: XREFfft, *note fftn:
     XREFfftn, *note fftw: XREFfftw.

 -- : ifft2 (A)
 -- : ifft2 (A, M, N)
     Compute the inverse two-dimensional discrete Fourier transform of A
     using a Fast Fourier Transform (FFT) algorithm.

     The optional arguments M and N may be used specify the number of
     rows and columns of A to use.  If either of these is larger than
     the size of A, A is resized and padded with zeros.

     If A is a multi-dimensional matrix, each two-dimensional sub-matrix
     of A is treated separately.

     See also: *note fft2: XREFfft2, *note ifft: XREFifft, *note ifftn:
     XREFifftn, *note fftw: XREFfftw.

 -- : fftn (A)
 -- : fftn (A, SIZE)
     Compute the N-dimensional discrete Fourier transform of A using a
     Fast Fourier Transform (FFT) algorithm.

     The optional vector argument SIZE may be used specify the
     dimensions of the array to be used.  If an element of SIZE is
     smaller than the corresponding dimension of A, then the dimension
     of A is truncated prior to performing the FFT.  Otherwise, if an
     element of SIZE is larger than the corresponding dimension then A
     is resized and padded with zeros.

     See also: *note ifftn: XREFifftn, *note fft: XREFfft, *note fft2:
     XREFfft2, *note fftw: XREFfftw.

 -- : ifftn (A)
 -- : ifftn (A, SIZE)
     Compute the inverse N-dimensional discrete Fourier transform of A
     using a Fast Fourier Transform (FFT) algorithm.

     The optional vector argument SIZE may be used specify the
     dimensions of the array to be used.  If an element of SIZE is
     smaller than the corresponding dimension of A, then the dimension
     of A is truncated prior to performing the inverse FFT.  Otherwise,
     if an element of SIZE is larger than the corresponding dimension
     then A is resized and padded with zeros.

     See also: *note fftn: XREFfftn, *note ifft: XREFifft, *note ifft2:
     XREFifft2, *note fftw: XREFfftw.

   Octave uses the FFTW libraries to perform FFT computations.  When
Octave starts up and initializes the FFTW libraries, they read a system
wide file (on a Unix system, it is typically ‘/etc/fftw/wisdom’) that
contains information useful to speed up FFT computations.  This
information is called the _wisdom_.  The system-wide file allows wisdom
to be shared between all applications using the FFTW libraries.

   Use the ‘fftw’ function to generate and save wisdom.  Using the
utilities provided together with the FFTW libraries (‘fftw-wisdom’ on
Unix systems), you can even add wisdom generated by Octave to the
system-wide wisdom file.

 -- : METHOD = fftw ("planner")
 -- : fftw ("planner", METHOD)
 -- : WISDOM = fftw ("dwisdom")
 -- : fftw ("dwisdom", WISDOM)
 -- : fftw ("threads", NTHREADS)
 -- : NTHREADS = fftw ("threads")

     Manage FFTW wisdom data.

     Wisdom data can be used to significantly accelerate the calculation
     of the FFTs, but implies an initial cost in its calculation.  When
     the FFTW libraries are initialized, they read a system wide wisdom
     file (typically in ‘/etc/fftw/wisdom’), allowing wisdom to be
     shared between applications other than Octave.  Alternatively, the
     ‘fftw’ function can be used to import wisdom.  For example,

          WISDOM = fftw ("dwisdom")

     will save the existing wisdom used by Octave to the string WISDOM.
     This string can then be saved to a file and restored using the
     ‘save’ and ‘load’ commands respectively.  This existing wisdom can
     be re-imported as follows

          fftw ("dwisdom", WISDOM)

     If WISDOM is an empty string, then the wisdom used is cleared.

     During the calculation of Fourier transforms further wisdom is
     generated.  The fashion in which this wisdom is generated is also
     controlled by the ‘fftw’ function.  There are five different
     manners in which the wisdom can be treated:

     "estimate"
          Specifies that no run-time measurement of the optimal means of
          calculating a particular is performed, and a simple heuristic
          is used to pick a (probably sub-optimal) plan.  The advantage
          of this method is that there is little or no overhead in the
          generation of the plan, which is appropriate for a Fourier
          transform that will be calculated once.

     "measure"
          In this case a range of algorithms to perform the transform is
          considered and the best is selected based on their execution
          time.

     "patient"
          Similar to "measure", but a wider range of algorithms is
          considered.

     "exhaustive"
          Like "measure", but all possible algorithms that may be used
          to treat the transform are considered.

     "hybrid"
          As run-time measurement of the algorithm can be expensive,
          this is a compromise where "measure" is used for transforms up
          to the size of 8192 and beyond that the "estimate" method is
          used.

     The default method is "estimate".  The current method can be
     queried with

          METHOD = fftw ("planner")

     or set by using

          fftw ("planner", METHOD)

     Note that calculated wisdom will be lost when restarting Octave.
     However, the wisdom data can be reloaded if it is saved to a file
     as described above.  Saved wisdom files should not be used on
     different platforms since they will not be efficient and the point
     of calculating the wisdom is lost.

     The number of threads used for computing the plans and executing
     the transforms can be set with

          fftw ("threads", NTHREADS)

     Note that octave must be compiled with multi-threaded FFTW support
     for this feature.  The number of processors available to the
     current process is used per default.

     See also: *note fft: XREFfft, *note ifft: XREFifft, *note fft2:
     XREFfft2, *note ifft2: XREFifft2, *note fftn: XREFfftn, *note
     ifftn: XREFifftn.

 -- : fftconv (X, Y)
 -- : fftconv (X, Y, N)
     Convolve two vectors using the FFT for computation.

     ‘c = fftconv (X, Y)’ returns a vector of length equal to ‘length
     (X) + length (Y) - 1’.  If X and Y are the coefficient vectors of
     two polynomials, the returned value is the coefficient vector of
     the product polynomial.

     The computation uses the FFT by calling the function ‘fftfilt’.  If
     the optional argument N is specified, an N-point FFT is used.

     See also: *note deconv: XREFdeconv, *note conv: XREFconv, *note
     conv2: XREFconv2.

 -- : fftfilt (B, X)
 -- : fftfilt (B, X, N)
     Filter X with the FIR filter B using the FFT.

     If X is a matrix, filter each column of the matrix.

     Given the optional third argument, N, ‘fftfilt’ uses the
     overlap-add method to filter X with B using an N-point FFT.  The
     FFT size must be an even power of 2 and must be greater than or
     equal to the length of B.  If the specified N does not meet these
     criteria, it is automatically adjusted to the nearest value that
     does.

     See also: *note filter: XREFfilter, *note filter2: XREFfilter2.

 -- : Y = filter (B, A, X)
 -- : [Y, SF] = filter (B, A, X, SI)
 -- : [Y, SF] = filter (B, A, X, [], DIM)
 -- : [Y, SF] = filter (B, A, X, SI, DIM)
     Apply a 1-D digital filter to the data X.

     ‘filter’ returns the solution to the following linear,
     time-invariant difference equation:

           N                   M
          SUM a(k+1) y(n-k) = SUM b(k+1) x(n-k)    for 1<=n<=length(x)
          k=0                 k=0

     where N=length(a)-1 and M=length(b)-1.  The result is calculated
     over the first non-singleton dimension of X or over DIM if
     supplied.

     An equivalent form of the equation is:

                    N                   M
          y(n) = - SUM c(k+1) y(n-k) + SUM d(k+1) x(n-k)  for 1<=n<=length(x)
                   k=1                 k=0

     where c = a/a(1) and d = b/a(1).

     If the fourth argument SI is provided, it is taken as the initial
     state of the system and the final state is returned as SF.  The
     state vector is a column vector whose length is equal to the length
     of the longest coefficient vector minus one.  If SI is not
     supplied, the initial state vector is set to all zeros.

     In terms of the Z Transform, Y is the result of passing the
     discrete-time signal X through a system characterized by the
     following rational system function:

                    M
                   SUM d(k+1) z^(-k)
                   k=0
          H(z) = ---------------------
                      N
                 1 + SUM c(k+1) z^(-k)
                     k=1

     See also: *note filter2: XREFfilter2, *note fftfilt: XREFfftfilt,
     *note freqz: XREFfreqz.

 -- : Y = filter2 (B, X)
 -- : Y = filter2 (B, X, SHAPE)
     Apply the 2-D FIR filter B to X.

     If the argument SHAPE is specified, return an array of the desired
     shape.  Possible values are:

     "full"
          pad X with zeros on all sides before filtering.

     "same"
          unpadded X (default)

     "valid"
          trim X after filtering so edge effects are no included.

     Note this is just a variation on convolution, with the parameters
     reversed and B rotated 180 degrees.

     See also: *note conv2: XREFconv2.

 -- : [H, W] = freqz (B, A, N, "whole")
 -- : [H, W] = freqz (B)
 -- : [H, W] = freqz (B, A)
 -- : [H, W] = freqz (B, A, N)
 -- : H = freqz (B, A, W)
 -- : [H, W] = freqz (..., FS)
 -- : freqz (...)

     Return the complex frequency response H of the rational IIR filter
     whose numerator and denominator coefficients are B and A,
     respectively.

     The response is evaluated at N angular frequencies between 0 and
     2*pi.

     The output value W is a vector of the frequencies.

     If A is omitted, the denominator is assumed to be 1 (this
     corresponds to a simple FIR filter).

     If N is omitted, a value of 512 is assumed.  For fastest
     computation, N should factor into a small number of small primes.

     If the fourth argument, "whole", is omitted the response is
     evaluated at frequencies between 0 and pi.

     ‘freqz (B, A, W)’

     Evaluate the response at the specific frequencies in the vector W.
     The values for W are measured in radians.

     ‘[...] = freqz (..., FS)’

     Return frequencies in Hz instead of radians assuming a sampling
     rate FS.  If you are evaluating the response at specific
     frequencies W, those frequencies should be requested in Hz rather
     than radians.

     ‘freqz (...)’

     Plot the magnitude and phase response of H rather than returning
     them.

     See also: *note freqz_plot: XREFfreqz_plot.

 -- : freqz_plot (W, H)
 -- : freqz_plot (W, H, FREQ_NORM)
     Plot the magnitude and phase response of H.

     If the optional FREQ_NORM argument is true, the frequency vector W
     is in units of normalized radians.  If FREQ_NORM is false, or not
     given, then W is measured in Hertz.

     See also: *note freqz: XREFfreqz.

 -- : sinc (X)
     Compute the sinc function.

     Return sin (pi*x) / (pi*x).

 -- : B = unwrap (X)
 -- : B = unwrap (X, TOL)
 -- : B = unwrap (X, TOL, DIM)

     Unwrap radian phases by adding or subtracting multiples of 2*pi as
     appropriate to remove jumps greater than TOL.

     TOL defaults to pi.

     Unwrap will work along the dimension DIM.  If DIM is unspecified it
     defaults to the first non-singleton dimension.

 -- : [A, B] = arch_fit (Y, X, P, ITER, GAMMA, A0, B0)
     Fit an ARCH regression model to the time series Y using the scoring
     algorithm in Engle’s original ARCH paper.

     The model is

          y(t) = b(1) * x(t,1) + ... + b(k) * x(t,k) + e(t),
          h(t) = a(1) + a(2) * e(t-1)^2 + ... + a(p+1) * e(t-p)^2

     in which e(t) is N(0, h(t)), given a time-series vector Y up to
     time t-1 and a matrix of (ordinary) regressors X up to t.  The
     order of the regression of the residual variance is specified by P.

     If invoked as ‘arch_fit (Y, K, P)’ with a positive integer K, fit
     an ARCH(K, P) process, i.e., do the above with the t-th row of X
     given by

          [1, y(t-1), ..., y(t-k)]

     Optionally, one can specify the number of iterations ITER, the
     updating factor GAMMA, and initial values a0 and b0 for the scoring
     algorithm.

 -- : arch_rnd (A, B, T)
     Simulate an ARCH sequence of length T with AR coefficients B and CH
     coefficients A.

     The result y(t) follows the model

          y(t) = b(1) + b(2) * y(t-1) + ... + b(lb) * y(t-lb+1) + e(t),

     where e(t), given Y up to time t-1, is N(0, h(t)), with

          h(t) = a(1) + a(2) * e(t-1)^2 + ... + a(la) * e(t-la+1)^2

 -- : [PVAL, LM] = arch_test (Y, X, P)
     For a linear regression model

          y = x * b + e

     perform a Lagrange Multiplier (LM) test of the null hypothesis of
     no conditional heteroscedascity against the alternative of CH(P).

     I.e., the model is

          y(t) = b(1) * x(t,1) + ... + b(k) * x(t,k) + e(t),

     given Y up to t-1 and X up to t, e(t) is N(0, h(t)) with

          h(t) = v + a(1) * e(t-1)^2 + ... + a(p) * e(t-p)^2,

     and the null is a(1) == ... == a(p) == 0.

     If the second argument is a scalar integer, k, perform the same
     test in a linear autoregression model of order k, i.e., with

          [1, y(t-1), ..., y(t-K)]

     as the t-th row of X.

     Under the null, LM approximately has a chisquare distribution with
     P degrees of freedom and PVAL is the p-value (1 minus the CDF of
     this distribution at LM) of the test.

     If no output argument is given, the p-value is displayed.

 -- : arma_rnd (A, B, V, T, N)
     Return a simulation of the ARMA model.

     The ARMA model is defined by

          x(n) = a(1) * x(n-1) + ... + a(k) * x(n-k)
               + e(n) + b(1) * e(n-1) + ... + b(l) * e(n-l)

     in which K is the length of vector A, L is the length of vector B
     and E is Gaussian white noise with variance V.  The function
     returns a vector of length T.

     The optional parameter N gives the number of dummy X(I) used for
     initialization, i.e., a sequence of length T+N is generated and
     X(N+1:T+N) is returned.  If N is omitted, N = 100 is used.

 -- : autoreg_matrix (Y, K)
     Given a time series (vector) Y, return a matrix with ones in the
     first column and the first K lagged values of Y in the other
     columns.

     In other words, for T > K, ‘[1, Y(T-1), ..., Y(T-K)]’ is the t-th
     row of the result.

     The resulting matrix may be used as a regressor matrix in
     autoregressions.

 -- : bartlett (M)
     Return the filter coefficients of a Bartlett (triangular) window of
     length M.

     For a definition of the Bartlett window see, e.g., A.V. Oppenheim &
     R. W. Schafer, ‘Discrete-Time Signal Processing’.

 -- : blackman (M)
 -- : blackman (M, "periodic")
 -- : blackman (M, "symmetric")
     Return the filter coefficients of a Blackman window of length M.

     If the optional argument "periodic" is given, the periodic form of
     the window is returned.  This is equivalent to the window of length
     M+1 with the last coefficient removed.  The optional argument
     "symmetric" is equivalent to not specifying a second argument.

     For a definition of the Blackman window, see, e.g., A.V. Oppenheim
     & R. W. Schafer, ‘Discrete-Time Signal Processing’.

 -- : detrend (X, P)
     If X is a vector, ‘detrend (X, P)’ removes the best fit of a
     polynomial of order P from the data X.

     If X is a matrix, ‘detrend (X, P)’ does the same for each column in
     X.

     The second argument P is optional.  If it is not specified, a value
     of 1 is assumed.  This corresponds to removing a linear trend.

     The order of the polynomial can also be given as a string, in which
     case P must be either "constant" (corresponds to ‘P=0’) or "linear"
     (corresponds to ‘P=1’).

     See also: *note polyfit: XREFpolyfit.

 -- : [D, DD] = diffpara (X, A, B)
     Return the estimator D for the differencing parameter of an
     integrated time series.

     The frequencies from [2*pi*a/t, 2*pi*b/T] are used for the
     estimation.  If B is omitted, the interval [2*pi/T, 2*pi*a/T] is
     used.  If both B and A are omitted then a = 0.5 * sqrt (T) and b =
     1.5 * sqrt (T) is used, where T is the sample size.  If X is a
     matrix, the differencing parameter of each column is estimated.

     The estimators for all frequencies in the intervals described above
     is returned in DD.

     The value of D is simply the mean of DD.

     Reference: P.J. Brockwell & R.A. Davis.  ‘Time Series: Theory and
     Methods’.  Springer 1987.

 -- : durbinlevinson (C, OLDPHI, OLDV)
     Perform one step of the Durbin-Levinson algorithm.

     The vector C specifies the autocovariances ‘[gamma_0, ...,
     gamma_t]’ from lag 0 to T, OLDPHI specifies the coefficients based
     on C(T-1) and OLDV specifies the corresponding error.

     If OLDPHI and OLDV are omitted, all steps from 1 to T of the
     algorithm are performed.

 -- : fftshift (X)
 -- : fftshift (X, DIM)
     Perform a shift of the vector X, for use with the ‘fft’ and ‘ifft’
     functions, in order to move the frequency 0 to the center of the
     vector or matrix.

     If X is a vector of N elements corresponding to N time samples
     spaced by dt, then ‘fftshift (fft (X))’ corresponds to frequencies

          f = [ -(ceil((N-1)/2):-1:1), 0, (1:floor((N-1)/2)) ] * df

     where df = 1 / (N * dt).

     If X is a matrix, the same holds for rows and columns.  If X is an
     array, then the same holds along each dimension.

     The optional DIM argument can be used to limit the dimension along
     which the permutation occurs.

     See also: *note ifftshift: XREFifftshift.

 -- : ifftshift (X)
 -- : ifftshift (X, DIM)
     Undo the action of the ‘fftshift’ function.

     For even length X, ‘fftshift’ is its own inverse, but odd lengths
     differ slightly.

     See also: *note fftshift: XREFfftshift.

 -- : fractdiff (X, D)
     Compute the fractional differences (1-L)^d x where L denotes the
     lag-operator and d is greater than -1.

 -- : hamming (M)
 -- : hamming (M, "periodic")
 -- : hamming (M, "symmetric")
     Return the filter coefficients of a Hamming window of length M.

     If the optional argument "periodic" is given, the periodic form of
     the window is returned.  This is equivalent to the window of length
     M+1 with the last coefficient removed.  The optional argument
     "symmetric" is equivalent to not specifying a second argument.

     For a definition of the Hamming window see, e.g., A.V. Oppenheim &
     R. W. Schafer, ‘Discrete-Time Signal Processing’.

 -- : hanning (M)
 -- : hanning (M, "periodic")
 -- : hanning (M, "symmetric")
     Return the filter coefficients of a Hanning window of length M.

     If the optional argument "periodic" is given, the periodic form of
     the window is returned.  This is equivalent to the window of length
     M+1 with the last coefficient removed.  The optional argument
     "symmetric" is equivalent to not specifying a second argument.

     For a definition of the Hanning window see, e.g., A.V. Oppenheim &
     R. W. Schafer, ‘Discrete-Time Signal Processing’.

 -- : hurst (X)
     Estimate the Hurst parameter of sample X via the rescaled range
     statistic.

     If X is a matrix, the parameter is estimated for every column.

 -- : PP = pchip (X, Y)
 -- : YI = pchip (X, Y, XI)
     Return the Piecewise Cubic Hermite Interpolating Polynomial (pchip)
     of points X and Y.

     If called with two arguments, return the piecewise polynomial PP
     that may be used with ‘ppval’ to evaluate the polynomial at
     specific points.

     When called with a third input argument, ‘pchip’ evaluates the
     pchip polynomial at the points XI.  The third calling form is
     equivalent to ‘ppval (pchip (X, Y), XI)’.

     The variable X must be a strictly monotonic vector (either
     increasing or decreasing) of length N.

     Y can be either a vector or array.  If Y is a vector then it must
     be the same length N as X.  If Y is an array then the size of Y
     must have the form ‘[S1, S2, ..., SK, N]’ The array is reshaped
     internally to a matrix where the leading dimension is given by ‘S1
     * S2 * ... * SK’ and each row of this matrix is then treated
     separately.  Note that this is exactly opposite to ‘interp1’ but is
     done for MATLAB compatibility.

     See also: *note spline: XREFspline, *note ppval: XREFppval, *note
     mkpp: XREFmkpp, *note unmkpp: XREFunmkpp.

 -- : [PXX, W] = periodogram (X)
 -- : [PXX, W] = periodogram (X, WIN)
 -- : [PXX, W] = periodogram (X, WIN, NFFT)
 -- : [PXX, F] = periodogram (X, WIN, NFFT, FS)
 -- : [PXX, F] = periodogram (..., "RANGE")
 -- : periodogram (...)
     Return the periodogram (Power Spectral Density) of X.

     The possible inputs are:

     X

          data vector.  If X is real-valued a one-sided spectrum is
          estimated.  If X is complex-valued, or "RANGE" specifies
          "twosided", the full spectrum is estimated.

     WIN
          window weight data.  If window is empty or unspecified a
          default rectangular window is used.  Otherwise, the window is
          applied to the signal (‘X .* WIN’) before computing the
          periodogram.  The window data must be a vector of the same
          length as X.

     NFFT
          number of frequency bins.  The default is 256 or the next
          higher power of 2 greater than the length of X (‘max (256,
          2.^nextpow2 (length (x)))’).  If NFFT is greater than the
          length of the input then X will be zero-padded to the length
          of NFFT.

     FS
          sampling rate.  The default is 1.

     RANGE
          range of spectrum.  "onesided" computes spectrum from
          [0:nfft/2+1].  "twosided" computes spectrum from [0:nfft-1].

     The optional second output W are the normalized angular
     frequencies.  For a one-sided calculation W is in the range [0, pi]
     if NFFT is even and [0, pi) if NFFT is odd.  Similarly, for a
     two-sided calculation W is in the range [0, 2*pi] or [0, 2*pi)
     depending on NFFT.

     If a sampling frequency is specified, FS, then the output
     frequencies F will be in the range [0, FS/2] or [0, FS/2) for
     one-sided calculations.  For two-sided calculations the range will
     be [0, FS).

     When called with no outputs the periodogram is immediately plotted
     in the current figure window.

     See also: *note fft: XREFfft.

 -- : sinetone (FREQ, RATE, SEC, AMPL)
     Return a sinetone of frequency FREQ with a length of SEC seconds at
     sampling rate RATE and with amplitude AMPL.

     The arguments FREQ and AMPL may be vectors of common size.

     The defaults are RATE = 8000, SEC = 1, and AMPL = 64.

     See also: *note sinewave: XREFsinewave.

 -- : sinewave (M, N, D)
     Return an M-element vector with I-th element given by ‘sin (2 * pi
     * (I+D-1) / N)’.

     The default value for D is 0 and the default value for N is M.

     See also: *note sinetone: XREFsinetone.

 -- : spectral_adf (C)
 -- : spectral_adf (C, WIN)
 -- : spectral_adf (C, WIN, B)
     Return the spectral density estimator given a vector of
     autocovariances C, window name WIN, and bandwidth, B.

     The window name, e.g., "triangle" or "rectangle" is used to search
     for a function called ‘WIN_lw’.

     If WIN is omitted, the triangle window is used.

     If B is omitted, ‘1 / sqrt (length (X))’ is used.

     See also: *note spectral_xdf: XREFspectral_xdf.

 -- : spectral_xdf (X)
 -- : spectral_xdf (X, WIN)
 -- : spectral_xdf (X, WIN, B)
     Return the spectral density estimator given a data vector X, window
     name WIN, and bandwidth, B.

     The window name, e.g., "triangle" or "rectangle" is used to search
     for a function called ‘WIN_sw’.

     If WIN is omitted, the triangle window is used.

     If B is omitted, ‘1 / sqrt (length (X))’ is used.

     See also: *note spectral_adf: XREFspectral_adf.

 -- : spencer (X)
     Return Spencer’s 15 point moving average of each column of X.

 -- : Y = stft (X)
 -- : Y = stft (X, WIN_SIZE)
 -- : Y = stft (X, WIN_SIZE, INC)
 -- : Y = stft (X, WIN_SIZE, INC, NUM_COEF)
 -- : Y = stft (X, WIN_SIZE, INC, NUM_COEF, WIN_TYPE)
 -- : [Y, C] = stft (...)
     Compute the short-time Fourier transform of the vector X with
     NUM_COEF coefficients by applying a window of WIN_SIZE data points
     and an increment of INC points.

     Before computing the Fourier transform, one of the following
     windows is applied:

     "hanning"
          win_type = 1

     "hamming"
          win_type = 2

     "rectangle"
          win_type = 3

     The window names can be passed as strings or by the WIN_TYPE
     number.

     The following defaults are used for unspecified arguments: WIN_SIZE
     = 80, INC = 24, NUM_COEF = 64, and WIN_TYPE = 1.

     ‘Y = stft (X, ...)’ returns the absolute values of the Fourier
     coefficients according to the NUM_COEF positive frequencies.

     ‘[Y, C] = stft (X, ...)’ returns the entire STFT-matrix Y and a
     3-element vector C containing the window size, increment, and
     window type, which is needed by the ‘synthesis’ function.

     See also: *note synthesis: XREFsynthesis.

 -- : X = synthesis (Y, C)
     Compute a signal from its short-time Fourier transform Y and a
     3-element vector C specifying window size, increment, and window
     type.

     The values Y and C can be derived by

          [Y, C] = stft (X , ...)

     See also: *note stft: XREFstft.

 -- : [A, V] = yulewalker (C)
     Fit an AR (p)-model with Yule-Walker estimates given a vector C of
     autocovariances ‘[gamma_0, ..., gamma_p]’.

     Returns the AR coefficients, A, and the variance of white noise, V.

