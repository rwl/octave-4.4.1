<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<!-- Created by GNU Texinfo 6.5, http://www.gnu.org/software/texinfo/ -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Matrix Factorizations (GNU Octave (version 4.4.1))</title>

<meta name="description" content="Matrix Factorizations (GNU Octave (version 4.4.1))">
<meta name="keywords" content="Matrix Factorizations (GNU Octave (version 4.4.1))">
<meta name="resource-type" content="document">
<meta name="distribution" content="global">
<meta name="Generator" content="makeinfo">
<link href="index.html#Top" rel="start" title="Top">
<link href="Concept-Index.html#Concept-Index" rel="index" title="Concept Index">
<link href="index.html#SEC_Contents" rel="contents" title="Table of Contents">
<link href="Linear-Algebra.html#Linear-Algebra" rel="up" title="Linear Algebra">
<link href="Functions-of-a-Matrix.html#Functions-of-a-Matrix" rel="next" title="Functions of a Matrix">
<link href="Basic-Matrix-Functions.html#Basic-Matrix-Functions" rel="prev" title="Basic Matrix Functions">
<style type="text/css">
<!--
a.summary-letter {text-decoration: none}
blockquote.indentedblock {margin-right: 0em}
blockquote.smallindentedblock {margin-right: 0em; font-size: smaller}
blockquote.smallquotation {font-size: smaller}
div.display {margin-left: 3.2em}
div.example {margin-left: 3.2em}
div.lisp {margin-left: 3.2em}
div.smalldisplay {margin-left: 3.2em}
div.smallexample {margin-left: 3.2em}
div.smalllisp {margin-left: 3.2em}
kbd {font-style: oblique}
pre.display {font-family: inherit}
pre.format {font-family: inherit}
pre.menu-comment {font-family: serif}
pre.menu-preformatted {font-family: serif}
pre.smalldisplay {font-family: inherit; font-size: smaller}
pre.smallexample {font-size: smaller}
pre.smallformat {font-family: inherit; font-size: smaller}
pre.smalllisp {font-size: smaller}
span.nolinebreak {white-space: nowrap}
span.roman {font-family: initial; font-weight: normal}
span.sansserif {font-family: sans-serif; font-weight: normal}
ul.no-bullet {list-style: none}
-->
</style>
<link rel="stylesheet" type="text/css" href="octave.css">


</head>

<body lang="en">
<a name="Matrix-Factorizations"></a>
<div class="header">
<p>
Next: <a href="Functions-of-a-Matrix.html#Functions-of-a-Matrix" accesskey="n" rel="next">Functions of a Matrix</a>, Previous: <a href="Basic-Matrix-Functions.html#Basic-Matrix-Functions" accesskey="p" rel="prev">Basic Matrix Functions</a>, Up: <a href="Linear-Algebra.html#Linear-Algebra" accesskey="u" rel="up">Linear Algebra</a> &nbsp; [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Concept-Index.html#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>
<hr>
<a name="Matrix-Factorizations-1"></a>
<h3 class="section">18.3 Matrix Factorizations</h3>
<a name="index-matrix-factorizations"></a>

<a name="XREFchol"></a><dl>
<dt><a name="index-chol"></a><em><var>R</var> =</em> <strong>chol</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-chol-1"></a><em>[<var>R</var>, <var>p</var>] =</em> <strong>chol</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-chol-2"></a><em>[<var>R</var>, <var>p</var>, <var>Q</var>] =</em> <strong>chol</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-chol-3"></a><em>[<var>R</var>, <var>p</var>, <var>Q</var>] =</em> <strong>chol</strong> <em>(<var>A</var>, &quot;vector&quot;)</em></dt>
<dt><a name="index-chol-4"></a><em>[<var>L</var>, &hellip;] =</em> <strong>chol</strong> <em>(&hellip;, &quot;lower&quot;)</em></dt>
<dt><a name="index-chol-5"></a><em>[<var>R</var>, &hellip;] =</em> <strong>chol</strong> <em>(&hellip;, &quot;upper&quot;)</em></dt>
<dd><a name="index-Cholesky-factorization"></a>
<p>Compute the upper Cholesky&nbsp;factor, <var>R</var>, of the real symmetric
or complex Hermitian positive definite matrix <var>A</var>.
</p>
<p>The upper Cholesky&nbsp;factor <var>R</var> is computed by using the upper
triangular part of matrix <var>A</var> and is defined by
</p>
<div class="example">
<pre class="example"><var>R</var>' * <var>R</var> = <var>A</var>.
</pre></div>


<p>Calling <code>chol</code> using the optional <code>&quot;upper&quot;</code> flag has the
same behavior.  In contrast, using the optional <code>&quot;lower&quot;</code> flag,
<code>chol</code> returns the lower triangular factorization, computed by using
the lower triangular part of matrix <var>A</var>, such that
</p>
<div class="example">
<pre class="example"><var>L</var> * <var>L</var>' = <var>A</var>.
</pre></div>


<p>Called with one output argument <code>chol</code> fails if matrix <var>A</var> is
not positive definite.  Note that if matrix <var>A</var> is not real symmetric
or complex Hermitian then the lower triangular part is considered to be
the (complex conjugate) transpose of the upper triangular part, or vice
versa, given the <code>&quot;lower&quot;</code> flag.
</p>
<p>Called with two or more output arguments <var>p</var> flags whether the matrix
<var>A</var> was positive definite and <code>chol</code> does not fail.  A zero value
of <var>p</var> indicates that matrix <var>A</var> is positive definite and <var>R</var>
gives the factorization.  Otherwise, <var>p</var> will have a positive value.
</p>
<p>If called with three output arguments matrix <var>A</var> must be sparse and
a sparsity preserving row/column permutation is applied to matrix <var>A</var>
prior to the factorization.  That is <var>R</var> is the factorization of
<code><var>A</var>(<var>Q</var>,<var>Q</var>)</code> such that
</p>
<div class="example">
<pre class="example"><var>R</var>' * <var>R</var> = <var>Q</var>' * <var>A</var> * <var>Q</var>.
</pre></div>


<p>The sparsity preserving permutation is generally returned as a matrix.
However, given the optional flag <code>&quot;vector&quot;</code>, <var>Q</var> will be
returned as a vector such that
</p>
<div class="example">
<pre class="example"><var>R</var>' * <var>R</var> = <var>A</var>(<var>Q</var>, <var>Q</var>).
</pre></div>


<p>In general the lower triangular factorization is significantly faster for
sparse matrices.
</p>
<p><strong>See also:</strong> <a href="#XREFhess">hess</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>, <a href="Iterative-Techniques.html#XREFichol">ichol</a>, <a href="#XREFcholinv">cholinv</a>, <a href="#XREFchol2inv">chol2inv</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholdelete">choldelete</a>, <a href="#XREFcholshift">cholshift</a>.
</p></dd></dl>


<a name="XREFcholinv"></a><dl>
<dt><a name="index-cholinv"></a><em></em> <strong>cholinv</strong> <em>(<var>A</var>)</em></dt>
<dd><p>Compute the inverse of the symmetric positive definite matrix <var>A</var> using
the Cholesky&nbsp;factorization.
</p>
<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFchol2inv">chol2inv</a>, <a href="Basic-Matrix-Functions.html#XREFinv">inv</a>.
</p></dd></dl>


<a name="XREFchol2inv"></a><dl>
<dt><a name="index-chol2inv"></a><em></em> <strong>chol2inv</strong> <em>(<var>U</var>)</em></dt>
<dd><p>Invert a symmetric, positive definite square matrix from its Cholesky
decomposition, <var>U</var>.
</p>
<p>Note that <var>U</var> should be an upper-triangular matrix with positive
diagonal elements.  <code>chol2inv (<var>U</var>)</code> provides
<code>inv (<var>U</var>'*<var>U</var>)</code> but it is much faster than using <code>inv</code>.
</p>
<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholinv">cholinv</a>, <a href="Basic-Matrix-Functions.html#XREFinv">inv</a>.
</p></dd></dl>


<a name="XREFcholupdate"></a><dl>
<dt><a name="index-cholupdate"></a><em>[<var>R1</var>, <var>info</var>] =</em> <strong>cholupdate</strong> <em>(<var>R</var>, <var>u</var>, <var>op</var>)</em></dt>
<dd><p>Update or downdate a Cholesky&nbsp;factorization.
</p>
<p>Given an upper triangular matrix <var>R</var> and a column vector <var>u</var>,
attempt to determine another upper triangular matrix <var>R1</var> such that
</p>
<ul>
<li> <var>R1</var>&rsquo;*<var>R1</var> = <var>R</var>&rsquo;*<var>R</var> + <var>u</var>*<var>u</var>&rsquo;
if <var>op</var> is <code>&quot;+&quot;</code>

</li><li> <var>R1</var>&rsquo;*<var>R1</var> = <var>R</var>&rsquo;*<var>R</var> - <var>u</var>*<var>u</var>&rsquo;
if <var>op</var> is <code>&quot;-&quot;</code>
</li></ul>

<p>If <var>op</var> is <code>&quot;-&quot;</code>, <var>info</var> is set to
</p>
<ul>
<li> 0 if the downdate was successful,

</li><li> 1 if <var>R</var>&rsquo;*<var>R</var> - <var>u</var>*<var>u</var>&rsquo; is not positive definite,

</li><li> 2 if <var>R</var> is singular.
</li></ul>

<p>If <var>info</var> is not present, an error message is printed in cases 1 and 2.
</p>
<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholdelete">choldelete</a>, <a href="#XREFcholshift">cholshift</a>.
</p></dd></dl>


<a name="XREFcholinsert"></a><dl>
<dt><a name="index-cholinsert"></a><em><var>R1</var> =</em> <strong>cholinsert</strong> <em>(<var>R</var>, <var>j</var>, <var>u</var>)</em></dt>
<dt><a name="index-cholinsert-1"></a><em>[<var>R1</var>, <var>info</var>] =</em> <strong>cholinsert</strong> <em>(<var>R</var>, <var>j</var>, <var>u</var>)</em></dt>
<dd><p>Update a Cholesky factorization given a row or column to insert in the original factored matrix.
</p>
<p>Given a Cholesky&nbsp;factorization of a real symmetric or complex Hermitian
positive definite matrix <var>A</var>&nbsp;=&nbsp;<var>R</var>&rsquo;*<var>R</var><!-- /@w -->, <var>R</var>&nbsp;upper
triangular, return the Cholesky&nbsp;factorization of
<var>A1</var>, where A1(p,p)&nbsp;=&nbsp;A<!-- /@w -->, A1(:,j)&nbsp;=&nbsp;A1(j,:)&rsquo;&nbsp;=&nbsp;u<!-- /@w --> and
p&nbsp;=&nbsp;<span class="nolinebreak">[1:j-1,j+1:n+1]</span><!-- /@w -->.  u(j)<!-- /@w --> should be positive.
</p>
<p>On return, <var>info</var> is set to
</p>
<ul>
<li> 0 if the insertion was successful,

</li><li> 1 if <var>A1</var> is not positive definite,

</li><li> 2 if <var>R</var> is singular.
</li></ul>

<p>If <var>info</var> is not present, an error message is printed in cases 1 and 2.
</p>
<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholdelete">choldelete</a>, <a href="#XREFcholshift">cholshift</a>.
</p></dd></dl>


<a name="XREFcholdelete"></a><dl>
<dt><a name="index-choldelete"></a><em><var>R1</var> =</em> <strong>choldelete</strong> <em>(<var>R</var>, <var>j</var>)</em></dt>
<dd><p>Update a Cholesky factorization given a row or column to delete from the original factored matrix.
</p>
<p>Given a Cholesky&nbsp;factorization of a real symmetric or complex Hermitian
positive definite matrix <var>A</var>&nbsp;=&nbsp;<var>R</var>&rsquo;*<var>R</var><!-- /@w -->, <var>R</var>&nbsp;upper
triangular, return the Cholesky&nbsp;factorization of A(p,p)<!-- /@w -->, where
p&nbsp;=&nbsp;<span class="nolinebreak">[1:j-1,j+1:n+1]</span><!-- /@w -->.
</p>
<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholshift">cholshift</a>.
</p></dd></dl>


<a name="XREFcholshift"></a><dl>
<dt><a name="index-cholshift"></a><em><var>R1</var> =</em> <strong>cholshift</strong> <em>(<var>R</var>, <var>i</var>, <var>j</var>)</em></dt>
<dd><p>Update a Cholesky factorization given a range of columns to shift in the original factored matrix.
</p>
<p>Given a Cholesky&nbsp;factorization of a real symmetric or complex Hermitian
positive definite matrix <var>A</var>&nbsp;=&nbsp;<var>R</var>&rsquo;*<var>R</var><!-- /@w -->, <var>R</var>&nbsp;upper
triangular, return the Cholesky&nbsp;factorization of
<var>A</var>(p,p)<!-- /@w -->, where p<!-- /@w --> is the permutation <br>
<code>p = [1:i-1, shift(i:j, 1), j+1:n]</code> if <var>i</var>&nbsp;&lt;&nbsp;<var>j</var><!-- /@w --> <br>
 or <br>
<code>p = [1:j-1, shift(j:i,-1), i+1:n]</code> if <var>j</var>&nbsp;&lt;&nbsp;<var>i</var><!-- /@w -->.  <br>
</p>

<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFcholinsert">cholinsert</a>, <a href="#XREFcholdelete">choldelete</a>.
</p></dd></dl>


<a name="XREFhess"></a><dl>
<dt><a name="index-hess"></a><em><var>H</var> =</em> <strong>hess</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-hess-1"></a><em>[<var>P</var>, <var>H</var>] =</em> <strong>hess</strong> <em>(<var>A</var>)</em></dt>
<dd><a name="index-Hessenberg-decomposition"></a>
<p>Compute the Hessenberg decomposition of the matrix <var>A</var>.
</p>
<p>The Hessenberg decomposition is
<code><var>P</var> * <var>H</var> * <var>P</var>' = <var>A</var></code> where <var>P</var> is a square
unitary matrix (<code><var>P</var>' * <var>P</var> = I</code>, using complex-conjugate
transposition) and <var>H</var> is upper Hessenberg
(<code><var>H</var>(i, j) = 0 forall i &gt; j+1)</code>.
</p>
<p>The Hessenberg decomposition is usually used as the first step in an
eigenvalue computation, but has other applications as well
(see Golub, Nash, and Van Loan,
IEEE Transactions on Automatic Control, 1979).
</p>
<p><strong>See also:</strong> <a href="Basic-Matrix-Functions.html#XREFeig">eig</a>, <a href="#XREFchol">chol</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>.
</p></dd></dl>


<a name="XREFlu"></a><dl>
<dt><a name="index-lu"></a><em>[<var>L</var>, <var>U</var>] =</em> <strong>lu</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-lu-1"></a><em>[<var>L</var>, <var>U</var>, <var>P</var>] =</em> <strong>lu</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-lu-2"></a><em>[<var>L</var>, <var>U</var>, <var>P</var>, <var>Q</var>] =</em> <strong>lu</strong> <em>(<var>S</var>)</em></dt>
<dt><a name="index-lu-3"></a><em>[<var>L</var>, <var>U</var>, <var>P</var>, <var>Q</var>, <var>R</var>] =</em> <strong>lu</strong> <em>(<var>S</var>)</em></dt>
<dt><a name="index-lu-4"></a><em>[&hellip;] =</em> <strong>lu</strong> <em>(<var>S</var>, <var>thres</var>)</em></dt>
<dt><a name="index-lu-5"></a><em><var>y</var> =</em> <strong>lu</strong> <em>(&hellip;)</em></dt>
<dt><a name="index-lu-6"></a><em>[&hellip;] =</em> <strong>lu</strong> <em>(&hellip;, &quot;vector&quot;)</em></dt>
<dd><a name="index-LU-decomposition"></a>
<p>Compute the LU&nbsp;decomposition of <var>A</var>.
</p>
<p>If <var>A</var> is full then subroutines from <small>LAPACK</small> are used, and if
<var>A</var> is sparse then <small>UMFPACK</small> is used.
</p>
<p>The result is returned in a permuted form, according to the optional return
value <var>P</var>.  For example, given the matrix <code>a = [1, 2; 3, 4]</code>,
</p>
<div class="example">
<pre class="example">[l, u, p] = lu (<var>a</var>)
</pre></div>

<p>returns
</p>
<div class="example">
<pre class="example">l =

  1.00000  0.00000
  0.33333  1.00000

u =

  3.00000  4.00000
  0.00000  0.66667

p =

  0  1
  1  0
</pre></div>

<p>The matrix is not required to be square.
</p>
<p>When called with two or three output arguments and a sparse input matrix,
<code>lu</code> does not attempt to perform sparsity preserving column permutations.
Called with a fourth output argument, the sparsity preserving column
transformation <var>Q</var> is returned, such that
<code><var>P</var> * <var>A</var> * <var>Q</var> = <var>L</var> * <var>U</var></code>.  This is the
<strong>preferred</strong> way to call <code>lu</code> with sparse input matrices.
</p>
<p>Called with a fifth output argument and a sparse input matrix, <code>lu</code>
attempts to use a scaling factor <var>R</var> on the input matrix such that
<code><var>P</var> * (<var>R</var> \ <var>A</var>) * <var>Q</var> = <var>L</var> * <var>U</var></code>.
This typically leads to a sparser and more stable factorization.
</p>
<p>An additional input argument <var>thres</var>, that defines the pivoting
threshold can be given.  <var>thres</var> can be a scalar, in which case
it defines the <small>UMFPACK</small> pivoting tolerance for both symmetric and
unsymmetric cases.  If <var>thres</var> is a 2-element vector, then the first
element defines the pivoting tolerance for the unsymmetric <small>UMFPACK</small>
pivoting strategy and the second for the symmetric strategy.  By default,
the values defined by <code>spparms</code> are used ([0.1, 0.001]).
</p>
<p>Given the string argument <code>&quot;vector&quot;</code>, <code>lu</code> returns the values
of <var>P</var> and <var>Q</var> as vector values, such that for full matrix,
<code><var>A</var>(<var>P</var>,:) = <var>L</var> * <var>U</var></code>, and <code><var>R</var>(<var>P</var>,:)
* <var>A</var>(:,<var>Q</var>) = <var>L</var> * <var>U</var></code>.
</p>
<p>With two output arguments, returns the permuted forms of the upper and
lower triangular matrices, such that <code><var>A</var> = <var>L</var> * <var>U</var></code>.
With one output argument <var>y</var>, then the matrix returned by the
<small>LAPACK</small> routines is returned.  If the input matrix is sparse then the
matrix <var>L</var> is embedded into <var>U</var> to give a return value similar to
the full case.  For both full and sparse matrices, <code>lu</code> loses the
permutation information.
</p>
<p><strong>See also:</strong> <a href="#XREFluupdate">luupdate</a>, <a href="Iterative-Techniques.html#XREFilu">ilu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>.
</p></dd></dl>


<a name="XREFluupdate"></a><dl>
<dt><a name="index-luupdate"></a><em>[<var>L</var>, <var>U</var>] =</em> <strong>luupdate</strong> <em>(<var>L</var>, <var>U</var>, <var>x</var>, <var>y</var>)</em></dt>
<dt><a name="index-luupdate-1"></a><em>[<var>L</var>, <var>U</var>, <var>P</var>] =</em> <strong>luupdate</strong> <em>(<var>L</var>, <var>U</var>, <var>P</var>, <var>x</var>, <var>y</var>)</em></dt>
<dd><p>Given an LU&nbsp;factorization of a real or complex matrix
<var>A</var>&nbsp;=&nbsp;<var>L</var>*<var>U</var><!-- /@w -->, <var>L</var>&nbsp;lower unit trapezoidal and
<var>U</var>&nbsp;upper trapezoidal, return the LU&nbsp;factorization
of <var>A</var>&nbsp;+&nbsp;<var>x</var>*<var>y</var>.&rsquo;<!-- /@w -->, where <var>x</var> and <var>y</var> are
column vectors (rank-1 update) or matrices with equal number of columns
(rank-k update).
</p>
<p>Optionally, row-pivoted updating can be used by supplying a row permutation
(pivoting) matrix <var>P</var>; in that case, an updated permutation matrix is
returned.  Note that if <var>L</var>, <var>U</var>, <var>P</var> is a pivoted
LU&nbsp;factorization as obtained by <code>lu</code>:
</p>
<div class="example">
<pre class="example">[<var>L</var>, <var>U</var>, <var>P</var>] = lu (<var>A</var>);
</pre></div>

<p>then a factorization of <code><var>A</var>+<var>x</var>*<var>y</var>.'</code> can be obtained
either as
</p>
<div class="example">
<pre class="example">[<var>L1</var>, <var>U1</var>] = lu (<var>L</var>, <var>U</var>, <var>P</var>*<var>x</var>, <var>y</var>)
</pre></div>

<p>or
</p>
<div class="example">
<pre class="example">[<var>L1</var>, <var>U1</var>, <var>P1</var>] = lu (<var>L</var>, <var>U</var>, <var>P</var>, <var>x</var>, <var>y</var>)
</pre></div>

<p>The first form uses the unpivoted algorithm, which is faster, but less
stable.  The second form uses a slower pivoted algorithm, which is more
stable.
</p>
<p>The matrix case is done as a sequence of rank-1 updates; thus, for large
enough k, it will be both faster and more accurate to recompute the
factorization from scratch.
</p>
<p><strong>See also:</strong> <a href="#XREFlu">lu</a>, <a href="#XREFcholupdate">cholupdate</a>, <a href="#XREFqrupdate">qrupdate</a>.
</p></dd></dl>


<a name="XREFqr"></a><dl>
<dt><a name="index-qr"></a><em>[<var>Q</var>, <var>R</var>] =</em> <strong>qr</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-qr-1"></a><em>[<var>Q</var>, <var>R</var>, <var>P</var>] =</em> <strong>qr</strong> <em>(<var>A</var>)  # non-sparse A</em></dt>
<dt><a name="index-qr-2"></a><em><var>X</var> =</em> <strong>qr</strong> <em>(<var>A</var>)  # non-sparse A</em></dt>
<dt><a name="index-qr-3"></a><em><var>R</var> =</em> <strong>qr</strong> <em>(<var>A</var>)  # sparse A</em></dt>
<dt><a name="index-qr-4"></a><em>[<var>C</var>, <var>R</var>] =</em> <strong>qr</strong> <em>(<var>A</var>, <var>B</var>)</em></dt>
<dt><a name="index-qr-5"></a><em>[&hellip;] =</em> <strong>qr</strong> <em>(&hellip;, 0)</em></dt>
<dt><a name="index-qr-6"></a><em>[&hellip;] =</em> <strong>qr</strong> <em>(&hellip;, &quot;vector&quot;)</em></dt>
<dt><a name="index-qr-7"></a><em>[&hellip;] =</em> <strong>qr</strong> <em>(&hellip;, &quot;matrix&quot;)</em></dt>
<dd><a name="index-QR-factorization"></a>
<p>Compute the QR&nbsp;factorization of <var>A</var>, using standard <small>LAPACK</small>
subroutines.
</p>
<p>The QR&nbsp;factorization is
</p>
<div class="example">
<pre class="example"><var>Q</var> * <var>R</var> = <var>A</var>
</pre></div>

<p>where <var>Q</var> is an orthogonal matrix and <var>R</var> is upper triangular.
</p>
<p>For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>,
</p>
<div class="example">
<pre class="example">[<var>Q</var>, <var>R</var>] = qr (<var>A</var>)
</pre></div>

<p>returns
</p>
<div class="example">
<pre class="example"><var>Q</var> =

  -0.31623  -0.94868
  -0.94868   0.31623

<var>R</var> =

  -3.16228  -4.42719
   0.00000  -0.63246
</pre></div>

<p>which multiplied together return the original matrix
</p>
<div class="example">
<pre class="example"><var>Q</var> * <var>R</var>
  &rArr;
     1.0000   2.0000
     3.0000   4.0000
</pre></div>

<p>If just a single return value is requested then it is either <var>R</var>, if
<var>A</var> is sparse, or <var>X</var>, such that <code><var>R</var> = triu (<var>X</var>)</code> if
<var>A</var> is full.  (Note: unlike most commands, the single return value is not
the first return value when multiple values are requested.)
</p>
<p>If the matrix <var>A</var> is full, and a third output <var>P</var> is requested, then
<code>qr</code> calculates the permuted QR&nbsp;factorization
</p>
<div class="example">
<pre class="example"><var>Q</var> * <var>R</var> = <var>A</var> * <var>P</var>
</pre></div>

<p>where <var>Q</var> is an orthogonal matrix, <var>R</var> is upper triangular, and
<var>P</var> is a permutation matrix.
</p>
<p>The permuted QR&nbsp;factorization has the additional property that the
diagonal entries of <var>R</var> are ordered by decreasing magnitude.  In other
words, <code>abs (diag (<var>R</var>))</code> will be ordered from largest to smallest.
</p>
<p>For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>,
</p>
<div class="example">
<pre class="example">[<var>Q</var>, <var>R</var>, <var>P</var>] = qr (<var>A</var>)
</pre></div>

<p>returns
</p>
<div class="example">
<pre class="example"><var>Q</var> =

  -0.44721  -0.89443
  -0.89443   0.44721

<var>R</var> =

  -4.47214  -3.13050
   0.00000   0.44721

<var>P</var> =

   0  1
   1  0
</pre></div>

<p>If the input matrix <var>A</var> is sparse then the sparse QR&nbsp;factorization
is computed using <small>CSPARSE</small>.  Because the matrix <var>Q</var> is, in general, a
full matrix, it is recommended to request only one return value <var>R</var>.  In
that case, the computation avoids the construction of <var>Q</var> and returns
<var>R</var> such that <code><var>R</var> = chol (<var>A</var>' * <var>A</var>)</code>.
</p>
<p>If an additional matrix <var>B</var> is supplied and two return values are
requested, then <code>qr</code> returns <var>C</var>, where
<code><var>C</var> = <var>Q</var>' * <var>B</var></code>.  This allows the least squares
approximation of <code><var>A</var> \ <var>B</var></code> to be calculated as
</p>
<div class="example">
<pre class="example">[<var>C</var>, <var>R</var>] = qr (<var>A</var>, <var>B</var>)
<var>x</var> = <var>R</var> \ <var>C</var>
</pre></div>

<p>If the final argument is the string <code>&quot;vector&quot;</code> then <var>P</var> is a
permutation vector (of the columns of <var>A</var>) instead of a permutation matrix.
In this case, the defining relationship is
</p>
<div class="example">
<pre class="example"><var>Q</var> * <var>R</var> = <var>A</var>(:, <var>P</var>)
</pre></div>

<p>The default, however, is to return a permutation matrix and this may be
explicitly specified by using a final argument of <code>&quot;matrix&quot;</code>.
</p>
<p>If the final argument is the scalar 0 an <code>&quot;economy&quot;</code> factorization is
returned.  When the original matrix <var>A</var> has size MxN and M &gt; N then the
<code>&quot;economy&quot;</code> factorization will calculate just N rows in <var>R</var> and N
columns in <var>Q</var> and omit the zeros in <var>R</var>.  If M &le; N there is no
difference between the economy and standard factorizations.  When calculating
an <code>&quot;economy&quot;</code> factorization the output <var>P</var> is always a vector
rather than a matrix.
</p>
<p>Background: The QR factorization has applications in the solution of least
squares problems
</p>
<div class="example">
<pre class="example">min norm (A*x - b)
</pre></div>

<p>for overdetermined systems of equations (i.e.,
<var>A</var>
is a tall, thin matrix).
</p>
<p>The permuted QR&nbsp;factorization
<code>[<var>Q</var>, <var>R</var>, <var>P</var>] = qr (<var>A</var>)</code> allows the construction of an
orthogonal basis of <code>span (A)</code>.
</p>

<p><strong>See also:</strong> <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFlu">lu</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrdelete">qrdelete</a>, <a href="#XREFqrshift">qrshift</a>.
</p></dd></dl>


<a name="XREFqrupdate"></a><dl>
<dt><a name="index-qrupdate"></a><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrupdate</strong> <em>(<var>Q</var>, <var>R</var>, <var>u</var>, <var>v</var>)</em></dt>
<dd><p>Update a QR factorization given update vectors or matrices.
</p>
<p>Given a QR&nbsp;factorization of a real or complex matrix
<var>A</var>&nbsp;=&nbsp;<var>Q</var>*<var>R</var><!-- /@w -->, <var>Q</var>&nbsp;unitary and
<var>R</var>&nbsp;upper trapezoidal, return the QR&nbsp;factorization of
<var>A</var>&nbsp;+&nbsp;<var>u</var>*<var>v</var>&rsquo;<!-- /@w -->, where <var>u</var> and <var>v</var> are column vectors
(rank-1 update) or matrices with equal number of columns
(rank-k update).  Notice that the latter case is done as a sequence of
rank-1 updates; thus, for k large enough, it will be both faster and more
accurate to recompute the factorization from scratch.
</p>
<p>The QR&nbsp;factorization supplied may be either full (Q is square) or
economized (R is square).
</p>

<p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrdelete">qrdelete</a>, <a href="#XREFqrshift">qrshift</a>.
</p></dd></dl>


<a name="XREFqrinsert"></a><dl>
<dt><a name="index-qrinsert"></a><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrinsert</strong> <em>(<var>Q</var>, <var>R</var>, <var>j</var>, <var>x</var>, <var>orient</var>)</em></dt>
<dd><p>Update a QR factorization given a row or column to insert in the original factored matrix.
</p>

<p>Given a QR&nbsp;factorization of a real or complex matrix
<var>A</var>&nbsp;=&nbsp;<var>Q</var>*<var>R</var><!-- /@w -->, <var>Q</var>&nbsp;unitary and
<var>R</var>&nbsp;upper trapezoidal, return the QR&nbsp;factorization of
<span class="nolinebreak">[A(:,1:j-1)</span>&nbsp;x&nbsp;A(:,j:n)]<!-- /@w -->, where <var>u</var> is a column vector to be inserted
into <var>A</var> (if <var>orient</var> is <code>&quot;col&quot;</code>), or the
QR&nbsp;factorization of <span class="nolinebreak">[A(1:j-1,:);x;A(:,j:n)]</span><!-- /@w -->, where <var>x</var> is a row
vector to be inserted into <var>A</var> (if <var>orient</var> is <code>&quot;row&quot;</code>).
</p>
<p>The default value of <var>orient</var> is <code>&quot;col&quot;</code>.  If <var>orient</var> is
<code>&quot;col&quot;</code>, <var>u</var> may be a matrix and <var>j</var> an index vector
resulting in the QR&nbsp;factorization of a matrix <var>B</var> such that
B(:,<var>j</var>)<!-- /@w --> gives <var>u</var> and B(:,<var>j</var>)&nbsp;=&nbsp;[]<!-- /@w --> gives <var>A</var>.
Notice that the latter case is done as a sequence of k insertions;
thus, for k large enough, it will be both faster and more accurate to
recompute the factorization from scratch.
</p>
<p>If <var>orient</var> is <code>&quot;col&quot;</code>, the QR&nbsp;factorization supplied may
be either full (Q is square) or economized (R is square).
</p>
<p>If <var>orient</var> is <code>&quot;row&quot;</code>, full factorization is needed.
</p>
<p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrdelete">qrdelete</a>, <a href="#XREFqrshift">qrshift</a>.
</p></dd></dl>


<a name="XREFqrdelete"></a><dl>
<dt><a name="index-qrdelete"></a><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrdelete</strong> <em>(<var>Q</var>, <var>R</var>, <var>j</var>, <var>orient</var>)</em></dt>
<dd><p>Update a QR factorization given a row or column to delete from the original factored matrix.
</p>
<p>Given a QR&nbsp;factorization of a real or complex matrix
<var>A</var>&nbsp;=&nbsp;<var>Q</var>*<var>R</var><!-- /@w -->, <var>Q</var>&nbsp;unitary and
<var>R</var>&nbsp;upper trapezoidal, return the QR&nbsp;factorization of
<span class="nolinebreak">[A(:,1:j-1),</span>&nbsp;U,&nbsp;A(:,j:n)]<!-- /@w -->,
where <var>u</var> is a column vector to be inserted into <var>A</var>
(if <var>orient</var> is <code>&quot;col&quot;</code>),
or the QR&nbsp;factorization of <span class="nolinebreak">[A(1:j-1,:);X;A(:,j:n)]</span><!-- /@w -->,
where <var>x</var> is a row <var>orient</var> is <code>&quot;row&quot;</code>).
The default value of <var>orient</var> is <code>&quot;col&quot;</code>.
</p>
<p>If <var>orient</var> is <code>&quot;col&quot;</code>, <var>j</var> may be an index vector
resulting in the QR&nbsp;factorization of a matrix <var>B</var> such that
A(:,<var>j</var>)&nbsp;=&nbsp;[]<!-- /@w --> gives <var>B</var>.  Notice that the latter case is done as
a sequence of k deletions; thus, for k large enough, it will be both faster
and more accurate to recompute the factorization from scratch.
</p>
<p>If <var>orient</var> is <code>&quot;col&quot;</code>, the QR&nbsp;factorization supplied may
be either full (Q is square) or economized (R is square).
</p>
<p>If <var>orient</var> is <code>&quot;row&quot;</code>, full factorization is needed.
</p>
<p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrshift">qrshift</a>.
</p></dd></dl>


<a name="XREFqrshift"></a><dl>
<dt><a name="index-qrshift"></a><em>[<var>Q1</var>, <var>R1</var>] =</em> <strong>qrshift</strong> <em>(<var>Q</var>, <var>R</var>, <var>i</var>, <var>j</var>)</em></dt>
<dd><p>Update a QR factorization given a range of columns to shift in the original factored matrix.
</p>
<p>Given a QR&nbsp;factorization of a real or complex matrix
<var>A</var>&nbsp;=&nbsp;<var>Q</var>*<var>R</var><!-- /@w -->, <var>Q</var>&nbsp;unitary and
<var>R</var>&nbsp;upper trapezoidal, return the QR&nbsp;factorization
of <var>A</var>(:,p)<!-- /@w -->, where p<!-- /@w --> is the permutation <br>
<code>p = [1:i-1, shift(i:j, 1), j+1:n]</code> if <var>i</var>&nbsp;&lt;&nbsp;<var>j</var><!-- /@w --> <br>
 or <br>
<code>p = [1:j-1, shift(j:i,-1), i+1:n]</code> if <var>j</var>&nbsp;&lt;&nbsp;<var>i</var><!-- /@w -->.  <br>
</p>

<p><strong>See also:</strong> <a href="#XREFqr">qr</a>, <a href="#XREFqrupdate">qrupdate</a>, <a href="#XREFqrinsert">qrinsert</a>, <a href="#XREFqrdelete">qrdelete</a>.
</p></dd></dl>


<a name="XREFqz"></a><dl>
<dt><a name="index-qz"></a><em><var>lambda</var> =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>)</em></dt>
<dt><a name="index-qz-1"></a><em>[<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>, <var>V</var>, <var>W</var>, <var>lambda</var>] =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>)</em></dt>
<dt><a name="index-qz-2"></a><em>[<var>AA</var>, <var>BB</var>, <var>Z</var>] =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>, <var>opt</var>)</em></dt>
<dt><a name="index-qz-3"></a><em>[<var>AA</var>, <var>BB</var>, <var>Z</var>, <var>lambda</var>] =</em> <strong>qz</strong> <em>(<var>A</var>, <var>B</var>, <var>opt</var>)</em></dt>
<dd><p>Compute the QZ&nbsp;decomposition of a generalized eigenvalue problem.
</p>
<p>The generalized eigenvalue problem is defined as
</p>

<p><em>A x = <var>lambda</var> B x</em>
</p>

<p>There are three calling forms of the function:
</p>
<ol>
<li> <code><var>lambda</var> = qz (<var>A</var>, <var>B</var>)</code>

<p>Compute the generalized eigenvalues
<var>lambda</var>.
</p>
</li><li> <code>[<var>AA</var>, <var>BB</var>, <var>Q</var>, <var>Z</var>, <var>V</var>, <var>W</var>, <var>lambda</var>] = qz (<var>A</var>, <var>B</var>)</code>

<p>Compute QZ&nbsp;decomposition, generalized eigenvectors, and generalized
eigenvalues.
</p>
<div class="example">
<pre class="example">

<var>A</var> * <var>V</var> = <var>B</var> * <var>V</var> * diag (<var>lambda</var>)
<var>W</var>' * <var>A</var> = diag (<var>lambda</var>) * <var>W</var>' * <var>B</var>
<var>AA</var> = <var>Q</var> * <var>A</var> * <var>Z</var>, <var>BB</var> = <var>Q</var> * <var>B</var> * <var>Z</var>

</pre></div>

<p>with <var>Q</var> and <var>Z</var> orthogonal (unitary for complex case).
</p>
</li><li> <code>[<var>AA</var>, <var>BB</var>, <var>Z</var> {, <var>lambda</var>}] = qz (<var>A</var>, <var>B</var>, <var>opt</var>)</code>

<p>As in form 2 above, but allows ordering of generalized eigenpairs for, e.g.,
solution of discrete time algebraic Riccati equations.  Form 3 is not
available for complex matrices, and does not compute the generalized
eigenvectors <var>V</var>, <var>W</var>, nor the orthogonal matrix <var>Q</var>.
</p>
<dl compact="compact">
<dt><var>opt</var></dt>
<dd><p>for ordering eigenvalues of the GEP pencil.  The leading block of
the revised pencil contains all eigenvalues that satisfy:
</p>
<dl compact="compact">
<dt><code>&quot;N&quot;</code></dt>
<dd><p>unordered (default)
</p>
</dd>
<dt><code>&quot;S&quot;</code></dt>
<dd><p>small: leading block has all
|<var>lambda</var>| &lt; 1
</p>
</dd>
<dt><code>&quot;B&quot;</code></dt>
<dd><p>big: leading block has all
|<var>lambda</var>| &ge; 1
</p>
</dd>
<dt><code>&quot;-&quot;</code></dt>
<dd><p>negative real part: leading block has all eigenvalues in the open left
half-plane
</p>
</dd>
<dt><code>&quot;+&quot;</code></dt>
<dd><p>non-negative real part: leading block has all eigenvalues in the closed right
half-plane
</p></dd>
</dl>
</dd>
</dl>
</li></ol>

<p>Note: <code>qz</code> performs permutation balancing, but not scaling
(see <a href="Basic-Matrix-Functions.html#XREFbalance">balance</a>), which may be lead to less accurate results than
<code>eig</code>.  The order of output arguments was selected for compatibility with
<small>MATLAB</small>.
</p>
<p><strong>See also:</strong> <a href="Basic-Matrix-Functions.html#XREFeig">eig</a>, <a href="Basic-Matrix-Functions.html#XREFbalance">balance</a>, <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqzhess">qzhess</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>.
</p></dd></dl>


<a name="XREFqzhess"></a><dl>
<dt><a name="index-qzhess"></a><em>[<var>aa</var>, <var>bb</var>, <var>q</var>, <var>z</var>] =</em> <strong>qzhess</strong> <em>(<var>A</var>, <var>B</var>)</em></dt>
<dd><p>Compute the Hessenberg-triangular decomposition of the matrix pencil
<code>(<var>A</var>, <var>B</var>)</code>, returning
<code><var>aa</var> = <var>q</var> * <var>A</var> * <var>z</var></code>,
<code><var>bb</var> = <var>q</var> * <var>B</var> * <var>z</var></code>, with <var>q</var> and <var>z</var>
orthogonal.
</p>
<p>For example:
</p>
<div class="example">
<pre class="example">[aa, bb, q, z] = qzhess ([1, 2; 3, 4], [5, 6; 7, 8])
     &rArr; aa = [ -3.02244, -4.41741;  0.92998,  0.69749 ]
     &rArr; bb = [ -8.60233, -9.99730;  0.00000, -0.23250 ]
     &rArr;  q = [ -0.58124, -0.81373; -0.81373,  0.58124 ]
     &rArr;  z = [ 1, 0; 0, 1 ]
</pre></div>

<p>The Hessenberg-triangular decomposition is the first step in
Moler and Stewart&rsquo;s QZ&nbsp;decomposition algorithm.
</p>
<p>Algorithm taken from Golub and Van Loan,
<cite>Matrix Computations, 2nd edition</cite>.
</p>

<p><strong>See also:</strong> <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFschur">schur</a>, <a href="#XREFsvd">svd</a>.
</p></dd></dl>


<a name="XREFschur"></a><dl>
<dt><a name="index-schur"></a><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-schur-1"></a><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>, &quot;real&quot;)</em></dt>
<dt><a name="index-schur-2"></a><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>, &quot;complex&quot;)</em></dt>
<dt><a name="index-schur-3"></a><em><var>S</var> =</em> <strong>schur</strong> <em>(<var>A</var>, <var>opt</var>)</em></dt>
<dt><a name="index-schur-4"></a><em>[<var>U</var>, <var>S</var>] =</em> <strong>schur</strong> <em>(&hellip;)</em></dt>
<dd><a name="index-Schur-decomposition"></a>
<p>Compute the Schur&nbsp;decomposition of <var>A</var>.
</p>
<p>The Schur&nbsp;decomposition is defined as
</p>
<div class="example">
<pre class="example"><code><var>S</var> = <var>U</var>' * <var>A</var> * <var>U</var></code>
</pre></div>

<p>where <var>U</var> is a unitary matrix
(<code><var>U</var>'* <var>U</var></code> is identity)
and <var>S</var> is upper triangular.  The eigenvalues of <var>A</var> (and <var>S</var>)
are the diagonal elements of <var>S</var>.  If the matrix <var>A</var> is real, then
the real Schur&nbsp;decomposition is computed, in which the matrix <var>U</var>
is orthogonal and <var>S</var> is block upper triangular with blocks of size at
most
<code>2 x 2</code>
along the diagonal.  The diagonal elements of <var>S</var>
(or the eigenvalues of the
<code>2 x 2</code>
blocks, when appropriate) are the eigenvalues of <var>A</var> and <var>S</var>.
</p>
<p>The default for real matrices is a real Schur&nbsp;decomposition.
A complex decomposition may be forced by passing the flag
<code>&quot;complex&quot;</code>.
</p>
<p>The eigenvalues are optionally ordered along the diagonal according to the
value of <var>opt</var>.  <code><var>opt</var> = &quot;a&quot;</code> indicates that all eigenvalues
with negative real parts should be moved to the leading block of <var>S</var>
(used in <code>are</code>), <code><var>opt</var> = &quot;d&quot;</code> indicates that all
eigenvalues with magnitude less than one should be moved to the leading
block of <var>S</var> (used in <code>dare</code>), and <code><var>opt</var> = &quot;u&quot;</code>, the
default, indicates that no ordering of eigenvalues should occur.  The
leading <var>k</var> columns of <var>U</var> always span the <var>A</var>-invariant
subspace corresponding to the <var>k</var> leading eigenvalues of <var>S</var>.
</p>
<p>The Schur&nbsp;decomposition is used to compute eigenvalues of a square
matrix, and has applications in the solution of algebraic Riccati
equations in control (see <code>are</code> and <code>dare</code>).
</p>
<p><strong>See also:</strong> <a href="#XREFrsf2csf">rsf2csf</a>, <a href="#XREFordschur">ordschur</a>, <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>, <a href="#XREFsvd">svd</a>.
</p></dd></dl>


<a name="XREFrsf2csf"></a><dl>
<dt><a name="index-rsf2csf"></a><em>[<var>U</var>, <var>T</var>] =</em> <strong>rsf2csf</strong> <em>(<var>UR</var>, <var>TR</var>)</em></dt>
<dd><p>Convert a real, upper quasi-triangular Schur&nbsp;form <var>TR</var> to a
complex, upper triangular Schur&nbsp;form <var>T</var>.
</p>
<p>Note that the following relations hold:
</p>
<p><code><var>UR</var> * <var>TR</var> * <var>UR</var>' = <var>U</var> * <var>T</var> * <var>U</var>'</code> and
<code><var>U</var>' * <var>U</var></code> is the identity matrix I.
</p>
<p>Note also that <var>U</var> and <var>T</var> are not unique.
</p>
<p><strong>See also:</strong> <a href="#XREFschur">schur</a>.
</p></dd></dl>


<a name="XREFordschur"></a><dl>
<dt><a name="index-ordschur"></a><em>[<var>UR</var>, <var>SR</var>] =</em> <strong>ordschur</strong> <em>(<var>U</var>, <var>S</var>, <var>select</var>)</em></dt>
<dd><p>Reorders the real Schur factorization (<var>U</var>,<var>S</var>) obtained with the
<code>schur</code> function, so that selected eigenvalues appear in the upper left
diagonal blocks of the quasi triangular Schur matrix.
</p>
<p>The logical vector <var>select</var> specifies the selected eigenvalues as they
appear along <var>S</var>&rsquo;s diagonal.
</p>
<p>For example, given the matrix <code><var>A</var> = [1, 2; 3, 4]</code>, and its Schur
decomposition
</p>
<div class="example">
<pre class="example">[<var>U</var>, <var>S</var>] = schur (<var>A</var>)
</pre></div>

<p>which returns
</p>
<div class="example">
<pre class="example"><var>U</var> =

  -0.82456  -0.56577
   0.56577  -0.82456

<var>S</var> =

  -0.37228  -1.00000
   0.00000   5.37228

</pre></div>

<p>It is possible to reorder the decomposition so that the positive eigenvalue
is in the upper left corner, by doing:
</p>
<div class="example">
<pre class="example">[<var>U</var>, <var>S</var>] = ordschur (<var>U</var>, <var>S</var>, [0,1])
</pre></div>


<p><strong>See also:</strong> <a href="#XREFschur">schur</a>.
</p></dd></dl>


<a name="XREFsubspace"></a><dl>
<dt><a name="index-subspace"></a><em><var>angle</var> =</em> <strong>subspace</strong> <em>(<var>A</var>, <var>B</var>)</em></dt>
<dd><p>Determine the largest principal angle between two subspaces
spanned by the columns of matrices <var>A</var> and <var>B</var>.
</p></dd></dl>


<a name="XREFsvd"></a><dl>
<dt><a name="index-svd"></a><em><var>s</var> =</em> <strong>svd</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-svd-1"></a><em>[<var>U</var>, <var>S</var>, <var>V</var>] =</em> <strong>svd</strong> <em>(<var>A</var>)</em></dt>
<dt><a name="index-svd-2"></a><em>[<var>U</var>, <var>S</var>, <var>V</var>] =</em> <strong>svd</strong> <em>(<var>A</var>, &quot;econ&quot;)</em></dt>
<dt><a name="index-svd-3"></a><em>[<var>U</var>, <var>S</var>, <var>V</var>] =</em> <strong>svd</strong> <em>(<var>A</var>, 0)</em></dt>
<dd><a name="index-singular-value-decomposition"></a>
<p>Compute the singular value decomposition of <var>A</var>.
</p>
<p>The singular value decomposition is defined by the relation
</p>

<div class="example">
<pre class="example">A = U*S*V'
</pre></div>


<p>The function <code>svd</code> normally returns only the vector of singular values.
When called with three return values, it computes
<var>U</var>, <var>S</var>, and <var>V</var>.
For example,
</p>
<div class="example">
<pre class="example">svd (hilb (3))
</pre></div>

<p>returns
</p>
<div class="example">
<pre class="example">ans =

  1.4083189
  0.1223271
  0.0026873
</pre></div>

<p>and
</p>
<div class="example">
<pre class="example">[u, s, v] = svd (hilb (3))
</pre></div>

<p>returns
</p>
<div class="example">
<pre class="example">u =

  -0.82704   0.54745   0.12766
  -0.45986  -0.52829  -0.71375
  -0.32330  -0.64901   0.68867

s =

  1.40832  0.00000  0.00000
  0.00000  0.12233  0.00000
  0.00000  0.00000  0.00269

v =

  -0.82704   0.54745   0.12766
  -0.45986  -0.52829  -0.71375
  -0.32330  -0.64901   0.68867
</pre></div>

<p>When given a second argument that is not 0, <code>svd</code> returns an economy-sized
decomposition, eliminating the unnecessary rows or columns of <var>U</var> or
<var>V</var>.
</p>
<p>If the second argument is exactly 0, then the choice of decomposition is based
on the matrix <var>A</var>.  If <var>A</var> has more rows than columns then an
economy-sized decomposition is returned, otherwise a regular decomposition
is calculated.
</p>
<p>Algorithm Notes: When calculating the full decomposition (left and right
singular matrices in addition to singular values) there is a choice of two
routines in <small>LAPACK</small>.  The default routine used by Octave is <code>gesdd</code>
which is 5X faster than the alternative <code>gesvd</code>, but may use more memory
and may be less accurate for some matrices.  See the documentation for
<code>svd_driver</code> for more information.
</p>
<p><strong>See also:</strong> <a href="#XREFsvd_005fdriver">svd_driver</a>, <a href="Sparse-Linear-Algebra.html#XREFsvds">svds</a>, <a href="Basic-Matrix-Functions.html#XREFeig">eig</a>, <a href="#XREFlu">lu</a>, <a href="#XREFchol">chol</a>, <a href="#XREFhess">hess</a>, <a href="#XREFqr">qr</a>, <a href="#XREFqz">qz</a>.
</p></dd></dl>


<a name="XREFsvd_005fdriver"></a><dl>
<dt><a name="index-svd_005fdriver"></a><em><var>val</var> =</em> <strong>svd_driver</strong> <em>()</em></dt>
<dt><a name="index-svd_005fdriver-1"></a><em><var>old_val</var> =</em> <strong>svd_driver</strong> <em>(<var>new_val</var>)</em></dt>
<dt><a name="index-svd_005fdriver-2"></a><em></em> <strong>svd_driver</strong> <em>(<var>new_val</var>, &quot;local&quot;)</em></dt>
<dd><p>Query or set the underlying <small>LAPACK</small> driver used by <code>svd</code>.
</p>
<p>Currently recognized values are <code>&quot;gesdd&quot;</code> and <code>&quot;gesvd&quot;</code>.
The default is <code>&quot;gesdd&quot;</code>.
</p>
<p>When called from inside a function with the <code>&quot;local&quot;</code> option, the
variable is changed locally for the function and any subroutines it calls.
The original variable value is restored when exiting the function.
</p>
<p>Algorithm Notes: The <small>LAPACK</small> library provides two routines for calculating
the full singular value decomposition (left and right singular matrices as
well as singular values).  When calculating just the singular values the
following discussion is not relevant.
</p>
<p>The default routine use by Octave is the newer <code>gesdd</code> which is based on a
Divide-and-Conquer algorithm that is 5X faster than the alternative
<code>gesvd</code>, which is based on QR factorization.  However, the new algorithm
can use significantly more memory.  For an MxN input matrix the
memory usage is of order O(min(M,N) ^ 2), whereas the alternative is of order
O(max(M,N)).  In general, modern computers have abundant memory so Octave has
chosen to prioritize speed.
</p>
<p>In addition, there have been instances in the past where some input matrices
were not accurately decomposed by <code>gesdd</code>.  This appears to have been
resolved with modern versions of <small>LAPACK</small>.  However, if certainty is
required the accuracy of the decomposition can always be tested after the fact
with
</p>
<div class="example">
<pre class="example">[<var>u</var>, <var>s</var>, <var>v</var>] = svd (<var>x</var>);
norm (<var>x</var> - <var>u</var>*<var>s</var>*<var>v'</var>, &quot;fro&quot;)
</pre></div>


<p><strong>See also:</strong> <a href="#XREFsvd">svd</a>.
</p></dd></dl>



<a name="XREFhoush"></a><dl>
<dt><a name="index-housh"></a><em>[<var>housv</var>, <var>beta</var>, <var>zer</var>] =</em> <strong>housh</strong> <em>(<var>x</var>, <var>j</var>, <var>z</var>)</em></dt>
<dd><p>Compute Householder reflection vector <var>housv</var> to reflect <var>x</var> to be
the j-th column of identity, i.e.,
</p>
<div class="example">
<pre class="example">(I - beta*housv*housv')x =  norm (x)*e(j) if x(j) &lt; 0,
(I - beta*housv*housv')x = -norm (x)*e(j) if x(j) &gt;= 0
</pre></div>

<p>Inputs
</p>
<dl compact="compact">
<dt><var>x</var></dt>
<dd><p>vector
</p>
</dd>
<dt><var>j</var></dt>
<dd><p>index into vector
</p>
</dd>
<dt><var>z</var></dt>
<dd><p>threshold for zero  (usually should be the number 0)
</p></dd>
</dl>

<p>Outputs (see Golub and Van Loan):
</p>
<dl compact="compact">
<dt><var>beta</var></dt>
<dd><p>If beta = 0, then no reflection need be applied (zer set to 0)
</p>
</dd>
<dt><var>housv</var></dt>
<dd><p>householder vector
</p></dd>
</dl>
</dd></dl>


<a name="XREFkrylov"></a><dl>
<dt><a name="index-krylov"></a><em>[<var>u</var>, <var>h</var>, <var>nu</var>] =</em> <strong>krylov</strong> <em>(<var>A</var>, <var>V</var>, <var>k</var>, <var>eps1</var>, <var>pflg</var>)</em></dt>
<dd><p>Construct an orthogonal basis <var>u</var> of a block Krylov subspace.
</p>
<p>The block Krylov subspace has the following form:
</p>
<div class="example">
<pre class="example">[v a*v a^2*v &hellip; a^(k+1)*v]
</pre></div>

<p>The construction is made with Householder reflections to guard against loss
of orthogonality.
</p>
<p>If <var>V</var> is a vector, then <var>h</var> contains the Hessenberg matrix
such that <code>a*u == u*h+rk*ek'</code>, in which
<code>rk = a*u(:,k)-u*h(:,k)</code>, and <code>ek'</code> is the vector
<code>[0, 0, &hellip;, 1]</code> of length <var>k</var>.  Otherwise, <var>h</var> is
meaningless.
</p>
<p>If <var>V</var> is a vector and <var>k</var> is greater than <code>length (A) - 1</code>,
then <var>h</var> contains the Hessenberg matrix such that <code>a*u == u*h</code>.
</p>
<p>The value of <var>nu</var> is the dimension of the span of the Krylov subspace
(based on <var>eps1</var>).
</p>
<p>If <var>b</var> is a vector and <var>k</var> is greater than <var>m-1</var>, then <var>h</var>
contains the Hessenberg decomposition of <var>A</var>.
</p>
<p>The optional parameter <var>eps1</var> is the threshold for zero.  The default
value is 1e-12.
</p>
<p>If the optional parameter <var>pflg</var> is nonzero, row pivoting is used to
improve numerical behavior.  The default value is 0.
</p>
<p>Reference: A. Hodel, P. Misra, <cite>Partial Pivoting in the
Computation of Krylov Subspaces of Large Sparse Systems</cite>, Proceedings of
the 42nd IEEE Conference on Decision and Control, December 2003.
</p></dd></dl>


<hr>
<div class="header">
<p>
Next: <a href="Functions-of-a-Matrix.html#Functions-of-a-Matrix" accesskey="n" rel="next">Functions of a Matrix</a>, Previous: <a href="Basic-Matrix-Functions.html#Basic-Matrix-Functions" accesskey="p" rel="prev">Basic Matrix Functions</a>, Up: <a href="Linear-Algebra.html#Linear-Algebra" accesskey="u" rel="up">Linear Algebra</a> &nbsp; [<a href="index.html#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Concept-Index.html#Concept-Index" title="Index" rel="index">Index</a>]</p>
</div>



</body>
</html>
